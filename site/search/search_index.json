{"config":{"indexing":"full","lang":["fr"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Acceuil \u00b6 Bienvenue sur la documentation CS2i r\u00e9alis\u00e9e par L\u00e9o Guilloux Page g\u00e9nr\u00e9e automatiquement par un script Nom Fichier Date de cr\u00e9ation GPO GPO 2023-01-11 Cr\u00e9ation fichier avec user + date Cr\u00e9ation fichier avec user + date 2023-01-11 Cr\u00e9ation d'un dossier+script Cr\u00e9ation d'un dossier+script 2023-01-11 Cr\u00e9ation_image Cr\u00e9ation_image 2023-03-26 Acceuil_mkdocs Acceuil_mkdocs 2023-03-26 Traefik_for_mkdocs Traefik_for_mkdocs 2023-03-26 Prepa Prepa 2023-04-07 Ansible Ansible 2023-02-14 Partition_LVM Partition_LVM 2023-02-14 RAID RAID 2023-02-14 SElinux SElinux 2023-01-27 sudo sudo 2023-01-27 permissions permissions 2023-01-26 Apache Apache 2023-03-21 Runners Runners 2023-02-22 Docker Docker 2023-02-20 Traefik Traefik 2023-02-22 Docker-swarm Docker-swarm 2023-03-21 RPM_et_yum RPM_et_yum 2023-01-11 Installation Installation 2023-01-26 NMCLI NMCLI 2023-02-14 SSH SSH 2023-03-21 LDAP LDAP 2023-02-16 DNS DNS 2023-02-22 Acceuil_Linux Acceuil_Linux 2023-03-22 Syntaxe fichier deployment et services Syntaxe fichier deployment et services 2023-03-23 Syntaxes des stockages Syntaxes des stockages 2023-03-23 Commandes dans kubernetes Commandes dans kubernetes 2023-03-22 Informations sur kubernetes Informations sur kubernetes 2023-01-11 pointasvaoir pointasvaoir 2023-03-24 les secrets les secrets 2023-03-24 Rappel sur la virtualisation Rappel sur la virtualisation 2023-01-11 Terraform Terraform 2023-04-08","title":"Acceuil"},{"location":"#acceuil","text":"Bienvenue sur la documentation CS2i r\u00e9alis\u00e9e par L\u00e9o Guilloux Page g\u00e9nr\u00e9e automatiquement par un script Nom Fichier Date de cr\u00e9ation GPO GPO 2023-01-11 Cr\u00e9ation fichier avec user + date Cr\u00e9ation fichier avec user + date 2023-01-11 Cr\u00e9ation d'un dossier+script Cr\u00e9ation d'un dossier+script 2023-01-11 Cr\u00e9ation_image Cr\u00e9ation_image 2023-03-26 Acceuil_mkdocs Acceuil_mkdocs 2023-03-26 Traefik_for_mkdocs Traefik_for_mkdocs 2023-03-26 Prepa Prepa 2023-04-07 Ansible Ansible 2023-02-14 Partition_LVM Partition_LVM 2023-02-14 RAID RAID 2023-02-14 SElinux SElinux 2023-01-27 sudo sudo 2023-01-27 permissions permissions 2023-01-26 Apache Apache 2023-03-21 Runners Runners 2023-02-22 Docker Docker 2023-02-20 Traefik Traefik 2023-02-22 Docker-swarm Docker-swarm 2023-03-21 RPM_et_yum RPM_et_yum 2023-01-11 Installation Installation 2023-01-26 NMCLI NMCLI 2023-02-14 SSH SSH 2023-03-21 LDAP LDAP 2023-02-16 DNS DNS 2023-02-22 Acceuil_Linux Acceuil_Linux 2023-03-22 Syntaxe fichier deployment et services Syntaxe fichier deployment et services 2023-03-23 Syntaxes des stockages Syntaxes des stockages 2023-03-23 Commandes dans kubernetes Commandes dans kubernetes 2023-03-22 Informations sur kubernetes Informations sur kubernetes 2023-01-11 pointasvaoir pointasvaoir 2023-03-24 les secrets les secrets 2023-03-24 Rappel sur la virtualisation Rappel sur la virtualisation 2023-01-11 Terraform Terraform 2023-04-08","title":"Acceuil"},{"location":"Linux/Acceuil_Linux/","text":"","title":"Acceuil Linux"},{"location":"Linux/Bachelor/Partionnement/Partition_LVM/","text":"Mise en place des partitions \u00b6 D\u00e9couverte des disques \u00b6 Emplacement des disques \u00b6 /dev/sda sda = Premier disque sdb = Second disque De mani\u00e8re g\u00e9n\u00e9rale sd x avec le x qui est le disque (par ordre aphab\u00e9tique) Partitions des disques \u00b6 /dev/sda1 sda1 = Premi\u00e8re partition du disque sda2 = Seconde partition du disque De mani\u00e8re g\u00e9\u00e9nrale sd x z avec z qui le num\u00e9ro de la partition. Cr\u00e9ation des partitions \u00b6 Liste des partitions \u00b6 1 partition swap 1 partition filesystem 3 partition LVM 3 partitions RAID Commande : fdisk /dev/sdb Pour acc\u00e8der au menu : m pour l'aide de la commande Cr\u00e9ation de la nouvelle table en GPT : g Cr\u00e9ation de la nouvelle partition : n -> Num\u00e9ro de partition -> Premier secteur -> Dernier secteur (possibilit\u00e9 de mettre un espace en K,M,G,T,P) Cr\u00e9ation du type de la partition : t -> Num\u00e9ro de la partition \u00e0 modifier -> Num\u00e9ro ou alias de type de partition Mise en place de sauvegarde \u00b6 Mise en place de l'archive de sauvegarde \u00b6 Sauvegarde : tar -cvz -f /home.tar.gz /home -> -c = Cr\u00e9ation d'archive -> -v = Verbose -> -z = Compression du fichier -> -f = Nom de l'archive (Toujours cette option en derni\u00e8re) Test de l'archive : tar -tf /home.tar.gz -> -t = pour tester l'archive -> -f = sp\u00e9cification du fichier (Toujours cette option en derni\u00e8re) Mise en place du nouveau /home \u00b6 Vidange du r\u00e9pertoire \u00b6 Plusieurs fa\u00e7on de vider le r\u00e9pertoire /home : rm -rf /home ; mkdir /home ou rm -rf /home/* Attention \u00e0 ne pas mettre d'espace entre / et home car cela supprimerais tout le syst\u00e8me de fichier. Mise en place du formatage \u00b6 Formatage en EXT4 pour la partition FileSystem : mkfs.ext4 /dev/sdb2 Message d'erreur si la partition est d\u00e9j\u00e0 format\u00e9e Obtenir l'UUID d'une partition : lsblk -o uuid -n /dev/sdb2 Modification de fstab : nano /etc/fstab Montage de la partition et test si fstab est correct: sudo mount -av Restauration de l'archive \u00b6 sudo tar -C / -xf /home.tar.gz ls -l /home Vigilance sur la taille du syst\u00e8me de fichier sinon l'extraction ne focntionnera pas. LVM \u00b6 Commandes LVM2 \u00b6 Scan des partitions LVM : pvs alias => pvscan Cr\u00e9ation disques physiques pour les volumes logiques : pvcreate /dev/sdb3 /dev/sdb4 /dev/sdb5 alias => pvcreate /dev/sdb{3..5} Cr\u00e9ation d'un volume logique vgdata vgcreate vgdata /dev/sdb3 lsblk pour affihcer tout les volumes VG => Volume groupe L'extention de VG prends des volumes physiques sudo vgextend vgdata /dev/sdb4 LV => Logical Volume - pour utiliser les commandes \u00e0 partir de PV.... , on parle de volume physique. PV => Physical volume Commandes pour afficher les volumes \u00b6 pvscan lvscan pvscan Suppression des volumes \u00b6 La suppression des volumes entraine la suppression des donn\u00e9es stock\u00e9es sur le logical volume D\u00e9montage des volumes en premier : unmount \\data Suppression du volume logique : lvremove /dev/rootvg/lvdata Suppression du volume groupe : vgremove /dev/rootvg Suppression des volumes physique : pvremove /dev/sdb3 /dev/sdb4 /dev/sdb5 Modification du fstab pour ne pas demarrer en mode recovery","title":"Mise en place des partitions"},{"location":"Linux/Bachelor/Partionnement/Partition_LVM/#mise-en-place-des-partitions","text":"","title":"Mise en place des partitions"},{"location":"Linux/Bachelor/Partionnement/Partition_LVM/#decouverte-des-disques","text":"","title":"D\u00e9couverte des disques"},{"location":"Linux/Bachelor/Partionnement/Partition_LVM/#emplacement-des-disques","text":"/dev/sda sda = Premier disque sdb = Second disque De mani\u00e8re g\u00e9n\u00e9rale sd x avec le x qui est le disque (par ordre aphab\u00e9tique)","title":"Emplacement des disques"},{"location":"Linux/Bachelor/Partionnement/Partition_LVM/#partitions-des-disques","text":"/dev/sda1 sda1 = Premi\u00e8re partition du disque sda2 = Seconde partition du disque De mani\u00e8re g\u00e9\u00e9nrale sd x z avec z qui le num\u00e9ro de la partition.","title":"Partitions des disques"},{"location":"Linux/Bachelor/Partionnement/Partition_LVM/#creation-des-partitions","text":"","title":"Cr\u00e9ation des partitions"},{"location":"Linux/Bachelor/Partionnement/Partition_LVM/#liste-des-partitions","text":"1 partition swap 1 partition filesystem 3 partition LVM 3 partitions RAID Commande : fdisk /dev/sdb Pour acc\u00e8der au menu : m pour l'aide de la commande Cr\u00e9ation de la nouvelle table en GPT : g Cr\u00e9ation de la nouvelle partition : n -> Num\u00e9ro de partition -> Premier secteur -> Dernier secteur (possibilit\u00e9 de mettre un espace en K,M,G,T,P) Cr\u00e9ation du type de la partition : t -> Num\u00e9ro de la partition \u00e0 modifier -> Num\u00e9ro ou alias de type de partition","title":"Liste des partitions"},{"location":"Linux/Bachelor/Partionnement/Partition_LVM/#mise-en-place-de-sauvegarde","text":"","title":"Mise en place de sauvegarde"},{"location":"Linux/Bachelor/Partionnement/Partition_LVM/#mise-en-place-de-larchive-de-sauvegarde","text":"Sauvegarde : tar -cvz -f /home.tar.gz /home -> -c = Cr\u00e9ation d'archive -> -v = Verbose -> -z = Compression du fichier -> -f = Nom de l'archive (Toujours cette option en derni\u00e8re) Test de l'archive : tar -tf /home.tar.gz -> -t = pour tester l'archive -> -f = sp\u00e9cification du fichier (Toujours cette option en derni\u00e8re)","title":"Mise en place de l'archive de sauvegarde"},{"location":"Linux/Bachelor/Partionnement/Partition_LVM/#mise-en-place-du-nouveau-home","text":"","title":"Mise en place du nouveau /home"},{"location":"Linux/Bachelor/Partionnement/Partition_LVM/#vidange-du-repertoire","text":"Plusieurs fa\u00e7on de vider le r\u00e9pertoire /home : rm -rf /home ; mkdir /home ou rm -rf /home/* Attention \u00e0 ne pas mettre d'espace entre / et home car cela supprimerais tout le syst\u00e8me de fichier.","title":"Vidange du r\u00e9pertoire"},{"location":"Linux/Bachelor/Partionnement/Partition_LVM/#mise-en-place-du-formatage","text":"Formatage en EXT4 pour la partition FileSystem : mkfs.ext4 /dev/sdb2 Message d'erreur si la partition est d\u00e9j\u00e0 format\u00e9e Obtenir l'UUID d'une partition : lsblk -o uuid -n /dev/sdb2 Modification de fstab : nano /etc/fstab Montage de la partition et test si fstab est correct: sudo mount -av","title":"Mise en place du formatage"},{"location":"Linux/Bachelor/Partionnement/Partition_LVM/#restauration-de-larchive","text":"sudo tar -C / -xf /home.tar.gz ls -l /home Vigilance sur la taille du syst\u00e8me de fichier sinon l'extraction ne focntionnera pas.","title":"Restauration de l'archive"},{"location":"Linux/Bachelor/Partionnement/Partition_LVM/#lvm","text":"","title":"LVM"},{"location":"Linux/Bachelor/Partionnement/Partition_LVM/#commandes-lvm2","text":"Scan des partitions LVM : pvs alias => pvscan Cr\u00e9ation disques physiques pour les volumes logiques : pvcreate /dev/sdb3 /dev/sdb4 /dev/sdb5 alias => pvcreate /dev/sdb{3..5} Cr\u00e9ation d'un volume logique vgdata vgcreate vgdata /dev/sdb3 lsblk pour affihcer tout les volumes VG => Volume groupe L'extention de VG prends des volumes physiques sudo vgextend vgdata /dev/sdb4 LV => Logical Volume - pour utiliser les commandes \u00e0 partir de PV.... , on parle de volume physique. PV => Physical volume","title":"Commandes LVM2"},{"location":"Linux/Bachelor/Partionnement/Partition_LVM/#commandes-pour-afficher-les-volumes","text":"pvscan lvscan pvscan","title":"Commandes pour afficher les volumes"},{"location":"Linux/Bachelor/Partionnement/Partition_LVM/#suppression-des-volumes","text":"La suppression des volumes entraine la suppression des donn\u00e9es stock\u00e9es sur le logical volume D\u00e9montage des volumes en premier : unmount \\data Suppression du volume logique : lvremove /dev/rootvg/lvdata Suppression du volume groupe : vgremove /dev/rootvg Suppression des volumes physique : pvremove /dev/sdb3 /dev/sdb4 /dev/sdb5 Modification du fstab pour ne pas demarrer en mode recovery","title":"Suppression des volumes"},{"location":"Linux/Bachelor/Partionnement/RAID/","text":"RAID \u00b6 Installation \u00b6 Installation via ansible \u00b6 Installer ansible apt install ansible Installation de mdadm : ansible localhost -m package -a \"name=mdadm state=latest\" Cr\u00e9ation du raid \u00b6 Mise en place du raid avec 1 disque manaquant (d'o\u00f9 l'option missing ) : mdadm --create /dev/md0 --level 1 --raid-device 2 /dev/sdb6 missing Status du raid : mdadm --detail /dev/md0 Ajout d'un disque : mdadm --manage /dev/md0 --add /dev/sdb7 Disque HS : mdadm /dev/md0 --fail /dev/sdb6 Retirer le disque : mdadm /dev/md0 --remove /dev/sdb6 Montage de /data via ansible : ansible localhost -m mount -a \"src=/dev/md0 path=/data state=mounted\" Recherche dans la doc ansible-doc -l |grep -i --color filesystem Montage via l'UUID : ansible localhost -m mount -a \"src= '-U 07684c31-dd62-45be-82bb-a72cae950930 name=/data fstype=ext4 state=present'\" formatage avec l'UUID : ansible localhost -m filesystem -a \"dev=/dev/md0 fstype=ext4 state=present opts='-U 06b4a9c3-9487-4685-a672-d28b6df2b5f6'\" cible de anible playbook : ansible-playbook make-filesystem.yml","title":"RAID"},{"location":"Linux/Bachelor/Partionnement/RAID/#raid","text":"","title":"RAID"},{"location":"Linux/Bachelor/Partionnement/RAID/#installation","text":"","title":"Installation"},{"location":"Linux/Bachelor/Partionnement/RAID/#installation-via-ansible","text":"Installer ansible apt install ansible Installation de mdadm : ansible localhost -m package -a \"name=mdadm state=latest\"","title":"Installation via ansible"},{"location":"Linux/Bachelor/Partionnement/RAID/#creation-du-raid","text":"Mise en place du raid avec 1 disque manaquant (d'o\u00f9 l'option missing ) : mdadm --create /dev/md0 --level 1 --raid-device 2 /dev/sdb6 missing Status du raid : mdadm --detail /dev/md0 Ajout d'un disque : mdadm --manage /dev/md0 --add /dev/sdb7 Disque HS : mdadm /dev/md0 --fail /dev/sdb6 Retirer le disque : mdadm /dev/md0 --remove /dev/sdb6 Montage de /data via ansible : ansible localhost -m mount -a \"src=/dev/md0 path=/data state=mounted\" Recherche dans la doc ansible-doc -l |grep -i --color filesystem Montage via l'UUID : ansible localhost -m mount -a \"src= '-U 07684c31-dd62-45be-82bb-a72cae950930 name=/data fstype=ext4 state=present'\" formatage avec l'UUID : ansible localhost -m filesystem -a \"dev=/dev/md0 fstype=ext4 state=present opts='-U 06b4a9c3-9487-4685-a672-d28b6df2b5f6'\" cible de anible playbook : ansible-playbook make-filesystem.yml","title":"Cr\u00e9ation du raid"},{"location":"Linux/Bachelor/deploiement_ansible/Ansible/","text":"Deployment ansible \u00b6 G\u00e9n\u00e9ration des cl\u00e9s SSH \u00b6 G\u00e9n\u00e9ration de la cl\u00e9 : ssh-keygen Mise en place de la cl\u00e9 : ssh-copy-id 127.0.0.1 Demande une derni\u00e8re fois un mot de passe pour confirmer l'ajout Mise en place des privil\u00e8ges : nano /etc/sudoers # User privilege specification root ALL =( ALL:ALL ) NOPASSWD: ALL # Allow members of group sudo to execute any command %sudo ALL =( ALL:ALL ) NOPASSWD: ALL rajout de l'option NOPASSWD: Test ansible ping \u00b6 Mise en place de l'inventaire : echo \"debian-locale ansible_host=127.0.0.1\" >> inventaire.txt Dans le fichier ansible.cfg , ajout de redirecteurs : 1 2 3 4 [defaults] deprecation_warnings = False //enl\u00e8vement des warnings inventory = inventaire.txt // redirecteur Commande de ping : ansible all -m ping -o Boot d'une machine \u00b6 D\u00e9marrage \u00b6 MBR : Master boot record Sous windows on utilise pas le bootloader. On va utiliser le premier secteur bootable sur le disque. (pas de programme d'ammorcage) RO = Read only dans les options de d\u00e9marrage D\u00e9marrage du syst\u00e8me : Construction du syst\u00e8me de base D\u00e9marrage des services Lancements de taches dites \"supervis\u00e9e\" comme le lancement d'une session Systemctl status permet d'obtenir des informations globalement sur la machine et donne l'\u00e9tat g\u00e9n\u00e9ral de tout les services lanc\u00e9s avec ceux qui sont failed et running. Mise en place d'un /data avec /etc/systemd/system/data.mount : 1 2 3 4 5 6 7 8 [Unit] [Mount] What = UUID=915bcbeb-c17a-44e9-9e4f-beb8b79b724c Where = /data Type = ext4 Options = defaults Passage avec ansible \u00b6 Mise en place de l'invetaire en yml avec ansible-inventory -y --list (option -y pour yaml/yml) Modification du fichier ansible.cfg pour int\u00e9grer l'invetaire en yml 1 2 3 4 [defaults] deprecation_warnings = False //enl\u00e8vement des warnings inventory = inventaire.yml // redirecteur Timer \u00b6 sudo nano /etc/systemd/system/compteur.timer Modifier une conf \u00b6 systemctl edit xx.socket Logs \u00b6 Mise en place de rsyslog avec envoi de msg sur un autre serveur \u00b6 Installation du package rsyslog-relp avec apt. Modification de la conf de /etc/rsyslog.conf : module(load=\"omrelp\") module(load=\"immark\" interval=\"180\") local1.info :omrelp:IP:PORT envoi d'un msg sudo logger -p local1.info -t \"tag-du-jour\" \"J'ai r\u00e9ussi \" Mise en place avec Ansible \u00b6 Mise en place d'un dossier roles mkdir roles Cr\u00e9ation des fichier li\u00e9s au roles ansible-galaxy role init roles/rsyslog Fichier de configuration des tasks 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 --- # tasks file for roles/rsyslog - name: maj derni\u00e8re version apt: name: \"*\" state: latest - name: install Rsyslog package: name: rsyslog state: latest - name: install Rsyslog_relp package: name: rsyslog-relp state: latest - name: D\u00e9marrer et activer rsyslog ansible.builtin.service: name: \"{{ rsyslog_service }}\" state: started enabled: yes - name: Mise en place de la Config template: src: rsyslog_relp.j2 dest: \"/etc/rsyslog.d/rsyslog-relp.conf\" owner: root group: root mode: \"0644\" notify: restart-rsyslog Mise en place des des variables dans defaults : 1 2 relp_port: 0000 relp_server: 1.2.3.4 Configuration d'un template : 1 2 3 4 5 6 7 8 9 [Unit] Description= Mise en place de RELP [Service] module(load=\"omrelp\") module(load=\"immark\" interval=\"180\") *.info :omrelp:{{relp_server}}:{{relp_port}} Logs \u00b6 Plusieurs application de logs : journalctl rsyslog => Les configuruations de rsyslog permettent de pouvoir conserver des donn\u00e9es suivant le poids d'un fichier, le nombre de jours, ...","title":"Deployment ansible"},{"location":"Linux/Bachelor/deploiement_ansible/Ansible/#deployment-ansible","text":"","title":"Deployment ansible"},{"location":"Linux/Bachelor/deploiement_ansible/Ansible/#generation-des-cles-ssh","text":"G\u00e9n\u00e9ration de la cl\u00e9 : ssh-keygen Mise en place de la cl\u00e9 : ssh-copy-id 127.0.0.1 Demande une derni\u00e8re fois un mot de passe pour confirmer l'ajout Mise en place des privil\u00e8ges : nano /etc/sudoers # User privilege specification root ALL =( ALL:ALL ) NOPASSWD: ALL # Allow members of group sudo to execute any command %sudo ALL =( ALL:ALL ) NOPASSWD: ALL rajout de l'option NOPASSWD:","title":"G\u00e9n\u00e9ration des cl\u00e9s SSH"},{"location":"Linux/Bachelor/deploiement_ansible/Ansible/#test-ansible-ping","text":"Mise en place de l'inventaire : echo \"debian-locale ansible_host=127.0.0.1\" >> inventaire.txt Dans le fichier ansible.cfg , ajout de redirecteurs : 1 2 3 4 [defaults] deprecation_warnings = False //enl\u00e8vement des warnings inventory = inventaire.txt // redirecteur Commande de ping : ansible all -m ping -o","title":"Test ansible ping"},{"location":"Linux/Bachelor/deploiement_ansible/Ansible/#boot-dune-machine","text":"","title":"Boot d'une machine"},{"location":"Linux/Bachelor/deploiement_ansible/Ansible/#demarrage","text":"MBR : Master boot record Sous windows on utilise pas le bootloader. On va utiliser le premier secteur bootable sur le disque. (pas de programme d'ammorcage) RO = Read only dans les options de d\u00e9marrage D\u00e9marrage du syst\u00e8me : Construction du syst\u00e8me de base D\u00e9marrage des services Lancements de taches dites \"supervis\u00e9e\" comme le lancement d'une session Systemctl status permet d'obtenir des informations globalement sur la machine et donne l'\u00e9tat g\u00e9n\u00e9ral de tout les services lanc\u00e9s avec ceux qui sont failed et running. Mise en place d'un /data avec /etc/systemd/system/data.mount : 1 2 3 4 5 6 7 8 [Unit] [Mount] What = UUID=915bcbeb-c17a-44e9-9e4f-beb8b79b724c Where = /data Type = ext4 Options = defaults","title":"D\u00e9marrage"},{"location":"Linux/Bachelor/deploiement_ansible/Ansible/#passage-avec-ansible","text":"Mise en place de l'invetaire en yml avec ansible-inventory -y --list (option -y pour yaml/yml) Modification du fichier ansible.cfg pour int\u00e9grer l'invetaire en yml 1 2 3 4 [defaults] deprecation_warnings = False //enl\u00e8vement des warnings inventory = inventaire.yml // redirecteur","title":"Passage avec ansible"},{"location":"Linux/Bachelor/deploiement_ansible/Ansible/#timer","text":"sudo nano /etc/systemd/system/compteur.timer","title":"Timer"},{"location":"Linux/Bachelor/deploiement_ansible/Ansible/#modifier-une-conf","text":"systemctl edit xx.socket","title":"Modifier une conf"},{"location":"Linux/Bachelor/deploiement_ansible/Ansible/#logs","text":"","title":"Logs"},{"location":"Linux/Bachelor/deploiement_ansible/Ansible/#mise-en-place-de-rsyslog-avec-envoi-de-msg-sur-un-autre-serveur","text":"Installation du package rsyslog-relp avec apt. Modification de la conf de /etc/rsyslog.conf : module(load=\"omrelp\") module(load=\"immark\" interval=\"180\") local1.info :omrelp:IP:PORT envoi d'un msg sudo logger -p local1.info -t \"tag-du-jour\" \"J'ai r\u00e9ussi \"","title":"Mise en place de rsyslog avec envoi de msg sur un autre serveur"},{"location":"Linux/Bachelor/deploiement_ansible/Ansible/#mise-en-place-avec-ansible","text":"Mise en place d'un dossier roles mkdir roles Cr\u00e9ation des fichier li\u00e9s au roles ansible-galaxy role init roles/rsyslog Fichier de configuration des tasks 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 --- # tasks file for roles/rsyslog - name: maj derni\u00e8re version apt: name: \"*\" state: latest - name: install Rsyslog package: name: rsyslog state: latest - name: install Rsyslog_relp package: name: rsyslog-relp state: latest - name: D\u00e9marrer et activer rsyslog ansible.builtin.service: name: \"{{ rsyslog_service }}\" state: started enabled: yes - name: Mise en place de la Config template: src: rsyslog_relp.j2 dest: \"/etc/rsyslog.d/rsyslog-relp.conf\" owner: root group: root mode: \"0644\" notify: restart-rsyslog Mise en place des des variables dans defaults : 1 2 relp_port: 0000 relp_server: 1.2.3.4 Configuration d'un template : 1 2 3 4 5 6 7 8 9 [Unit] Description= Mise en place de RELP [Service] module(load=\"omrelp\") module(load=\"immark\" interval=\"180\") *.info :omrelp:{{relp_server}}:{{relp_port}}","title":"Mise en place avec Ansible"},{"location":"Linux/Bachelor/deploiement_ansible/Ansible/#logs_1","text":"Plusieurs application de logs : journalctl rsyslog => Les configuruations de rsyslog permettent de pouvoir conserver des donn\u00e9es suivant le poids d'un fichier, le nombre de jours, ...","title":"Logs"},{"location":"Linux/Master/Administration%20avanc%C3%A9e/Installation%20avanc%C3%A9e%20CENTOS%209/Installation/","text":"Installation de Centos \u00b6 kickstart (redhat) = methode d'installation qui permet de faire passer les questions d'installation utilisation avec la modification de l'ecran d'installation Proc\u00e9dure \u00b6 installation manuellement R\u00e9cuparation du fichier /rot/anaconda-ks.cfg --> /srv/ks.cfg Mettre le fichier \u00e0 disposition avec un client http = conteneur docker Installation nouvelle VM avec l'utilisation du fichier KS inst.ks=https://...../ks.cfg si probl\u00e8me r\u00e9solution : inst.resolution=1080x1920 Cahier des charges \u00b6 3 partitions : /boot : 500Mo, format ext2 Swap : 1Go Syst\u00e8me de fichier racine (/), ext4, 3 Go, mais sur du LVM, volume groupe = rootvg, volume logique = rootlv Rappels \u00b6 LVM : Logical Volume Manager PV : Physical volume VG : Volume Volume (prends l'int\u00e9gralit\u00e9 des PV) LG : Logical Volume (Volumes logiques cr\u00e9es sur le VG et permet d'utiliser des systemes de fichier diff\u00e9rents) exemples : LV1 /leo (ext4) LV2 /data1 (EXT3) LV3 /data2 (EXT4) Sch\u00e9ma de LVM Modification du nom de la machine Dans le fichier /etc/hostname , on peux changer le nom ou avec la commande hostname set-hostname nomdelamachine Installation CENTOS9 \u00b6 Choix du clavier Mise en place du partitionnement Installation docker \u00b6 Rappel sur docker Site de documentation docker : https://docs.docker.com Selon la firme de recherche sur l'industrie 451 Research, \u00ab Docker est un outil qui peut empaqueter une application et ses d\u00e9pendances dans un conteneur isol\u00e9, qui pourra \u00eatre ex\u00e9cut\u00e9 sur n'importe quel serveur \u00bb. Il ne s'agit pas de virtualisation, mais de conteneurisation, une forme plus l\u00e9g\u00e8re qui s'appuie sur certaines parties de la machine h\u00f4te pour son fonctionnement. Copier le fichier ananconda cp anaconda-ks.cfg /srv/kickstart/ks.cfg installer docker avec CURL curl -sSL https://get.docker.com | sudo bash ou sinon : curl -sSl -o get-docker.sh https://get.docker.com controle : get-docker.sh execution : bash get-docker.sh Demarrage et automatisation de docker au boot systemctl enable --now docker.service D\u00e9marrage d'un conteneur de serveur web Apache - > docker container run -d --name websrv --publish 80:80 --volume /srv/kickstart:/usr/local/apache2/htdocs httpd Ngnix - > docker container run -d --name websrv --publish 80:80 --volume /srv/kickstart:/usr/share/nginx/html nginx Verficiation des user dans docker docker container top websrv Mise \u00e0 jour des permissions chmod 644 /srv/kickstart/ks.cfg Installation de micro curl https://getmic.ro | bash mv micro /usr/local/bin ln -s /usr/local/bin/micro /usr/local/sbin/micro Changement pour enlever le mot de passe de user sed -i -e '/ %wheel/s, ,# ,' -e '/^# %wheel.*NOPASSWD/s,^# ,,' /etc/sudoers Le -i prend en compte pour l'execution Mise en place de l'anaconda pour installer d'autres machines \u00b6 Cahier des charges \u00b6 \"micro\" doit etre install\u00e9 dans /usr/local/bin Lien symbolique dans /usr/local/bin User n'a pas \u00e0 s'identifier pour sudo ... No PASSWD On ne peut se connecter en trannt que \"user\" avec une cl\u00e9 punlique definie ici Extention du volume groupe \u00b6 Cr\u00e9ation du volume dans le sdb pvcreate /dev/sdb Extentention du volume groupe sur le nouveau disque vgextend /dev/rootvg /dev/sdb Extention du volume logique lvextend -l 100%FREE -r /dev/rootvg/rootlv modification du SSH \u00b6 Cr\u00e9ation des dossier ssh (/.ssh/authorized_keys) .ssh avec les droits 700 authorized_keys avec les droits 600 Exemple de fichier anaconda : # Generated by Anaconda 34.25.2.2 # Generated by pykickstart v3.32 #version=RHEL9 # Use graphical install graphical repo --name = \"AppStream\" --baseurl=file:///run/install/sources/mount-0000-cdrom/AppStream %addon com_redhat_kdump --enable --reserve-mb = 'auto' %end # Keyboard layouts keyboard --xlayouts = 'fr (oss)' # System language lang fr_FR.UTF-8 # Network information network --hostname = LG-stream9-1.local # Use CDROM installation media cdrom %packages @^minimal-environment %end # Run the Setup Agent on first boot firstboot --enable # Generated using Blivet version 3.6.0 ignoredisk --only-use = sda # Partition clearing information clearpart --none --initlabel # Disk partitioning information part pv.1220 --fstype = \"lvmpv\" --ondisk=sda --size=7690 part /boot/efi --fstype = \"efi\" --ondisk=sda --size=1024 --fsoptions=\"umask=0077,shortname=winnt\" part swap --fstype = \"swap\" --ondisk=sda --size=1024 part /boot --fstype = \"ext2\" --ondisk=sda --size=500 volgroup rootvg --pesize = 4096 pv.1220 logvol / --fstype = \"ext4\" --size=3072 --name=rootlv --vgname=rootvg # System timezone timezone Europe/Paris --utc # Root password rootpw --iscrypted --allow-ssh $6$2y5hbbXM4dYt4c0v$usoQguNqD5QySTU5sbwDHMPuHU4tBs0mwPqUU574s83Vr1Tz5aJ//zIwtIEPdqsaTwpiBDQwnT.LQ/9PMC95o. user --groups = wheel --name=user --password=$6$IW2fEdwd1zcdKMCW$ecnGuYPR.PvRDy354ttoEJbnYuFHJm9HpAA6ZT2sHF2sqGEsHWnvnAYdvr6EdVFipZKkjchbaQOMyRERyZAR91 --iscrypted --gecos=\"user\" Debian \u00b6 Preseed (debian) = methode d'installation qui permet de faire passer les questions d'installation","title":"Installation de Centos"},{"location":"Linux/Master/Administration%20avanc%C3%A9e/Installation%20avanc%C3%A9e%20CENTOS%209/Installation/#installation-de-centos","text":"kickstart (redhat) = methode d'installation qui permet de faire passer les questions d'installation utilisation avec la modification de l'ecran d'installation","title":"Installation de Centos"},{"location":"Linux/Master/Administration%20avanc%C3%A9e/Installation%20avanc%C3%A9e%20CENTOS%209/Installation/#procedure","text":"installation manuellement R\u00e9cuparation du fichier /rot/anaconda-ks.cfg --> /srv/ks.cfg Mettre le fichier \u00e0 disposition avec un client http = conteneur docker Installation nouvelle VM avec l'utilisation du fichier KS inst.ks=https://...../ks.cfg si probl\u00e8me r\u00e9solution : inst.resolution=1080x1920","title":"Proc\u00e9dure"},{"location":"Linux/Master/Administration%20avanc%C3%A9e/Installation%20avanc%C3%A9e%20CENTOS%209/Installation/#cahier-des-charges","text":"3 partitions : /boot : 500Mo, format ext2 Swap : 1Go Syst\u00e8me de fichier racine (/), ext4, 3 Go, mais sur du LVM, volume groupe = rootvg, volume logique = rootlv","title":"Cahier des charges"},{"location":"Linux/Master/Administration%20avanc%C3%A9e/Installation%20avanc%C3%A9e%20CENTOS%209/Installation/#rappels","text":"LVM : Logical Volume Manager PV : Physical volume VG : Volume Volume (prends l'int\u00e9gralit\u00e9 des PV) LG : Logical Volume (Volumes logiques cr\u00e9es sur le VG et permet d'utiliser des systemes de fichier diff\u00e9rents) exemples : LV1 /leo (ext4) LV2 /data1 (EXT3) LV3 /data2 (EXT4) Sch\u00e9ma de LVM Modification du nom de la machine Dans le fichier /etc/hostname , on peux changer le nom ou avec la commande hostname set-hostname nomdelamachine","title":"Rappels"},{"location":"Linux/Master/Administration%20avanc%C3%A9e/Installation%20avanc%C3%A9e%20CENTOS%209/Installation/#installation-centos9","text":"Choix du clavier Mise en place du partitionnement","title":"Installation CENTOS9"},{"location":"Linux/Master/Administration%20avanc%C3%A9e/Installation%20avanc%C3%A9e%20CENTOS%209/Installation/#installation-docker","text":"Rappel sur docker Site de documentation docker : https://docs.docker.com Selon la firme de recherche sur l'industrie 451 Research, \u00ab Docker est un outil qui peut empaqueter une application et ses d\u00e9pendances dans un conteneur isol\u00e9, qui pourra \u00eatre ex\u00e9cut\u00e9 sur n'importe quel serveur \u00bb. Il ne s'agit pas de virtualisation, mais de conteneurisation, une forme plus l\u00e9g\u00e8re qui s'appuie sur certaines parties de la machine h\u00f4te pour son fonctionnement. Copier le fichier ananconda cp anaconda-ks.cfg /srv/kickstart/ks.cfg installer docker avec CURL curl -sSL https://get.docker.com | sudo bash ou sinon : curl -sSl -o get-docker.sh https://get.docker.com controle : get-docker.sh execution : bash get-docker.sh Demarrage et automatisation de docker au boot systemctl enable --now docker.service D\u00e9marrage d'un conteneur de serveur web Apache - > docker container run -d --name websrv --publish 80:80 --volume /srv/kickstart:/usr/local/apache2/htdocs httpd Ngnix - > docker container run -d --name websrv --publish 80:80 --volume /srv/kickstart:/usr/share/nginx/html nginx Verficiation des user dans docker docker container top websrv Mise \u00e0 jour des permissions chmod 644 /srv/kickstart/ks.cfg Installation de micro curl https://getmic.ro | bash mv micro /usr/local/bin ln -s /usr/local/bin/micro /usr/local/sbin/micro Changement pour enlever le mot de passe de user sed -i -e '/ %wheel/s, ,# ,' -e '/^# %wheel.*NOPASSWD/s,^# ,,' /etc/sudoers Le -i prend en compte pour l'execution","title":"Installation docker"},{"location":"Linux/Master/Administration%20avanc%C3%A9e/Installation%20avanc%C3%A9e%20CENTOS%209/Installation/#mise-en-place-de-lanaconda-pour-installer-dautres-machines","text":"","title":"Mise en place de l'anaconda pour installer d'autres machines"},{"location":"Linux/Master/Administration%20avanc%C3%A9e/Installation%20avanc%C3%A9e%20CENTOS%209/Installation/#cahier-des-charges_1","text":"\"micro\" doit etre install\u00e9 dans /usr/local/bin Lien symbolique dans /usr/local/bin User n'a pas \u00e0 s'identifier pour sudo ... No PASSWD On ne peut se connecter en trannt que \"user\" avec une cl\u00e9 punlique definie ici","title":"Cahier des charges"},{"location":"Linux/Master/Administration%20avanc%C3%A9e/Installation%20avanc%C3%A9e%20CENTOS%209/Installation/#extention-du-volume-groupe","text":"Cr\u00e9ation du volume dans le sdb pvcreate /dev/sdb Extentention du volume groupe sur le nouveau disque vgextend /dev/rootvg /dev/sdb Extention du volume logique lvextend -l 100%FREE -r /dev/rootvg/rootlv","title":"Extention du volume groupe"},{"location":"Linux/Master/Administration%20avanc%C3%A9e/Installation%20avanc%C3%A9e%20CENTOS%209/Installation/#modification-du-ssh","text":"Cr\u00e9ation des dossier ssh (/.ssh/authorized_keys) .ssh avec les droits 700 authorized_keys avec les droits 600 Exemple de fichier anaconda : # Generated by Anaconda 34.25.2.2 # Generated by pykickstart v3.32 #version=RHEL9 # Use graphical install graphical repo --name = \"AppStream\" --baseurl=file:///run/install/sources/mount-0000-cdrom/AppStream %addon com_redhat_kdump --enable --reserve-mb = 'auto' %end # Keyboard layouts keyboard --xlayouts = 'fr (oss)' # System language lang fr_FR.UTF-8 # Network information network --hostname = LG-stream9-1.local # Use CDROM installation media cdrom %packages @^minimal-environment %end # Run the Setup Agent on first boot firstboot --enable # Generated using Blivet version 3.6.0 ignoredisk --only-use = sda # Partition clearing information clearpart --none --initlabel # Disk partitioning information part pv.1220 --fstype = \"lvmpv\" --ondisk=sda --size=7690 part /boot/efi --fstype = \"efi\" --ondisk=sda --size=1024 --fsoptions=\"umask=0077,shortname=winnt\" part swap --fstype = \"swap\" --ondisk=sda --size=1024 part /boot --fstype = \"ext2\" --ondisk=sda --size=500 volgroup rootvg --pesize = 4096 pv.1220 logvol / --fstype = \"ext4\" --size=3072 --name=rootlv --vgname=rootvg # System timezone timezone Europe/Paris --utc # Root password rootpw --iscrypted --allow-ssh $6$2y5hbbXM4dYt4c0v$usoQguNqD5QySTU5sbwDHMPuHU4tBs0mwPqUU574s83Vr1Tz5aJ//zIwtIEPdqsaTwpiBDQwnT.LQ/9PMC95o. user --groups = wheel --name=user --password=$6$IW2fEdwd1zcdKMCW$ecnGuYPR.PvRDy354ttoEJbnYuFHJm9HpAA6ZT2sHF2sqGEsHWnvnAYdvr6EdVFipZKkjchbaQOMyRERyZAR91 --iscrypted --gecos=\"user\"","title":"modification du SSH"},{"location":"Linux/Master/Administration%20avanc%C3%A9e/Installation%20avanc%C3%A9e%20CENTOS%209/Installation/#debian","text":"Preseed (debian) = methode d'installation qui permet de faire passer les questions d'installation","title":"Debian"},{"location":"Linux/Master/Administration%20avanc%C3%A9e/RPM-YUM/RPM_et_yum/","text":"Programme du jour \u00b6 Manipuler rpm et yum Compiler un logiciel libre (\u00e0 partir des sources) Cr\u00e9er un pakcage RPM Cr\u00e9er un d\u00e9p\u00f4t pour mettre \u00e0 dispo mes packages D\u00e9clarer mon d\u00e9p\u00f4t sur les pc clients Manipuler rpm et yum \u00b6 RPM \u00b6 RPM : commande pour manipuler des package et savoir les informations sur ceux-ci Options : -q query => Information de version -qi => descriptif sur le paquage -qa => liste de tout les paquages install\u00e9s -ql => liste des fihcier install\u00e9 le paquet -qc => Liste des fihciers de config -qd => Liste des fichiers de docs -qf => savoir quel fichier \u00e0 install\u00e9 le package --requires (-R) => savoir les paquages dont il a besoin --provides (-P) => d\u00e9pendances pour qui ? --scripts => fichier spec avec les scripts de d\u00e9sinstall, install, preinstall YUM \u00b6 Yum : surcouche de rpm DNF = reprise de yum qui etait sur python 2.3 Options : install update upgrade (attention cela peut remplacer des paquets) remove list (liste tout les paquets) search (liste les paquets avec par exemple http dans les descriptions) provides Extraire une archive test de l'archive tar -tvzf ARCHIVE | tail options : - t pour tester ou lister (--list) - v versbose - f file - z compression - x pour extraire Le tail est utilis\u00e9 pour etre sur que tout les fichiers soient dans le meme dossier racine Extraction tar -xvzf ARCHIVE Verification des signatures GPG : \u00b6 Importer la cl\u00e9 avec WGET : wget https://download.samba.org/pub/rsync/src/rsync-3.2.7.tar.gz.asc Verification de la signature : gpg --verify rsync-3.2.7.tar.gz.asc Copie de la cl\u00e9 pour enregistrer la cl\u00e9 via un serveur de cl\u00e9s gpg --receive-keys 0048C8B026D4C96F0E589C2F6C859FB14B96A8C5 V\u00e9rifier \u00e0 nouveau la cl\u00e9 Paquet rsync \u00b6 Erreurs lors de la configuration Installation de GCC compilateur C dnf -y install gcc Nouvelle erreur lors de la configuration : On cherche les paquets openssl : yum provides \"*/openssl/md4.h\" On trouve ensuite les paquets openssl-devel dnf -y install gcc openssl-devel On retrouve plusieurs erreurs suppl\u00e9mentaires zstd lz4 xxhash Pour xxhash on va sur le site https://pkgs.org et on cherche un paquet qui se rapporte xxhash-devel On trouve le repo CRB : Commande compl\u00e8te avec tout les arguments : dnf --enablerepo=\"crb\" -y install gcc openssl-devel lz4-devel libzstd-devel xxhash-devel On retrouve ensuite le code retour avec la configuration termin\u00e9e : epel-release permet d'aller chercher des paquets qui ne sont pas soutenu par REDHAT mais par une autre communaut\u00e9 comme la communaut\u00e9 FEDORA Petite astuce pour savoir le nombre de coeur : grep -c ^processor /proc/cpuinfo RPM build \u00b6 Package rsync (non vide) \u00b6 3 options : b pour partir d'un fichier spec r pour partir d'un fichier sources package t pour partir d\"un tarball On build avec RPM : rpmbuild -tb rsync-3.y.z.tar.gz Exemple du fichier SPEC modifi\u00e9 : Attention, le %files n'accepte pas les doubles fichiers sur la m\u00eame ligne : RPM -ivh (v pour verbose ; h pour la barre de progressions) Package rsync (vide) \u00b6 Installation de rpmdev : dnf -y install rpmdevtools Cr\u00e9ation du fichier (--output pour set le nom et l'endoit du fichier) : rpmdev-newspec --type minimal --output rpmbuild/SPECS/vide.spec Modification du fichier SPEC : Cr\u00e9ation d'un repo \u00b6 Installation de la commande createrepo : dnf install creatrepo_c Installation du repo : Createrepo rpmbuild/RPMS Lancement d'un conteneur docker en restart always : docker container run -d --name repo --publish 8001:80 --volume /root/rpmbuild/RPMS/:/usr/local/apache2/htdocs --restart always httpd Cr\u00e9er le fichier /etc/yum.repos.d/mondepot.repo 1 2 3 [mondepot] name = Mon beau d\u00e9pot baseurl = http://IP:8001","title":"Programme du jour"},{"location":"Linux/Master/Administration%20avanc%C3%A9e/RPM-YUM/RPM_et_yum/#programme-du-jour","text":"Manipuler rpm et yum Compiler un logiciel libre (\u00e0 partir des sources) Cr\u00e9er un pakcage RPM Cr\u00e9er un d\u00e9p\u00f4t pour mettre \u00e0 dispo mes packages D\u00e9clarer mon d\u00e9p\u00f4t sur les pc clients","title":"Programme du jour"},{"location":"Linux/Master/Administration%20avanc%C3%A9e/RPM-YUM/RPM_et_yum/#manipuler-rpm-et-yum","text":"","title":"Manipuler rpm et yum"},{"location":"Linux/Master/Administration%20avanc%C3%A9e/RPM-YUM/RPM_et_yum/#rpm","text":"RPM : commande pour manipuler des package et savoir les informations sur ceux-ci Options : -q query => Information de version -qi => descriptif sur le paquage -qa => liste de tout les paquages install\u00e9s -ql => liste des fihcier install\u00e9 le paquet -qc => Liste des fihciers de config -qd => Liste des fichiers de docs -qf => savoir quel fichier \u00e0 install\u00e9 le package --requires (-R) => savoir les paquages dont il a besoin --provides (-P) => d\u00e9pendances pour qui ? --scripts => fichier spec avec les scripts de d\u00e9sinstall, install, preinstall","title":"RPM"},{"location":"Linux/Master/Administration%20avanc%C3%A9e/RPM-YUM/RPM_et_yum/#yum","text":"Yum : surcouche de rpm DNF = reprise de yum qui etait sur python 2.3 Options : install update upgrade (attention cela peut remplacer des paquets) remove list (liste tout les paquets) search (liste les paquets avec par exemple http dans les descriptions) provides Extraire une archive test de l'archive tar -tvzf ARCHIVE | tail options : - t pour tester ou lister (--list) - v versbose - f file - z compression - x pour extraire Le tail est utilis\u00e9 pour etre sur que tout les fichiers soient dans le meme dossier racine Extraction tar -xvzf ARCHIVE","title":"YUM"},{"location":"Linux/Master/Administration%20avanc%C3%A9e/RPM-YUM/RPM_et_yum/#verification-des-signatures-gpg","text":"Importer la cl\u00e9 avec WGET : wget https://download.samba.org/pub/rsync/src/rsync-3.2.7.tar.gz.asc Verification de la signature : gpg --verify rsync-3.2.7.tar.gz.asc Copie de la cl\u00e9 pour enregistrer la cl\u00e9 via un serveur de cl\u00e9s gpg --receive-keys 0048C8B026D4C96F0E589C2F6C859FB14B96A8C5 V\u00e9rifier \u00e0 nouveau la cl\u00e9","title":"Verification des signatures GPG :"},{"location":"Linux/Master/Administration%20avanc%C3%A9e/RPM-YUM/RPM_et_yum/#paquet-rsync","text":"Erreurs lors de la configuration Installation de GCC compilateur C dnf -y install gcc Nouvelle erreur lors de la configuration : On cherche les paquets openssl : yum provides \"*/openssl/md4.h\" On trouve ensuite les paquets openssl-devel dnf -y install gcc openssl-devel On retrouve plusieurs erreurs suppl\u00e9mentaires zstd lz4 xxhash Pour xxhash on va sur le site https://pkgs.org et on cherche un paquet qui se rapporte xxhash-devel On trouve le repo CRB : Commande compl\u00e8te avec tout les arguments : dnf --enablerepo=\"crb\" -y install gcc openssl-devel lz4-devel libzstd-devel xxhash-devel On retrouve ensuite le code retour avec la configuration termin\u00e9e : epel-release permet d'aller chercher des paquets qui ne sont pas soutenu par REDHAT mais par une autre communaut\u00e9 comme la communaut\u00e9 FEDORA Petite astuce pour savoir le nombre de coeur : grep -c ^processor /proc/cpuinfo","title":"Paquet rsync"},{"location":"Linux/Master/Administration%20avanc%C3%A9e/RPM-YUM/RPM_et_yum/#rpm-build","text":"","title":"RPM build"},{"location":"Linux/Master/Administration%20avanc%C3%A9e/RPM-YUM/RPM_et_yum/#package-rsync-non-vide","text":"3 options : b pour partir d'un fichier spec r pour partir d'un fichier sources package t pour partir d\"un tarball On build avec RPM : rpmbuild -tb rsync-3.y.z.tar.gz Exemple du fichier SPEC modifi\u00e9 : Attention, le %files n'accepte pas les doubles fichiers sur la m\u00eame ligne : RPM -ivh (v pour verbose ; h pour la barre de progressions)","title":"Package rsync (non vide)"},{"location":"Linux/Master/Administration%20avanc%C3%A9e/RPM-YUM/RPM_et_yum/#package-rsync-vide","text":"Installation de rpmdev : dnf -y install rpmdevtools Cr\u00e9ation du fichier (--output pour set le nom et l'endoit du fichier) : rpmdev-newspec --type minimal --output rpmbuild/SPECS/vide.spec Modification du fichier SPEC :","title":"Package rsync (vide)"},{"location":"Linux/Master/Administration%20avanc%C3%A9e/RPM-YUM/RPM_et_yum/#creation-dun-repo","text":"Installation de la commande createrepo : dnf install creatrepo_c Installation du repo : Createrepo rpmbuild/RPMS Lancement d'un conteneur docker en restart always : docker container run -d --name repo --publish 8001:80 --volume /root/rpmbuild/RPMS/:/usr/local/apache2/htdocs --restart always httpd Cr\u00e9er le fichier /etc/yum.repos.d/mondepot.repo 1 2 3 [mondepot] name = Mon beau d\u00e9pot baseurl = http://IP:8001","title":"Cr\u00e9ation d'un repo"},{"location":"Linux/Master/Administration%20r%C3%A9seau/DNS/","text":"Les DNS \u00b6 Objectifs D\u00e9clarer le serveur DNS Etre un salve d'un autre serveur Pour la r\u00e9solution de noms DNS, la commande getent est pr\u00e9sente sur les syst\u00e8mes linux. SPF Le protocole Simple Mail Transfer Protocol (SMTP) utilis\u00e9 pour le transfert du courrier \u00e9lectronique sur Internet ne pr\u00e9voit pas de m\u00e9canisme de v\u00e9rification de l'exp\u00e9diteur, c'est-\u00e0-dire qu'il est facile d'envoyer un courrier avec une adresse d'exp\u00e9diteur factice, voire usurp\u00e9e. SPF vise \u00e0 r\u00e9duire les possibilit\u00e9s d'usurpation en publiant, dans le DNS, un enregistrement (de type TXT)3 indiquant quelles adresses IP sont autoris\u00e9es ou interdites \u00e0 envoyer du courrier pour le domaine consid\u00e9r\u00e9. DKIM DKIM (DomainKeys Identified Mail) est une norme d'authentification fiable du nom de domaine de l'exp\u00e9diteur d'un courrier \u00e9lectronique. Elle constitue une protection efficace contre le spam et l'hame\u00e7onnage. En effet, DKIM fonctionne par signature cryptographique du corps du message ou d'une partie de celui-ci et d'une partie de ses en-t\u00eates. Une signature DKIM v\u00e9rifie donc l'authenticit\u00e9 du domaine exp\u00e9diteur et garantit l'int\u00e9grit\u00e9 du message. DKIM intervient au niveau de la couche application du mod\u00e8le OSI, ainsi il constitue une double protection pour des protocoles de messagerie \u00e9lectronique tels que SMTP, IMAP et POP en plus de l'utilisation de ces protocoles en mode s\u00e9curis\u00e9 (POPS, IMAPS). Bind \u00b6 Installation de bind : dnf install -y bind Observation des nouvelles installations : rpm -ql bind | grep /etc/ Mise en place de l'ecoute sur l'ip \"publique\" dans /etc/named.conf : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 options { listen-on port 53 { 127 .0.0.1 ; 10 .56.126.223 } ; listen-on-v6 port 53 { ::1 ; } ; directory \"/var/named\" ; dump-file \"/var/named/data/cache_dump.db\" ; statistics-file \"/var/named/data/named_stats.txt\" ; memstatistics-file \"/var/named/data/named_mem_stats.txt\" ; secroots-file \"/var/named/data/named.secroots\" ; recursing-file \"/var/named/data/named.recursing\" ; allow-query { localhost ; } ; /* - If you are building an AUTHORITATIVE DNS server, do NOT enable recursion. - If you are building a RECURSIVE ( caching ) DNS server, you need to enable recursion. - If your recursive DNS server has a public IP address, you MUST enable access control to limit queries to your legitimate users. Failing to do so will cause your server to become part of large scale DNS amplification attacks. Implementing BCP38 within your network would greatly reduce such attack surface */ recursion yes ; dnssec-validation yes ; managed-keys-directory \"/var/named/dynamic\" ; geoip-directory \"/usr/share/GeoIP\" ; pid-file \"/run/named/named.pid\" ; session-keyfile \"/run/named/session.key\" ; /* https://fedoraproject.org/wiki/Changes/CryptoPolicy */ include \"/etc/crypto-policies/back-ends/bind.config\" ; } ; logging { channel default_debug { file \"data/named.run\" ; severity dynamic ; } ; } ; zone \".\" IN { type hint ; file \"named.ca\" ; } ; include \"/etc/named.rfc1912.zones\" ; include \"/etc/named.root.key\" ; Ajout d'une ACL que l'on pourra r\u00e9utiliser : 1 2 3 acl mes-clients { 10 .56.126.0/24 ; } ; Ajout de mes-clients sur la ligne suivante: allow-query { localhost ; mes-clients ; } ; Ajout d'une zone avec la cr\u00e9ation d'un fichier dans /etc/named/mes-domaines.conf : zone \"dom3.local. \" { type master ; file \"dynamic/dom3.local.zone\" ; } ; Pour que le fichier soit lu par named, on lui indique le chemin complet dans sont fichier de configuration etc/named.conf : include \"/etc/named/mes-domaines.conf\" ; Configuration de la zone dans /var/named/dynamic/dom3.local.zone : $TTL 3600 @ IN SOA dns1 leoguilloux.yahoo.com. ( 2023021401 ; Serial 3600 ; Refresh 1800 ; Retry 604800 ; Expire 86400 ) ; Minimum TTL @ NS dns1 dns1 A 10 .56.126.223 Ports ouverts sur une machine ss -plntu Pour que une machine cliente puisse ping l'exterieur, on lui met une route par d\u00e9faut passant par la gateway. Sur le routeur, on lui change l'interface dans la zone external : firewall-cmd --zone = external --add-interface = eth2 --permanent On red\u00e9marre le service avec : systemctl restart firewalld","title":"Les DNS"},{"location":"Linux/Master/Administration%20r%C3%A9seau/DNS/#les-dns","text":"Objectifs D\u00e9clarer le serveur DNS Etre un salve d'un autre serveur Pour la r\u00e9solution de noms DNS, la commande getent est pr\u00e9sente sur les syst\u00e8mes linux. SPF Le protocole Simple Mail Transfer Protocol (SMTP) utilis\u00e9 pour le transfert du courrier \u00e9lectronique sur Internet ne pr\u00e9voit pas de m\u00e9canisme de v\u00e9rification de l'exp\u00e9diteur, c'est-\u00e0-dire qu'il est facile d'envoyer un courrier avec une adresse d'exp\u00e9diteur factice, voire usurp\u00e9e. SPF vise \u00e0 r\u00e9duire les possibilit\u00e9s d'usurpation en publiant, dans le DNS, un enregistrement (de type TXT)3 indiquant quelles adresses IP sont autoris\u00e9es ou interdites \u00e0 envoyer du courrier pour le domaine consid\u00e9r\u00e9. DKIM DKIM (DomainKeys Identified Mail) est une norme d'authentification fiable du nom de domaine de l'exp\u00e9diteur d'un courrier \u00e9lectronique. Elle constitue une protection efficace contre le spam et l'hame\u00e7onnage. En effet, DKIM fonctionne par signature cryptographique du corps du message ou d'une partie de celui-ci et d'une partie de ses en-t\u00eates. Une signature DKIM v\u00e9rifie donc l'authenticit\u00e9 du domaine exp\u00e9diteur et garantit l'int\u00e9grit\u00e9 du message. DKIM intervient au niveau de la couche application du mod\u00e8le OSI, ainsi il constitue une double protection pour des protocoles de messagerie \u00e9lectronique tels que SMTP, IMAP et POP en plus de l'utilisation de ces protocoles en mode s\u00e9curis\u00e9 (POPS, IMAPS).","title":"Les DNS"},{"location":"Linux/Master/Administration%20r%C3%A9seau/DNS/#bind","text":"Installation de bind : dnf install -y bind Observation des nouvelles installations : rpm -ql bind | grep /etc/ Mise en place de l'ecoute sur l'ip \"publique\" dans /etc/named.conf : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 options { listen-on port 53 { 127 .0.0.1 ; 10 .56.126.223 } ; listen-on-v6 port 53 { ::1 ; } ; directory \"/var/named\" ; dump-file \"/var/named/data/cache_dump.db\" ; statistics-file \"/var/named/data/named_stats.txt\" ; memstatistics-file \"/var/named/data/named_mem_stats.txt\" ; secroots-file \"/var/named/data/named.secroots\" ; recursing-file \"/var/named/data/named.recursing\" ; allow-query { localhost ; } ; /* - If you are building an AUTHORITATIVE DNS server, do NOT enable recursion. - If you are building a RECURSIVE ( caching ) DNS server, you need to enable recursion. - If your recursive DNS server has a public IP address, you MUST enable access control to limit queries to your legitimate users. Failing to do so will cause your server to become part of large scale DNS amplification attacks. Implementing BCP38 within your network would greatly reduce such attack surface */ recursion yes ; dnssec-validation yes ; managed-keys-directory \"/var/named/dynamic\" ; geoip-directory \"/usr/share/GeoIP\" ; pid-file \"/run/named/named.pid\" ; session-keyfile \"/run/named/session.key\" ; /* https://fedoraproject.org/wiki/Changes/CryptoPolicy */ include \"/etc/crypto-policies/back-ends/bind.config\" ; } ; logging { channel default_debug { file \"data/named.run\" ; severity dynamic ; } ; } ; zone \".\" IN { type hint ; file \"named.ca\" ; } ; include \"/etc/named.rfc1912.zones\" ; include \"/etc/named.root.key\" ; Ajout d'une ACL que l'on pourra r\u00e9utiliser : 1 2 3 acl mes-clients { 10 .56.126.0/24 ; } ; Ajout de mes-clients sur la ligne suivante: allow-query { localhost ; mes-clients ; } ; Ajout d'une zone avec la cr\u00e9ation d'un fichier dans /etc/named/mes-domaines.conf : zone \"dom3.local. \" { type master ; file \"dynamic/dom3.local.zone\" ; } ; Pour que le fichier soit lu par named, on lui indique le chemin complet dans sont fichier de configuration etc/named.conf : include \"/etc/named/mes-domaines.conf\" ; Configuration de la zone dans /var/named/dynamic/dom3.local.zone : $TTL 3600 @ IN SOA dns1 leoguilloux.yahoo.com. ( 2023021401 ; Serial 3600 ; Refresh 1800 ; Retry 604800 ; Expire 86400 ) ; Minimum TTL @ NS dns1 dns1 A 10 .56.126.223 Ports ouverts sur une machine ss -plntu Pour que une machine cliente puisse ping l'exterieur, on lui met une route par d\u00e9faut passant par la gateway. Sur le routeur, on lui change l'interface dans la zone external : firewall-cmd --zone = external --add-interface = eth2 --permanent On red\u00e9marre le service avec : systemctl restart firewalld","title":"Bind"},{"location":"Linux/Master/Administration%20r%C3%A9seau/LDAP/","text":"LDAP \u00b6 D\u00e9finition \u00b6 LDAP est l'abr\u00e9viation de Lightweight Directory Access Protocol (protocole l\u00e9ger d'acc\u00e8s \u00e0 un annuaire). C'est un protocole de communication utilis\u00e9 pour acc\u00e9der \u00e0 des annuaires en ligne, qui sont des bases de donn\u00e9es contenant des informations sur des utilisateurs, des groupes, des ordinateurs et d'autres ressources r\u00e9seau. LDAP permet aux clients d'acc\u00e9der \u00e0 ces annuaires pour effectuer des op\u00e9rations telles que la recherche, la lecture, la mise \u00e0 jour et la suppression de donn\u00e9es. Les annuaires LDAP sont utilis\u00e9s dans de nombreuses applications, notamment pour la gestion des utilisateurs et des groupes, l'authentification et l'autorisation, la messagerie \u00e9lectronique, la voix sur IP, et bien d'autres. LDAP utilise un mod\u00e8le client-serveur et repose sur un ensemble de r\u00e8gles et de sp\u00e9cifications d\u00e9finies par l'Internet Engineering Task Force (IETF). Il est consid\u00e9r\u00e9 comme un protocole efficace et s\u00fbr pour la gestion de donn\u00e9es d'annuaire \u00e0 grande \u00e9chelle. D\u00e9couverte et param\u00e9trages \u00b6 Success Changer toutes les commandes qui demande un editeur de texte comme ldapvi, on peut changer l'editeur avec : export EDITOR = nano Recherche dans les schemas : grep -rni --color PosixAccount /etc/openldap/schema/ Affichage des lignes de 161 \u00e0 180 du fichier nis.schema : objectclass ( 1 .3.6.1.1.1.2.0 NAME 'posixAccount' DESC 'Abstraction of an account with POSIX attributes' SUP top AUXILIARY MUST ( cn $ uid $ uidNumber $ gidNumber $ homeDirectory ) MAY ( userPassword $ loginShell $ gecos $ description ) ) objectclass ( 1 .3.6.1.1.1.2.1 NAME 'shadowAccount' DESC 'Additional attributes for shadow passwords' SUP top AUXILIARY MUST uid MAY ( userPassword $ shadowLastChange $ shadowMin $ shadowMax $ shadowWarning $ shadowInactive $ shadowExpire $ shadowFlag $ description ) ) objectclass ( 1 .3.6.1.1.1.2.2 NAME 'posixGroup' DESC 'Abstraction of a group of accounts' SUP top STRUCTURAL MUST ( cn $ gidNumber ) MAY ( userPassword $ memberUid $ description ) ) 1 objet rentr\u00e9 dans l'annuaire doit obliatoirement avoir une classe structurale. La classe Account se situe dans le fichier cosine.schema et cette classe est une classe Structurale : objectclass ( 0 .9.2342.19200300.100.4.5 NAME 'account' SUP top STRUCTURAL MUST userid MAY ( description $ seeAlso $ localityName $ organizationName $ organizationalUnitName $ host ) ) D\u00e9marrage de ldap : systemctl start slapd Plusieurs LDAP : Ldapi : Connexion avec le socket UNIX (locale) Ldaps : connexion avec des certficats (utlis\u00e9 par des clients TLS) Ldap : connexion simple sans certificats (tuilis\u00e9 par des clients non TLS) Les commandes ldapwhoami permettent de tester l'acc\u00e8s \u00e0 un annuaire. Recherche et connexion dans l'annuaire avec connexion : ldapsearch -Y EXTERNAL -H ldapi:/// -Q -b CN = config Options de filtres ( attention pas d'op\u00e9rateur < ou > (op\u00e9ratuers strictes) ) : = (\u00e9gal) * : joker <= (plus petit ou \u00e9gal) >= (plus grand ou \u00e9gal) ~= (approximation) Recherche port\u00e9e avec scope -s et ses options : base (uniquement la base) sub (\u00e0 partir de la base sur la totalit\u00e9 de la base) one (fils directs) ldapmodify utlise un sch\u00e9ma pour la modification : le DN, le type d'op\u00e9ration r\u00e9alis\u00e9e, changetype: add : pour ajouter une entr\u00e9e changetype: delete : pour supprimer une entr\u00e9e changetype: modify : pour modifier une entr\u00e9e d\u00e9j\u00e0 pr\u00e9sente La ligne du dessous mentionne alors le type de modification : add : attribut delete : attribut replace : attribut La ligne du dessous donne alors la nouvelle valeur de l'attribut Cr\u00e9ation d'un fichier pour modifier le mot de passe root : dn: olcDatabase ={ 2 } mdb,cn = config changetype: modify replace: olcRootPW olcRootPW: secret Application de la modification : ldapmodify -Y EXTERNAL -H ldapi:/// -Q -f modif-rootpw.ldif Observation de la modification avec la commande ldapsearch -Y EXTERNAL -H ldapi:/// -Q -LLL -b 'olcDatabase={2}mdb,cn=config' : 1 2 3 4 5 6 7 8 9 10 dn: olcDatabase ={ 2 } mdb,cn = config objectClass: olcDatabaseConfig objectClass: olcMdbConfig olcDatabase: { 2 } mdb olcDbDirectory: /var/lib/ldap olcSuffix: dc = my-domain,dc = com olcRootDN: cn = Manager,dc = my-domain,dc = com olcDbIndex: objectClass eq,pres olcDbIndex: ou,cn,mail,surname,givenname eq,pres,sub olcRootPW: secret Pour obtenir un mot de passe chiffr\u00e9, on utilise slappasswd . Saut de ligne Dans les diff\u00e9rents \u00e9diteurs, ceux-ci enregisre un saut de ligne qui est interpr\u00e9t\u00e9 par ldap (ex: mot de passe de 6 caract\u00e8res comptera sur 7). Cela se suprrime avec la commande : echo -n secret > .ldappass R\u00e9alisation du travail \u00b6 Travail \u00e0 r\u00e9aliser On cherche \u00e0 cr\u00e9er une organisation \"mon domaine domX.local\" (entr\u00e9e d'annuaire \"organization\") Cr\u00e9ation d'une OU \"users\" (entr\u00e9e d'annuaire : organizationUnit\") Ajout d'une entr\u00e9e bas\u00e9e sur posixAccount : \"ldapuser1\" Cr\u00e9ation d'une OU \"groups\" (entr\u00e9e d'annuaire : organizationUnit\") Ajout d'une entr\u00e9e bas\u00e9e sur posixGroup : \"ldapgroup1\" Cr\u00e9ation d'une organisation avec la cr\u00e9ation d'un fichier org.ldif \u00b6 dn: dc = dom3,dc = local objectClass: organization objectClass: dcObject o: Mon domaine dom0.local On ajout l'organistaion avec : ldapadd -D cn = leo,dc = dom3,dc = local -y ~/.ldappass -f org.ldif -c Info L'option -c permet de continuer si des lignes provoquent des erreurs Dans la suite des travaux, nous continurons dans le fichier org.ldif . Cr\u00e9ation d'une OU \"users\" \u00b6 dn: ou = users,dc = dom3,dc = local objectClass: organizationalUnit Ajout d'un utilisateur ldapuser1 \u00b6 Ajout du sch\u00e9ma inetorgperson : ldapadd -Y EXTERNAL -H ldapi:/// -f /etc/openldap/schema/inetorgperson.ldif Ajout de l'utilisateur ici dans groups : 1 2 3 4 5 6 7 8 9 10 dn: cn = ldapuser1,ou = groups,dc = dom3,dc = local objectClass: posixAccount objectClass: inetOrgPerson cn: Youzer Un gn: Youzer sn: Un uid: ldpauser1 uidNumber: 10001 gidNumber: 10000 homeDirectory: /home/ldapuser1 Ajout d'utilisateur ici dans users : 1 2 3 4 5 6 7 8 9 10 dn: cn = ldapuser1,ou = users,dc = dom3,dc = local objectClass: posixAccount objectClass: inetOrgPerson cn: Youzer Un gn: Youzer sn: Un uid: ldapuser1 uidNumber: 10001 gidNumber: 10000 homeDirectory: /home/ldapuser1 Cr\u00e9ation d'une OU \"groups\" \u00b6 dn: ou = groups,dc = dom3,dc = local objectClass: organizationalUnit Ajout d'un groupe ldapgroup1 \u00b6 On cherche dans les sch\u00e9mas les r\u00e9f\u00e9rences \u00e0 posixGroup : grep -rni --color PosixGroup /etc/openldap/schema/ On retrouve dans le fichier nis.schema que l'identifiant est gidnumber . On ajoute le schema nis.ldif : ldapadd -Y EXTERNAL -H ldapi:/// -f /etc/openldap/schema/nis.ldif On cherche l'erreur suivante sur les manager que l'on trouve dans cosine.schema. On ajoute ensuite le fichier ldif : ldapadd -Y EXTERNAL -H ldapi:/// -f /etc/openldap/schema/cosine.ldif Si il y a des erreurs, il faut int\u00e9grer les fichier dans l'ordre nis.ldif puis cosine.ldif . Code d\u00e9finitif pour la cr\u00e9ation : dn: cn = ldapgroupe1,ou = groups,dc = dom3,dc = local objectClass: posixGroup gidNumber: 10000 PAM \u00b6 PAM permet d'authentifier des utilisateurs en utilisant LDAP. On cherche les fichiers de PAM avec /etc/pam.d/ . Le fichier other est pr\u00e9sent lorsque aucun fichier du nom du programme existe. Pour voir si un programme d\u00e9pend de pam ou tout autre programme, on utilise ldd . Par exemple pour passwd , on obtient : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 linux-vdso.so.1 ( 0x00007ffcf63ec000 ) libuser.so.1 = > /lib64/libuser.so.1 ( 0x00007ff80b72f000 ) libgobject-2.0.so.0 = > /lib64/libgobject-2.0.so.0 ( 0x00007ff80b6d4000 ) libglib-2.0.so.0 = > /lib64/libglib-2.0.so.0 ( 0x00007ff80b59a000 ) libpopt.so.0 = > /lib64/libpopt.so.0 ( 0x00007ff80b58b000 ) libpam.so.0 = > /lib64/libpam.so.0 ( 0x00007ff80b579000 ) libpam_misc.so.0 = > /lib64/libpam_misc.so.0 ( 0x00007ff80b573000 ) libaudit.so.1 = > /lib64/libaudit.so.1 ( 0x00007ff80b543000 ) libselinux.so.1 = > /lib64/libselinux.so.1 ( 0x00007ff80b516000 ) libc.so.6 = > /lib64/libc.so.6 ( 0x00007ff80b200000 ) libgmodule-2.0.so.0 = > /lib64/libgmodule-2.0.so.0 ( 0x00007ff80b510000 ) libcrypt.so.2 = > /lib64/libcrypt.so.2 ( 0x00007ff80b4d6000 ) libffi.so.8 = > /lib64/libffi.so.8 ( 0x00007ff80b4ca000 ) libpcre.so.1 = > /lib64/libpcre.so.1 ( 0x00007ff80b450000 ) libeconf.so.0 = > /lib64/libeconf.so.0 ( 0x00007ff80b445000 ) libm.so.6 = > /lib64/libm.so.6 ( 0x00007ff80b125000 ) libcap-ng.so.0 = > /lib64/libcap-ng.so.0 ( 0x00007ff80b43c000 ) libpcre2-8.so.0 = > /lib64/libpcre2-8.so.0 ( 0x00007ff80b089000 ) /lib64/ld-linux-x86-64.so.2 ( 0x00007ff80b762000 ) On observe ligne 6, que le programme n\u00e9c\u00e9ssite PAM pour focntionner. Pour l'authentification, le fichier de PAM /etc/pam.d/system_auth pr\u00e9sente les r\u00e8gles d'authentifications. 1 2 3 auth required pam_env.so auth sufficient pam_unix.so try_first_pass nullok auth required pam_deny.so Note PAM est appel\u00e9 pour le login et ne donnera jamais l'\u00e9l\u00e9ment qui \u00e0 \u00e9chou\u00e9. Chez PAM, plusieurs strat\u00e9gies sont pr\u00e9d\u00e9finies : Required : R\u00e9ussir le module est n\u00e9cessaire, on annoncera une erreur \u00e0 la fin du traitement uniquement si 1 des modules \"required\" \u00e9choue. Requisite : R\u00e9ussir le module est n\u00e9cessaire : la premi\u00e8re erreur (on annoncera laquelle) est synonyme d'abandon Sufficient : La r\u00e9ussite du module est suffisante pour que l'on valide le contexte. On ne fait pas l'analyse des modules qui suivent (m\u00eame required ou requisite) dans le contexte Optional : La r\u00e9ussite d'un module optional est n\u00e9cessaire si les autres sont ignor\u00e9s. Le module n'est pas appel\u00e9 si un autre module r\u00e9ussit ou \u00e9choue Include : sert \u00e0 brancher vers un sous-fichier de r\u00e8gles PAM SSSD \u00b6 Pourquoi utiliser SSHD ? Car SSHD est plus r\u00e9cent que PAM pour LDAP. Installation des packages SSHD : dnf -y install sssd sssd-ldap sssd-tools oddjob oddjob-mkhomedir D\u00e9marrage du service : systemctl enable --now oddjobd.service Authselect permet de configurer des profils d'authentifications. Nous pouvons lister les profils avec authselect list : - minimal Local users only for minimal installations - sssd Enable SSSD for system authentication ( also for local users only ) - winbind Enable winbind for system authentication Configuration de PAM avec SSHD : authselect select --force sssd with-mkhomedir Si on regarde maintenant le fichier de pam system_auth : auth required pam_env.so auth required pam_faildelay.so delay = 2000000 auth [ default = 1 ignore = ignore success = ok ] pam_usertype.so isregular auth [ default = 1 ignore = ignore success = ok ] pam_localuser.so auth sufficient pam_unix.so nullok auth [ default = 1 ignore = ignore success = ok ] pam_usertype.so isregular auth sufficient pam_sss.so forward_pass auth required pam_deny.so On observe de nouvelles lignes qui se sont ajout\u00e9es dans le fichier avec des param\u00e8tres suppl\u00e9mentaires. Configuration de SSS \u00b6 Ajout d'un fichier de configuration /etc/sssd/sssd.conf : [ sssd ] services = nss, pam domains = dom3.local [ nss ] filter_users = root filter_groups = root [ domain/dom3.local ] cache_credentials = true id_provider = ldap auth_provider = ldap ldap_uri = ldap://10.56.126.220 #ldap_tls_reqcert = demand ldap_search_base = dc = dom3,dc = local ldap_user_search_base = ou = users,dc = dom3,dc = local ldap_groups_search_base = ou = groups,dc = dom3,dc = local [ pam ] offline_credentials_expiration = 1 offline_failed_login_attempts = 3 offline_failed_login_delay = 5 Modification des droits en 600 : chmod 600 /etc/sssd/sssd.conf D\u00e9marrage du service SSSD qui n\u00e9c\u00e9ssitait un fichier de configuration : systemctl restart sssd On verifie la connexion avec sssctl user-checks ldapuser1 (ici un extrait du message retour): 1 2 3 4 5 6 7 8 9 10 11 user: ldapuser1 action: acct service: system-auth SSSD nss user lookup result: - user name: ldapuser1 - user id: 10001 - group id: 10000 - gecos: Youzer Un - home directory: /home/ldapuser1 - shell: Verficiation aussi avec id ldapuser1 : uid = 10001 ( ldapuser1 ) gid = 10000 ( ldapgroupe1 ) groupes = 10000 ( ldapgroupe1 ) Certification avec TLS \u00b6 Certificat auto-sign\u00e9 \u00b6 Cr\u00e9ation d'un dossier avec des droits personnalis\u00e9s sur le serveur : install -d -m 2750 -o root -g ldap /etc/openldap/certs Cr\u00e9ation des documents ca.pem et ca-key.pem : openssl req \\ -newkey rsa:4096 -nodes -keyout /etc/openldap/certs/ca-key.pem \\ -subj '/countryName=FR/stateOrProvinceName=Bretagne/organizationName=Actilis/CN=CA-LDAP/' \\ -x509 -sha256 -days 365 \\ -extensions v3_ca \\ -out /etc/openldap/certs/ca.pem Ajout des droits sur le fichier ca.pem : chmod 444 /etc/openldap/certs/ca.pem Certificat serveur \u00b6 Cr\u00e9ation des fichiers server.csr et key.pem : openssl req \\ -newkey rsa:4096 -nodes -keyout /etc/openldap/certs/key.pem \\ -subj '/CN=dom3.local/' \\ -out server.csr Ajout des permissions : chmod 440 /etc/openldap/certs/key.pem Tamponnage du fichier \u00b6 openssl x509 -req -days 365 -sha256 -in server.csr -out /etc/openldap/certs/cert.pem \\ -CA /etc/openldap/certs/ca.pem -CAkey /etc/openldap/certs/ca-key.pem -CAcreateserial \\ -extfile < ( printf \"basicConstraints = CA:FALSE\\n subjectAltName=IP:127.0.0.1,IP:10.56.126.220,DNS:ldap.dom3.local\" ) Verifications du certificat : openssl x509 -noout -subject < /etc/openldap/certs/cert.pem Int\u00e9gration des configurations \u00b6 Ajouter un fichier tls.ldif : 1 2 3 4 5 6 7 8 9 10 dn: cn = config changetype: modify replace: olcTLSCACertificateFile olcTLSCACertificateFile: /etc/openldap/certs/ca.pem - replace: olcTLSCertificateFile olcTLSCertificateFile: /etc/openldap/certs/cert.pem - replace: olcTLSCertificateKeyFile olcTLSCertificateKeyFile: /etc/openldap/certs/key.pem Ajout de la configuration avec ldapmodify : ldapmodify -Y EXTERNAL -H ldapi:/// < tls.ldif Modification et ajout du fichier /etc/openldap/ldap.conf : TLS_CACERT /etc/openldap/certs/ca.pem TLS_REQCERT demand Ajout pour sudo : dn: cn = defaults,ou = SUDOers,dc = example,dc = com objectClass: top objectClass: sudoRole cn: defaults description: Default sudoOption ' s go here sudoOption: env_keep += SSH_AUTH_SOCK T\u00e9l\u00e9chargement de schema2ldif : Documentation de schema2ldif Ajout d'un repo avec la cr\u00e9ation d'un fichier /etc/yum.repos.d/fusion.repo : [ fusiondirectory-schema2ldif-release ] name = Fusiondirectory Packages for CentOS 7 baseurl = https://public.fusiondirectory.org/centos7-schema2ldif-release/RPMS enabled = 1 gpgcheck = 0 gpgkey = file:///etc/pki/rpm-gpg/RPM-GPG-KEY-FUSIONDIRECTORY T\u00e9lechargement via dnf de schema2ldif Modification d'un fichier en ldif : schema2ldif /usr/share/doc/sudo/schema.OpenLDAP > sudo-schema.ldif On peut observer le d\u00e9but du fichier avec la commande head sudo-schema.ldif : dn: cn = schema,cn = schema,cn = config objectClass: olcSchemaConfig cn: schema # # OpenLDAP schema file for Sudo # Save as /etc/openldap/schema/sudo.schema and restart slapd. # For a version that uses online configuration, see schema.olcSudo. # olcAttributeTypes: ( 1 .3.6.1.4.1.15953.9.1.1 NAME 'sudoUser'","title":"LDAP"},{"location":"Linux/Master/Administration%20r%C3%A9seau/LDAP/#ldap","text":"","title":"LDAP"},{"location":"Linux/Master/Administration%20r%C3%A9seau/LDAP/#definition","text":"LDAP est l'abr\u00e9viation de Lightweight Directory Access Protocol (protocole l\u00e9ger d'acc\u00e8s \u00e0 un annuaire). C'est un protocole de communication utilis\u00e9 pour acc\u00e9der \u00e0 des annuaires en ligne, qui sont des bases de donn\u00e9es contenant des informations sur des utilisateurs, des groupes, des ordinateurs et d'autres ressources r\u00e9seau. LDAP permet aux clients d'acc\u00e9der \u00e0 ces annuaires pour effectuer des op\u00e9rations telles que la recherche, la lecture, la mise \u00e0 jour et la suppression de donn\u00e9es. Les annuaires LDAP sont utilis\u00e9s dans de nombreuses applications, notamment pour la gestion des utilisateurs et des groupes, l'authentification et l'autorisation, la messagerie \u00e9lectronique, la voix sur IP, et bien d'autres. LDAP utilise un mod\u00e8le client-serveur et repose sur un ensemble de r\u00e8gles et de sp\u00e9cifications d\u00e9finies par l'Internet Engineering Task Force (IETF). Il est consid\u00e9r\u00e9 comme un protocole efficace et s\u00fbr pour la gestion de donn\u00e9es d'annuaire \u00e0 grande \u00e9chelle.","title":"D\u00e9finition"},{"location":"Linux/Master/Administration%20r%C3%A9seau/LDAP/#decouverte-et-parametrages","text":"Success Changer toutes les commandes qui demande un editeur de texte comme ldapvi, on peut changer l'editeur avec : export EDITOR = nano Recherche dans les schemas : grep -rni --color PosixAccount /etc/openldap/schema/ Affichage des lignes de 161 \u00e0 180 du fichier nis.schema : objectclass ( 1 .3.6.1.1.1.2.0 NAME 'posixAccount' DESC 'Abstraction of an account with POSIX attributes' SUP top AUXILIARY MUST ( cn $ uid $ uidNumber $ gidNumber $ homeDirectory ) MAY ( userPassword $ loginShell $ gecos $ description ) ) objectclass ( 1 .3.6.1.1.1.2.1 NAME 'shadowAccount' DESC 'Additional attributes for shadow passwords' SUP top AUXILIARY MUST uid MAY ( userPassword $ shadowLastChange $ shadowMin $ shadowMax $ shadowWarning $ shadowInactive $ shadowExpire $ shadowFlag $ description ) ) objectclass ( 1 .3.6.1.1.1.2.2 NAME 'posixGroup' DESC 'Abstraction of a group of accounts' SUP top STRUCTURAL MUST ( cn $ gidNumber ) MAY ( userPassword $ memberUid $ description ) ) 1 objet rentr\u00e9 dans l'annuaire doit obliatoirement avoir une classe structurale. La classe Account se situe dans le fichier cosine.schema et cette classe est une classe Structurale : objectclass ( 0 .9.2342.19200300.100.4.5 NAME 'account' SUP top STRUCTURAL MUST userid MAY ( description $ seeAlso $ localityName $ organizationName $ organizationalUnitName $ host ) ) D\u00e9marrage de ldap : systemctl start slapd Plusieurs LDAP : Ldapi : Connexion avec le socket UNIX (locale) Ldaps : connexion avec des certficats (utlis\u00e9 par des clients TLS) Ldap : connexion simple sans certificats (tuilis\u00e9 par des clients non TLS) Les commandes ldapwhoami permettent de tester l'acc\u00e8s \u00e0 un annuaire. Recherche et connexion dans l'annuaire avec connexion : ldapsearch -Y EXTERNAL -H ldapi:/// -Q -b CN = config Options de filtres ( attention pas d'op\u00e9rateur < ou > (op\u00e9ratuers strictes) ) : = (\u00e9gal) * : joker <= (plus petit ou \u00e9gal) >= (plus grand ou \u00e9gal) ~= (approximation) Recherche port\u00e9e avec scope -s et ses options : base (uniquement la base) sub (\u00e0 partir de la base sur la totalit\u00e9 de la base) one (fils directs) ldapmodify utlise un sch\u00e9ma pour la modification : le DN, le type d'op\u00e9ration r\u00e9alis\u00e9e, changetype: add : pour ajouter une entr\u00e9e changetype: delete : pour supprimer une entr\u00e9e changetype: modify : pour modifier une entr\u00e9e d\u00e9j\u00e0 pr\u00e9sente La ligne du dessous mentionne alors le type de modification : add : attribut delete : attribut replace : attribut La ligne du dessous donne alors la nouvelle valeur de l'attribut Cr\u00e9ation d'un fichier pour modifier le mot de passe root : dn: olcDatabase ={ 2 } mdb,cn = config changetype: modify replace: olcRootPW olcRootPW: secret Application de la modification : ldapmodify -Y EXTERNAL -H ldapi:/// -Q -f modif-rootpw.ldif Observation de la modification avec la commande ldapsearch -Y EXTERNAL -H ldapi:/// -Q -LLL -b 'olcDatabase={2}mdb,cn=config' : 1 2 3 4 5 6 7 8 9 10 dn: olcDatabase ={ 2 } mdb,cn = config objectClass: olcDatabaseConfig objectClass: olcMdbConfig olcDatabase: { 2 } mdb olcDbDirectory: /var/lib/ldap olcSuffix: dc = my-domain,dc = com olcRootDN: cn = Manager,dc = my-domain,dc = com olcDbIndex: objectClass eq,pres olcDbIndex: ou,cn,mail,surname,givenname eq,pres,sub olcRootPW: secret Pour obtenir un mot de passe chiffr\u00e9, on utilise slappasswd . Saut de ligne Dans les diff\u00e9rents \u00e9diteurs, ceux-ci enregisre un saut de ligne qui est interpr\u00e9t\u00e9 par ldap (ex: mot de passe de 6 caract\u00e8res comptera sur 7). Cela se suprrime avec la commande : echo -n secret > .ldappass","title":"D\u00e9couverte et param\u00e9trages"},{"location":"Linux/Master/Administration%20r%C3%A9seau/LDAP/#realisation-du-travail","text":"Travail \u00e0 r\u00e9aliser On cherche \u00e0 cr\u00e9er une organisation \"mon domaine domX.local\" (entr\u00e9e d'annuaire \"organization\") Cr\u00e9ation d'une OU \"users\" (entr\u00e9e d'annuaire : organizationUnit\") Ajout d'une entr\u00e9e bas\u00e9e sur posixAccount : \"ldapuser1\" Cr\u00e9ation d'une OU \"groups\" (entr\u00e9e d'annuaire : organizationUnit\") Ajout d'une entr\u00e9e bas\u00e9e sur posixGroup : \"ldapgroup1\"","title":"R\u00e9alisation du travail"},{"location":"Linux/Master/Administration%20r%C3%A9seau/LDAP/#creation-dune-organisation-avec-la-creation-dun-fichier-orgldif","text":"dn: dc = dom3,dc = local objectClass: organization objectClass: dcObject o: Mon domaine dom0.local On ajout l'organistaion avec : ldapadd -D cn = leo,dc = dom3,dc = local -y ~/.ldappass -f org.ldif -c Info L'option -c permet de continuer si des lignes provoquent des erreurs Dans la suite des travaux, nous continurons dans le fichier org.ldif .","title":"Cr\u00e9ation d'une organisation avec la cr\u00e9ation d'un fichier org.ldif"},{"location":"Linux/Master/Administration%20r%C3%A9seau/LDAP/#creation-dune-ou-users","text":"dn: ou = users,dc = dom3,dc = local objectClass: organizationalUnit","title":"Cr\u00e9ation d'une OU \"users\""},{"location":"Linux/Master/Administration%20r%C3%A9seau/LDAP/#ajout-dun-utilisateur-ldapuser1","text":"Ajout du sch\u00e9ma inetorgperson : ldapadd -Y EXTERNAL -H ldapi:/// -f /etc/openldap/schema/inetorgperson.ldif Ajout de l'utilisateur ici dans groups : 1 2 3 4 5 6 7 8 9 10 dn: cn = ldapuser1,ou = groups,dc = dom3,dc = local objectClass: posixAccount objectClass: inetOrgPerson cn: Youzer Un gn: Youzer sn: Un uid: ldpauser1 uidNumber: 10001 gidNumber: 10000 homeDirectory: /home/ldapuser1 Ajout d'utilisateur ici dans users : 1 2 3 4 5 6 7 8 9 10 dn: cn = ldapuser1,ou = users,dc = dom3,dc = local objectClass: posixAccount objectClass: inetOrgPerson cn: Youzer Un gn: Youzer sn: Un uid: ldapuser1 uidNumber: 10001 gidNumber: 10000 homeDirectory: /home/ldapuser1","title":"Ajout d'un utilisateur ldapuser1"},{"location":"Linux/Master/Administration%20r%C3%A9seau/LDAP/#creation-dune-ou-groups","text":"dn: ou = groups,dc = dom3,dc = local objectClass: organizationalUnit","title":"Cr\u00e9ation d'une OU \"groups\""},{"location":"Linux/Master/Administration%20r%C3%A9seau/LDAP/#ajout-dun-groupe-ldapgroup1","text":"On cherche dans les sch\u00e9mas les r\u00e9f\u00e9rences \u00e0 posixGroup : grep -rni --color PosixGroup /etc/openldap/schema/ On retrouve dans le fichier nis.schema que l'identifiant est gidnumber . On ajoute le schema nis.ldif : ldapadd -Y EXTERNAL -H ldapi:/// -f /etc/openldap/schema/nis.ldif On cherche l'erreur suivante sur les manager que l'on trouve dans cosine.schema. On ajoute ensuite le fichier ldif : ldapadd -Y EXTERNAL -H ldapi:/// -f /etc/openldap/schema/cosine.ldif Si il y a des erreurs, il faut int\u00e9grer les fichier dans l'ordre nis.ldif puis cosine.ldif . Code d\u00e9finitif pour la cr\u00e9ation : dn: cn = ldapgroupe1,ou = groups,dc = dom3,dc = local objectClass: posixGroup gidNumber: 10000","title":"Ajout d'un groupe ldapgroup1"},{"location":"Linux/Master/Administration%20r%C3%A9seau/LDAP/#pam","text":"PAM permet d'authentifier des utilisateurs en utilisant LDAP. On cherche les fichiers de PAM avec /etc/pam.d/ . Le fichier other est pr\u00e9sent lorsque aucun fichier du nom du programme existe. Pour voir si un programme d\u00e9pend de pam ou tout autre programme, on utilise ldd . Par exemple pour passwd , on obtient : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 linux-vdso.so.1 ( 0x00007ffcf63ec000 ) libuser.so.1 = > /lib64/libuser.so.1 ( 0x00007ff80b72f000 ) libgobject-2.0.so.0 = > /lib64/libgobject-2.0.so.0 ( 0x00007ff80b6d4000 ) libglib-2.0.so.0 = > /lib64/libglib-2.0.so.0 ( 0x00007ff80b59a000 ) libpopt.so.0 = > /lib64/libpopt.so.0 ( 0x00007ff80b58b000 ) libpam.so.0 = > /lib64/libpam.so.0 ( 0x00007ff80b579000 ) libpam_misc.so.0 = > /lib64/libpam_misc.so.0 ( 0x00007ff80b573000 ) libaudit.so.1 = > /lib64/libaudit.so.1 ( 0x00007ff80b543000 ) libselinux.so.1 = > /lib64/libselinux.so.1 ( 0x00007ff80b516000 ) libc.so.6 = > /lib64/libc.so.6 ( 0x00007ff80b200000 ) libgmodule-2.0.so.0 = > /lib64/libgmodule-2.0.so.0 ( 0x00007ff80b510000 ) libcrypt.so.2 = > /lib64/libcrypt.so.2 ( 0x00007ff80b4d6000 ) libffi.so.8 = > /lib64/libffi.so.8 ( 0x00007ff80b4ca000 ) libpcre.so.1 = > /lib64/libpcre.so.1 ( 0x00007ff80b450000 ) libeconf.so.0 = > /lib64/libeconf.so.0 ( 0x00007ff80b445000 ) libm.so.6 = > /lib64/libm.so.6 ( 0x00007ff80b125000 ) libcap-ng.so.0 = > /lib64/libcap-ng.so.0 ( 0x00007ff80b43c000 ) libpcre2-8.so.0 = > /lib64/libpcre2-8.so.0 ( 0x00007ff80b089000 ) /lib64/ld-linux-x86-64.so.2 ( 0x00007ff80b762000 ) On observe ligne 6, que le programme n\u00e9c\u00e9ssite PAM pour focntionner. Pour l'authentification, le fichier de PAM /etc/pam.d/system_auth pr\u00e9sente les r\u00e8gles d'authentifications. 1 2 3 auth required pam_env.so auth sufficient pam_unix.so try_first_pass nullok auth required pam_deny.so Note PAM est appel\u00e9 pour le login et ne donnera jamais l'\u00e9l\u00e9ment qui \u00e0 \u00e9chou\u00e9. Chez PAM, plusieurs strat\u00e9gies sont pr\u00e9d\u00e9finies : Required : R\u00e9ussir le module est n\u00e9cessaire, on annoncera une erreur \u00e0 la fin du traitement uniquement si 1 des modules \"required\" \u00e9choue. Requisite : R\u00e9ussir le module est n\u00e9cessaire : la premi\u00e8re erreur (on annoncera laquelle) est synonyme d'abandon Sufficient : La r\u00e9ussite du module est suffisante pour que l'on valide le contexte. On ne fait pas l'analyse des modules qui suivent (m\u00eame required ou requisite) dans le contexte Optional : La r\u00e9ussite d'un module optional est n\u00e9cessaire si les autres sont ignor\u00e9s. Le module n'est pas appel\u00e9 si un autre module r\u00e9ussit ou \u00e9choue Include : sert \u00e0 brancher vers un sous-fichier de r\u00e8gles PAM","title":"PAM"},{"location":"Linux/Master/Administration%20r%C3%A9seau/LDAP/#sssd","text":"Pourquoi utiliser SSHD ? Car SSHD est plus r\u00e9cent que PAM pour LDAP. Installation des packages SSHD : dnf -y install sssd sssd-ldap sssd-tools oddjob oddjob-mkhomedir D\u00e9marrage du service : systemctl enable --now oddjobd.service Authselect permet de configurer des profils d'authentifications. Nous pouvons lister les profils avec authselect list : - minimal Local users only for minimal installations - sssd Enable SSSD for system authentication ( also for local users only ) - winbind Enable winbind for system authentication Configuration de PAM avec SSHD : authselect select --force sssd with-mkhomedir Si on regarde maintenant le fichier de pam system_auth : auth required pam_env.so auth required pam_faildelay.so delay = 2000000 auth [ default = 1 ignore = ignore success = ok ] pam_usertype.so isregular auth [ default = 1 ignore = ignore success = ok ] pam_localuser.so auth sufficient pam_unix.so nullok auth [ default = 1 ignore = ignore success = ok ] pam_usertype.so isregular auth sufficient pam_sss.so forward_pass auth required pam_deny.so On observe de nouvelles lignes qui se sont ajout\u00e9es dans le fichier avec des param\u00e8tres suppl\u00e9mentaires.","title":"SSSD"},{"location":"Linux/Master/Administration%20r%C3%A9seau/LDAP/#configuration-de-sss","text":"Ajout d'un fichier de configuration /etc/sssd/sssd.conf : [ sssd ] services = nss, pam domains = dom3.local [ nss ] filter_users = root filter_groups = root [ domain/dom3.local ] cache_credentials = true id_provider = ldap auth_provider = ldap ldap_uri = ldap://10.56.126.220 #ldap_tls_reqcert = demand ldap_search_base = dc = dom3,dc = local ldap_user_search_base = ou = users,dc = dom3,dc = local ldap_groups_search_base = ou = groups,dc = dom3,dc = local [ pam ] offline_credentials_expiration = 1 offline_failed_login_attempts = 3 offline_failed_login_delay = 5 Modification des droits en 600 : chmod 600 /etc/sssd/sssd.conf D\u00e9marrage du service SSSD qui n\u00e9c\u00e9ssitait un fichier de configuration : systemctl restart sssd On verifie la connexion avec sssctl user-checks ldapuser1 (ici un extrait du message retour): 1 2 3 4 5 6 7 8 9 10 11 user: ldapuser1 action: acct service: system-auth SSSD nss user lookup result: - user name: ldapuser1 - user id: 10001 - group id: 10000 - gecos: Youzer Un - home directory: /home/ldapuser1 - shell: Verficiation aussi avec id ldapuser1 : uid = 10001 ( ldapuser1 ) gid = 10000 ( ldapgroupe1 ) groupes = 10000 ( ldapgroupe1 )","title":"Configuration de SSS"},{"location":"Linux/Master/Administration%20r%C3%A9seau/LDAP/#certification-avec-tls","text":"","title":"Certification avec TLS"},{"location":"Linux/Master/Administration%20r%C3%A9seau/LDAP/#certificat-auto-signe","text":"Cr\u00e9ation d'un dossier avec des droits personnalis\u00e9s sur le serveur : install -d -m 2750 -o root -g ldap /etc/openldap/certs Cr\u00e9ation des documents ca.pem et ca-key.pem : openssl req \\ -newkey rsa:4096 -nodes -keyout /etc/openldap/certs/ca-key.pem \\ -subj '/countryName=FR/stateOrProvinceName=Bretagne/organizationName=Actilis/CN=CA-LDAP/' \\ -x509 -sha256 -days 365 \\ -extensions v3_ca \\ -out /etc/openldap/certs/ca.pem Ajout des droits sur le fichier ca.pem : chmod 444 /etc/openldap/certs/ca.pem","title":"Certificat auto-sign\u00e9"},{"location":"Linux/Master/Administration%20r%C3%A9seau/LDAP/#certificat-serveur","text":"Cr\u00e9ation des fichiers server.csr et key.pem : openssl req \\ -newkey rsa:4096 -nodes -keyout /etc/openldap/certs/key.pem \\ -subj '/CN=dom3.local/' \\ -out server.csr Ajout des permissions : chmod 440 /etc/openldap/certs/key.pem","title":"Certificat serveur"},{"location":"Linux/Master/Administration%20r%C3%A9seau/LDAP/#tamponnage-du-fichier","text":"openssl x509 -req -days 365 -sha256 -in server.csr -out /etc/openldap/certs/cert.pem \\ -CA /etc/openldap/certs/ca.pem -CAkey /etc/openldap/certs/ca-key.pem -CAcreateserial \\ -extfile < ( printf \"basicConstraints = CA:FALSE\\n subjectAltName=IP:127.0.0.1,IP:10.56.126.220,DNS:ldap.dom3.local\" ) Verifications du certificat : openssl x509 -noout -subject < /etc/openldap/certs/cert.pem","title":"Tamponnage du fichier"},{"location":"Linux/Master/Administration%20r%C3%A9seau/LDAP/#integration-des-configurations","text":"Ajouter un fichier tls.ldif : 1 2 3 4 5 6 7 8 9 10 dn: cn = config changetype: modify replace: olcTLSCACertificateFile olcTLSCACertificateFile: /etc/openldap/certs/ca.pem - replace: olcTLSCertificateFile olcTLSCertificateFile: /etc/openldap/certs/cert.pem - replace: olcTLSCertificateKeyFile olcTLSCertificateKeyFile: /etc/openldap/certs/key.pem Ajout de la configuration avec ldapmodify : ldapmodify -Y EXTERNAL -H ldapi:/// < tls.ldif Modification et ajout du fichier /etc/openldap/ldap.conf : TLS_CACERT /etc/openldap/certs/ca.pem TLS_REQCERT demand Ajout pour sudo : dn: cn = defaults,ou = SUDOers,dc = example,dc = com objectClass: top objectClass: sudoRole cn: defaults description: Default sudoOption ' s go here sudoOption: env_keep += SSH_AUTH_SOCK T\u00e9l\u00e9chargement de schema2ldif : Documentation de schema2ldif Ajout d'un repo avec la cr\u00e9ation d'un fichier /etc/yum.repos.d/fusion.repo : [ fusiondirectory-schema2ldif-release ] name = Fusiondirectory Packages for CentOS 7 baseurl = https://public.fusiondirectory.org/centos7-schema2ldif-release/RPMS enabled = 1 gpgcheck = 0 gpgkey = file:///etc/pki/rpm-gpg/RPM-GPG-KEY-FUSIONDIRECTORY T\u00e9lechargement via dnf de schema2ldif Modification d'un fichier en ldif : schema2ldif /usr/share/doc/sudo/schema.OpenLDAP > sudo-schema.ldif On peut observer le d\u00e9but du fichier avec la commande head sudo-schema.ldif : dn: cn = schema,cn = schema,cn = config objectClass: olcSchemaConfig cn: schema # # OpenLDAP schema file for Sudo # Save as /etc/openldap/schema/sudo.schema and restart slapd. # For a version that uses online configuration, see schema.olcSudo. # olcAttributeTypes: ( 1 .3.6.1.4.1.15953.9.1.1 NAME 'sudoUser'","title":"Int\u00e9gration des configurations"},{"location":"Linux/Master/Administration%20r%C3%A9seau/NMCLI/","text":"Configuration r\u00e9seau \u00b6 Configuration d'une IP fixe avec nmcli \u00b6 Info nmcli est un outil qui permet de g\u00e9rer la configuration r\u00e9seau en interagissant avec le deamon NetworkManager . nmcli est utilis\u00e9 pour cr\u00e9er, afficher, modifier, supprimer, activer et d\u00e9sactiver les connexions r\u00e9seau, ainsi que pour contr\u00f4ler et afficher l'\u00e9tat des p\u00e9riph\u00e9riques r\u00e9seau. Pour ajouter une IP fixe, nmcli propose une gestion de profile permettant d'activer une configuration personnalis\u00e9e pour chaque r\u00e9seau souhait\u00e9. Ici, nous souhaitons avoir les informations suivantes : Adresse IP : 10.56.126.223 Masque : 255.255.255.0 Gateway : 10.56.126.254 DNS : 1.1.1.1 Ajout d'un profil pour une connexion ip fixe : nmcli connection add type ethernet con-name ipfixe ifname eth0 ipv4.addresses 10 .56.126.223/24 ipv4.gateway 10 .56.126.254 ipv4.dns 1 .1.1.1 ipv4.method manual On observe ensuite les diff\u00e9rentes connection avec nmcli connection show : 1 2 3 4 5 NAME UUID TYPE DEVICE ipfixe 693bdc04-28e0-4e83-9b58-fef659d8f33c ethernet eth0 docker0 0250129c-212a-4ecc-a7f3-35649a492f08 bridge docker0 lo 45cc8d65-2e4e-40ce-bdbd-1c90b23dada8 loopback lo eth0 40d5bcc8-ca0c-42a9-9fad-388b15a5e856 ethernet -- On active la connextion avec : nmcli connection up ipfixe Network Manager \u00b6 Installation du package systemd-networkd pour obtenir la commande networkctl : dnf -y install systemd-networkd Pour observer les diff\u00e9rentes cartes r\u00e9seaux, on utlise networkctl : 1 2 3 4 5 6 IDX LINK TYPE OPERATIONAL SETUP 1 lo loopback carrier unmanaged 2 eth0 ether routable unmanaged 3 eth1 ether carrier unmanaged 4 docker0 bridge routable unmanaged 6 vethda849ef ether enslaved unmanaged Empecher le management des cartes tout le temps : Ajout d'un fichier dans /etc/NetworkManager/conf.d/99-unmanaged.conf [ keyfile ] unmanaged-devices = mac:00:15:5d:85:01:0f,mac:00:15:5d:85:01:10 Suppression des profiles avec nmcli : nmcli connection delete #nomdelaconnexion Configuration d'une carte avec un fichier de configuration dans /etc/systemd/network/ avec un fichier en .network : # Configuration du LAN 1 [ Match ] MACAddress = 00 :15:5d:85:01:0f [ Network ] Address = 192 .168.131.254/24 # Configuration du LAN 2 [ Match ] MACAddress = 00 :15:5d:85:01:10 [ Network ] Address = 192 .168.132.254/24 Tip Pour continuer le tp, on utilise 3 machines diff\u00e9rentes afin d'avoir la possibilit\u00e9 de communiquer entre elles. Modification des fichiers de configuration de network : # Configuration du LAN 1 [ Match ] MACAddress = 00 :15:5d:85:01:0f [ Network ] Address = 192 .168.131.1/24 Gateway = 192 .168.131.254 On active le routage car par d\u00e9faut le routage n'est pas activ\u00e9 sur linux : sysctl -w net.ipv4.ip_forward = 1 Rendre le param\u00e8tre persistant dans etc/sysctl.d/01-routage.conf : net.ipv4.ip_forward = 1 Mettre en place une r\u00e8gle de firewall pour enlever le message \"paquet filtr\u00e9\" : firewall-cmd --zone = trusted --add-source = 192 .168.0.0/16 --permanent Ajout d'une ou plusieurs routes statiques permanantes avec nmcli pour permettre \u00e0 plusieurs sous-r\u00e9seaux de communiquer entre eux : nmcli connection modify eth2 +ipv4.routes \"192.168.101.0/24 10.56.126.220\"","title":"Configuration r\u00e9seau"},{"location":"Linux/Master/Administration%20r%C3%A9seau/NMCLI/#configuration-reseau","text":"","title":"Configuration r\u00e9seau"},{"location":"Linux/Master/Administration%20r%C3%A9seau/NMCLI/#configuration-dune-ip-fixe-avec-nmcli","text":"Info nmcli est un outil qui permet de g\u00e9rer la configuration r\u00e9seau en interagissant avec le deamon NetworkManager . nmcli est utilis\u00e9 pour cr\u00e9er, afficher, modifier, supprimer, activer et d\u00e9sactiver les connexions r\u00e9seau, ainsi que pour contr\u00f4ler et afficher l'\u00e9tat des p\u00e9riph\u00e9riques r\u00e9seau. Pour ajouter une IP fixe, nmcli propose une gestion de profile permettant d'activer une configuration personnalis\u00e9e pour chaque r\u00e9seau souhait\u00e9. Ici, nous souhaitons avoir les informations suivantes : Adresse IP : 10.56.126.223 Masque : 255.255.255.0 Gateway : 10.56.126.254 DNS : 1.1.1.1 Ajout d'un profil pour une connexion ip fixe : nmcli connection add type ethernet con-name ipfixe ifname eth0 ipv4.addresses 10 .56.126.223/24 ipv4.gateway 10 .56.126.254 ipv4.dns 1 .1.1.1 ipv4.method manual On observe ensuite les diff\u00e9rentes connection avec nmcli connection show : 1 2 3 4 5 NAME UUID TYPE DEVICE ipfixe 693bdc04-28e0-4e83-9b58-fef659d8f33c ethernet eth0 docker0 0250129c-212a-4ecc-a7f3-35649a492f08 bridge docker0 lo 45cc8d65-2e4e-40ce-bdbd-1c90b23dada8 loopback lo eth0 40d5bcc8-ca0c-42a9-9fad-388b15a5e856 ethernet -- On active la connextion avec : nmcli connection up ipfixe","title":"Configuration d'une IP fixe avec nmcli"},{"location":"Linux/Master/Administration%20r%C3%A9seau/NMCLI/#network-manager","text":"Installation du package systemd-networkd pour obtenir la commande networkctl : dnf -y install systemd-networkd Pour observer les diff\u00e9rentes cartes r\u00e9seaux, on utlise networkctl : 1 2 3 4 5 6 IDX LINK TYPE OPERATIONAL SETUP 1 lo loopback carrier unmanaged 2 eth0 ether routable unmanaged 3 eth1 ether carrier unmanaged 4 docker0 bridge routable unmanaged 6 vethda849ef ether enslaved unmanaged Empecher le management des cartes tout le temps : Ajout d'un fichier dans /etc/NetworkManager/conf.d/99-unmanaged.conf [ keyfile ] unmanaged-devices = mac:00:15:5d:85:01:0f,mac:00:15:5d:85:01:10 Suppression des profiles avec nmcli : nmcli connection delete #nomdelaconnexion Configuration d'une carte avec un fichier de configuration dans /etc/systemd/network/ avec un fichier en .network : # Configuration du LAN 1 [ Match ] MACAddress = 00 :15:5d:85:01:0f [ Network ] Address = 192 .168.131.254/24 # Configuration du LAN 2 [ Match ] MACAddress = 00 :15:5d:85:01:10 [ Network ] Address = 192 .168.132.254/24 Tip Pour continuer le tp, on utilise 3 machines diff\u00e9rentes afin d'avoir la possibilit\u00e9 de communiquer entre elles. Modification des fichiers de configuration de network : # Configuration du LAN 1 [ Match ] MACAddress = 00 :15:5d:85:01:0f [ Network ] Address = 192 .168.131.1/24 Gateway = 192 .168.131.254 On active le routage car par d\u00e9faut le routage n'est pas activ\u00e9 sur linux : sysctl -w net.ipv4.ip_forward = 1 Rendre le param\u00e8tre persistant dans etc/sysctl.d/01-routage.conf : net.ipv4.ip_forward = 1 Mettre en place une r\u00e8gle de firewall pour enlever le message \"paquet filtr\u00e9\" : firewall-cmd --zone = trusted --add-source = 192 .168.0.0/16 --permanent Ajout d'une ou plusieurs routes statiques permanantes avec nmcli pour permettre \u00e0 plusieurs sous-r\u00e9seaux de communiquer entre eux : nmcli connection modify eth2 +ipv4.routes \"192.168.101.0/24 10.56.126.220\"","title":"Network Manager"},{"location":"Linux/Master/Administration%20r%C3%A9seau/SSH/","text":"S\u00e9curit\u00e9 de SSH \u00b6 Changement du port de SSH \u00b6 Warning Cette solution pour s\u00e9curiser SSH n'est pas recommand\u00e9 car cela ne procure pas beaucoup de s\u00e9curit\u00e9 Localisation du fichier de configguration de SSH /etc/ssh/sshd_config Pour modifier le port, on modifie la ligne : #Port 22 On enregistre ensuite le fichier et on execute la policy de SE linux : semanage port -a -t ssh_port_t -p tcp #PORTNUMBER On restart aussi le service : sudo systemctl restart sshd Fail2ban \u00b6 Info Pour chercher des packages qui ne sont pas pr\u00e9sent sur les dep\u00f4ts par d\u00e9faut : https://pkgs.org Installation d'un d\u00e9pot suppl\u00e9mentaire : dnf install epel-release On cherche le repo fail2ban et de quoi il est compos\u00e9: 1 2 dnf search fail2ban dnf info fail2ban Installation de bail2ban : dnf install fail2ban-firewalld Info Systemd \u00e0 la main sur cron, fstab, les services et aussi les logs Dans le service journald, on cherche les envois de logs avec grep Forward /etc/systemd/journald.conf . Cela nous retourne : 1 2 3 4 #ForwardToSyslog=no #ForwardToKMsg=no #ForwardToConsole=no #ForwardToWall=yes Pour obtenir les logs de sshd avec systemctl : journalctl --unit sshd.service Installation d'un package suppl\u00e9mentaire : dnf install -y fail2ban-systemd Tip Le service de fail2ban n'est pas en d\u00e9marrage automatique d\u00e8s son installation. Mise en route du service fail2ban : systemctl start fail2ban Observation des prisons fail2ban-client status : 1 2 3 Status | - Number of jail: 0 ` - Jail list: Localisation des fichiers de configuation des fichiers de fail2ban : /etc/fail2ban/ Interdiction On ne travaille pas sur le fichier de configuration direct, on utilise le dossier en .d \u00e0 la fin Affichage de pages de man install\u00e9es avec le package rpm -ql fail2ban-server | grep /man et on cherche la documentation sur les jails : 1 2 3 4 5 6 /usr/share/man/man1/fail2ban-client.1.gz /usr/share/man/man1/fail2ban-python.1.gz /usr/share/man/man1/fail2ban-regex.1.gz /usr/share/man/man1/fail2ban-server.1.gz /usr/share/man/man1/fail2ban.1.gz /usr/share/man/man5/jail.conf.5.gz Ajout d'un fichier de configuration dans le dossier jail.d : 1 2 3 4 5 6 7 8 [ sshd ] enabled = true # Mise en place d'un blocage de 30 minutes si il y a 5 essais erron\u00e9s en 5 minutes bantime = 1800 findtime = 300 maxretry = 5 On restart le service fail2ban : systemctl restart fail2ban.service On peut observer les jail: fail2ban-client get sshd banned On d\u00e9ban juste d'un jail avec la commande : fail2ban-cleint set sshd unbanip #ipdelamachine On d\u00e9ban une ip de toutes les jails: fail2ban-clent unban #ipdelamachine Info On d\u00e9sactive fail2ban pour la suite du tp. SSHGuard \u00b6 Recherche de SSHGuard : dnf search sshguard Dans la liste on cherche ce qui se rapporte au firewall : 1 2 3 4 5 6 ======================================== Nom correspond exactement \u00e0 : sshguard ======================================== sshguard.x86_64 : Protects hosts from brute-force attacks against SSH and other services ========================================= Nom & R\u00e9sum\u00e9 correspond \u00e0 : sshguard ========================================= sshguard-firewalld.x86_64 : Configuration for firewalld backend of SSHGuard sshguard-iptables.x86_64 : Configuration for iptables backend of SSHGuard sshguard-nftables.x86_64 : Configuration for nftables backend of SSHGuard PortKnocker \u00b6 Installation du serveur knock \u00b6 Info Port_knocker permet d\u2019ouvrir et de fermer les ports d\u2019une machine de fa\u00e7on dynamique. Il agit avec un client qui vient \"frapper\" \u00e0 la porte de la machine sur plusieurs ports. Si la s\u00e9quence est correcte, port-knocker ouvre le port qui correspond \u00e0 la s\u00e9quence pendant un certain temps avant de le d\u00e9sactiver. Recherche du pakcge knockd : dnf search knock Installation de knock et de son serveur : dnf -y install knock dnf -y install knock-server Tip Attention le service n'est pas d\u00e9marr\u00e9 par d\u00e9faut \u00e0 l'installation. Pour le d\u00e9marrer, utiliser : systemctl start knockd Localisation des fichiers de configurations : /etc/knockd.conf On observe le fichier de configuration : 1 2 3 4 5 6 7 8 9 10 [ options ] UseSyslog [ opencloseSSH ] sequence = 2222 :udp,3333:tcp,4444:udp seq_timeout = 15 tcpflags = syn,ack start_command = /sbin/iptables -A INPUT -s %IP% -p tcp --dport ssh -j ACCEPT cmd_timeout = 10 stop_command = /sbin/iptables -D INPUT -s %IP% -p tcp --dport ssh -j ACCEPT Sur la configuration, on observe la s\u00e9quence utilis\u00e9e avec les ports suivants: 2222:udp,3333:tcp,4444:udp . De plus, on remarque 2 commandes iptables permettant d'ajouter (option -A) et de supprimer (option -D) une ip dans le fichier iptables Warning Pour que le port knocking fontionne correctement, il faut que tout les ports de la machine soient ferm\u00e9s. On utlise la commade iptables pour fermer tout les ports : iptables -P INPUT DROP On r\u00e9alise notre propre fichier de configuration. Au pr\u00e9lable, comme il n'y a pas de dossier en .d pour faire des configurations annexe, on copie le fichier de configuration pour en faire une sauvegarde. Modification du fichier knockd.config : 1 2 3 4 5 6 7 [ opencloseSSH ] sequence = 2222 :tcp,3333:udp,4444:tcp seq_timeout = 15 start_command = /bin/firewall-cmd --zone = public --add-rich-rule 'rule family=ipv4 source address=%IP% service name=ssh accept' tcpflags = syn cmd_timeout = 10 stop_command = /bin/firewall-cmd --zone = public --remove-rich-rule 'rule family=ipv4 source address=%IP% service name=ssh accept' Warning Comme ici on utilise firewall-cmd , on d\u00e9sactive sur la zone publique ssh firewall-cmd --zone = public --remove-service = ssh Ici nous avons utilis\u00e9 firewall-cmd pour remplacer iptables . Les start_command et stop_command permettent d'ajouter avec les rich-rules le service SSH. Sur la s\u00e9quence, les ports sont en tcp et udp. Warning Lorsque le port n'est pas sp\u00e9cifi\u00e9, celui-ci prend par d\u00e9faut la valeur TCP .* Connexion avec knock \u00b6 Pour la connexion client, nous avons besoin du package knock . On toc \u00e0 la porte de la machine : knock 10 .56.126.74 2222 :tcp 3333 :udp 4444 :tcp Si on decompose la commande, on retrouve l'ip de destination puis les diff\u00e9rents ports avec les protocoles si ce n'est pas du TCP . Warning Une fois la commande de knock envoy\u00e9e, il faut envoyer la commande ssh dans le laps de temps o\u00f9 le port est ouvert","title":"S\u00e9curit\u00e9 de SSH"},{"location":"Linux/Master/Administration%20r%C3%A9seau/SSH/#securite-de-ssh","text":"","title":"S\u00e9curit\u00e9 de SSH"},{"location":"Linux/Master/Administration%20r%C3%A9seau/SSH/#changement-du-port-de-ssh","text":"Warning Cette solution pour s\u00e9curiser SSH n'est pas recommand\u00e9 car cela ne procure pas beaucoup de s\u00e9curit\u00e9 Localisation du fichier de configguration de SSH /etc/ssh/sshd_config Pour modifier le port, on modifie la ligne : #Port 22 On enregistre ensuite le fichier et on execute la policy de SE linux : semanage port -a -t ssh_port_t -p tcp #PORTNUMBER On restart aussi le service : sudo systemctl restart sshd","title":"Changement du port de SSH"},{"location":"Linux/Master/Administration%20r%C3%A9seau/SSH/#fail2ban","text":"Info Pour chercher des packages qui ne sont pas pr\u00e9sent sur les dep\u00f4ts par d\u00e9faut : https://pkgs.org Installation d'un d\u00e9pot suppl\u00e9mentaire : dnf install epel-release On cherche le repo fail2ban et de quoi il est compos\u00e9: 1 2 dnf search fail2ban dnf info fail2ban Installation de bail2ban : dnf install fail2ban-firewalld Info Systemd \u00e0 la main sur cron, fstab, les services et aussi les logs Dans le service journald, on cherche les envois de logs avec grep Forward /etc/systemd/journald.conf . Cela nous retourne : 1 2 3 4 #ForwardToSyslog=no #ForwardToKMsg=no #ForwardToConsole=no #ForwardToWall=yes Pour obtenir les logs de sshd avec systemctl : journalctl --unit sshd.service Installation d'un package suppl\u00e9mentaire : dnf install -y fail2ban-systemd Tip Le service de fail2ban n'est pas en d\u00e9marrage automatique d\u00e8s son installation. Mise en route du service fail2ban : systemctl start fail2ban Observation des prisons fail2ban-client status : 1 2 3 Status | - Number of jail: 0 ` - Jail list: Localisation des fichiers de configuation des fichiers de fail2ban : /etc/fail2ban/ Interdiction On ne travaille pas sur le fichier de configuration direct, on utilise le dossier en .d \u00e0 la fin Affichage de pages de man install\u00e9es avec le package rpm -ql fail2ban-server | grep /man et on cherche la documentation sur les jails : 1 2 3 4 5 6 /usr/share/man/man1/fail2ban-client.1.gz /usr/share/man/man1/fail2ban-python.1.gz /usr/share/man/man1/fail2ban-regex.1.gz /usr/share/man/man1/fail2ban-server.1.gz /usr/share/man/man1/fail2ban.1.gz /usr/share/man/man5/jail.conf.5.gz Ajout d'un fichier de configuration dans le dossier jail.d : 1 2 3 4 5 6 7 8 [ sshd ] enabled = true # Mise en place d'un blocage de 30 minutes si il y a 5 essais erron\u00e9s en 5 minutes bantime = 1800 findtime = 300 maxretry = 5 On restart le service fail2ban : systemctl restart fail2ban.service On peut observer les jail: fail2ban-client get sshd banned On d\u00e9ban juste d'un jail avec la commande : fail2ban-cleint set sshd unbanip #ipdelamachine On d\u00e9ban une ip de toutes les jails: fail2ban-clent unban #ipdelamachine Info On d\u00e9sactive fail2ban pour la suite du tp.","title":"Fail2ban"},{"location":"Linux/Master/Administration%20r%C3%A9seau/SSH/#sshguard","text":"Recherche de SSHGuard : dnf search sshguard Dans la liste on cherche ce qui se rapporte au firewall : 1 2 3 4 5 6 ======================================== Nom correspond exactement \u00e0 : sshguard ======================================== sshguard.x86_64 : Protects hosts from brute-force attacks against SSH and other services ========================================= Nom & R\u00e9sum\u00e9 correspond \u00e0 : sshguard ========================================= sshguard-firewalld.x86_64 : Configuration for firewalld backend of SSHGuard sshguard-iptables.x86_64 : Configuration for iptables backend of SSHGuard sshguard-nftables.x86_64 : Configuration for nftables backend of SSHGuard","title":"SSHGuard"},{"location":"Linux/Master/Administration%20r%C3%A9seau/SSH/#portknocker","text":"","title":"PortKnocker"},{"location":"Linux/Master/Administration%20r%C3%A9seau/SSH/#installation-du-serveur-knock","text":"Info Port_knocker permet d\u2019ouvrir et de fermer les ports d\u2019une machine de fa\u00e7on dynamique. Il agit avec un client qui vient \"frapper\" \u00e0 la porte de la machine sur plusieurs ports. Si la s\u00e9quence est correcte, port-knocker ouvre le port qui correspond \u00e0 la s\u00e9quence pendant un certain temps avant de le d\u00e9sactiver. Recherche du pakcge knockd : dnf search knock Installation de knock et de son serveur : dnf -y install knock dnf -y install knock-server Tip Attention le service n'est pas d\u00e9marr\u00e9 par d\u00e9faut \u00e0 l'installation. Pour le d\u00e9marrer, utiliser : systemctl start knockd Localisation des fichiers de configurations : /etc/knockd.conf On observe le fichier de configuration : 1 2 3 4 5 6 7 8 9 10 [ options ] UseSyslog [ opencloseSSH ] sequence = 2222 :udp,3333:tcp,4444:udp seq_timeout = 15 tcpflags = syn,ack start_command = /sbin/iptables -A INPUT -s %IP% -p tcp --dport ssh -j ACCEPT cmd_timeout = 10 stop_command = /sbin/iptables -D INPUT -s %IP% -p tcp --dport ssh -j ACCEPT Sur la configuration, on observe la s\u00e9quence utilis\u00e9e avec les ports suivants: 2222:udp,3333:tcp,4444:udp . De plus, on remarque 2 commandes iptables permettant d'ajouter (option -A) et de supprimer (option -D) une ip dans le fichier iptables Warning Pour que le port knocking fontionne correctement, il faut que tout les ports de la machine soient ferm\u00e9s. On utlise la commade iptables pour fermer tout les ports : iptables -P INPUT DROP On r\u00e9alise notre propre fichier de configuration. Au pr\u00e9lable, comme il n'y a pas de dossier en .d pour faire des configurations annexe, on copie le fichier de configuration pour en faire une sauvegarde. Modification du fichier knockd.config : 1 2 3 4 5 6 7 [ opencloseSSH ] sequence = 2222 :tcp,3333:udp,4444:tcp seq_timeout = 15 start_command = /bin/firewall-cmd --zone = public --add-rich-rule 'rule family=ipv4 source address=%IP% service name=ssh accept' tcpflags = syn cmd_timeout = 10 stop_command = /bin/firewall-cmd --zone = public --remove-rich-rule 'rule family=ipv4 source address=%IP% service name=ssh accept' Warning Comme ici on utilise firewall-cmd , on d\u00e9sactive sur la zone publique ssh firewall-cmd --zone = public --remove-service = ssh Ici nous avons utilis\u00e9 firewall-cmd pour remplacer iptables . Les start_command et stop_command permettent d'ajouter avec les rich-rules le service SSH. Sur la s\u00e9quence, les ports sont en tcp et udp. Warning Lorsque le port n'est pas sp\u00e9cifi\u00e9, celui-ci prend par d\u00e9faut la valeur TCP .*","title":"Installation du serveur knock"},{"location":"Linux/Master/Administration%20r%C3%A9seau/SSH/#connexion-avec-knock","text":"Pour la connexion client, nous avons besoin du package knock . On toc \u00e0 la porte de la machine : knock 10 .56.126.74 2222 :tcp 3333 :udp 4444 :tcp Si on decompose la commande, on retrouve l'ip de destination puis les diff\u00e9rents ports avec les protocoles si ce n'est pas du TCP . Warning Une fois la commande de knock envoy\u00e9e, il faut envoyer la commande ssh dans le laps de temps o\u00f9 le port est ouvert","title":"Connexion avec knock"},{"location":"Linux/Master/Conteneur%20et%20pipelines%20CICD/Docker-swarm/","text":"Docker Swarm \u00b6 Pr\u00e9sentation et d\u00e9finition des termes dans docker swarm \u00b6 Info Ici on aborde docker swarm qui est une solution de virtualisation de conteneur. Cette solution fonctionne diff\u00e9rement que Kubernetes. Les nodes sont des noeuds. On manipule les nodes avec les commandes qui commencent par docker node COMMAND . On obtient les options suivantes : Commands: demote Demote one or more nodes from manager in the swarm inspect Display detailed information on one or more nodes ls List nodes in the swarm promote Promote one or more nodes to manager in the swarm ps List tasks running on one or more nodes, defaults to current node rm Remove one or more nodes from the swarm update Update a node Le swarm est un cluster. C'est orchestrateur de serveur docker. On demande au cluster d'excuter une t\u00e2che qui s'appelle un service . Lorsque on d\u00e9ploie un service, l'orchestrateur va executer une t\u00e2che . Cette t\u00e2che est un conteneur ex\u00e9cut\u00e9 sur une machine que nous ne connaissons pas car l'orchestrateur va d\u00e9cider sans nous en faire part. Sch\u00e9ma du swarm Info sur les managers Par d\u00e9faut, dans docker swarm, le manager est aussi un worker . D\u00e9marrage de docker swarm \u00b6 D\u00e9marrage de son propre cluster \u00b6 D\u00e9marrage d'un swarm : docker swarm init Attention lors d'une configuration avec plusieurs cartes r\u00e9seau Si vous avez plusieurs cartes r\u00e9seau, il faut en sp\u00e9cifier une carte via l'option --advertise-addr : docker swarm init --advertise-addr eth2 Partir d'un cluster \u00b6 Si on doit rejoindre un nouveau cluster, on doit partir de son cluster cr\u00e9e pr\u00e9cedement. On utilise la commande : docker swarm leave --force Info Ici on utilise le param\u00e8tre --force pour forcer de quitter le cluster. On obtient un message de confirmation : [ root@LG-stream9-1 ~ ] # docker swarm leave -f Node left the swarm. Rejoindre un cluster existant \u00b6 Pour rejoindre un cluster, on utilise les commandes docker swarm : Commands: ca Display and rotate the root CA init Initialize a swarm join Join a swarm as a node and/or manager join-token Manage join tokens leave Leave the swarm unlock Unlock swarm unlock-key Manage the unlock key update Update the swarm Ici on ouvre le firewall pour le r\u00e9seau interne avec firewall-cmd : firewall-cmd --zone = trusted --add-source = 10 .56.126.0/24 --permanent On arrive dans un cluster avec un r\u00f4le de worker . Pour promouvoir une machine en manager , on utilise : docker node promote ID Lancement d'un premier service \u00b6 Le lancement d'un service se fait avec : docker service create [ OPTIONS ] IMAGE [ COMMAND ] [ ARG... ] Exemple de cr\u00e9ation : docker service create --name test --publish 80 :80 containous/whoami Pour dupliquer le service, on utilise : docker service scale test = 5 Info Ici on ajoute 4 services en plus On peux voir les logs avec docker service ps test : ID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR PORTS y8czfynfhgw4 test.1 containous/whoami:latest alma9-jg.local Running Running 6 minutes ago 0ri8oj6ixygl test.2 containous/whoami:latest alma9-AC Running Running 4 minutes ago vdzrheeflpo2 test.3 containous/whoami:latest alma9-fm.local Running Running 4 minutes ago mzrx1dcukyd0 test.4 containous/whoami:latest LG-stream9-1.local Running Running 22 seconds ago df8zp8cp3tqn \\_ test.4 containous/whoami:latest stream-anto Shutdown Running 4 minutes ago bzmko7hsn59j test.5 containous/whoami:latest LG-stream9-1.local Running Running 2 minutes ago lt35aa0y1pwi \\_ test.5 containous/whoami:latest alma9-1-vg.formation.local Shutdown Shutdown 2 minutes ago 3uxy6hqg364r \\_ test.5 containous/whoami:latest alma9-1-vg.formation.local Shutdown Rejected 3 minutes ago \"No such image: containous/who\u2026\" Des probl\u00e8mes dans des noeuds Ici on a la machine alma9-1-vg.formation.local qui \u00e0 un probl\u00e8me de DNS. On a pass\u00e9 la machine en DRAIN . Cela veux dire qu'il prend uniquements des t\u00e2ches de management. Tip docker node update --availability drain alma9-1-vg.formation.local Le service est donc report\u00e9 sur un autre noeud : LG-stream9-1.local Si un noeud est down, docker swarm reporte encore le service vers un autre noeud. On r\u00e9alise une mise \u00e0 jour des noeuds afin de d\u00e9ployer une nouvelle application. Dans un premier temps, on change le parall\u00e9lisme et le delai lors des mises \u00e0 jours : docker service update --detach --update-deplay 2s --update-parallelism 1 test On met en suite en place la nouvelle application : docker service update --detach --image traefik/whoami test L'option rollback On peux faire un rollback d'une ancienne configuration : docker service rollback test On peux trier les outputs avec : docker service ps -f \"desired-state=running\" test Cr\u00e9ation d'un service via un fichier de compose.yml \u00b6 Cr\u00e9ation du fichier de compose.yml : 1 2 3 4 5 6 7 8 9 10 11 12 version : \"3.9\" services : whoami : image : \"containous/whoami\" container_name : \"lguilloux-whoami\" ports : - \"8003:80\" deploy : mode : replicated replicas : 12 Info On peux utiliser plusieurs options : mode: global qui permet de d\u00e9ployer sur tout les noeuds mode: replicated qui demande une option suppl\u00e9mentaire avec le nombre de r\u00e9plicats avec replicas: 12 Failure Si on passe d'un mode global \u00e0 un mode replicated, il faut absolument enlever le service pour ensuite le recr\u00e9er. Attention \u00e0 la rapidit\u00e9 d'exection qui peut-\u00eatre probl\u00e9matique lors de la nouvelle cr\u00e9ation du network Lancement du service avec : docker stack deploy -c compose.yml leo Pour observer, les services on peux utliser 2 commandes : docker stack services [NOM_DU_SERVICE] docker service ls Emplacement des fichiers de swarm On retrouve tout les fichiers de swarm dans le dossier suivant /var/lib/docker/swarm/ : ls -trl /var/lib/docker/swarm/ Sortie de la commande avec tout les fichiers : total 20 -rw-------. 1 root root 213 20 mars 13 :54 docker-state.json drwxr-xr-x. 2 root root 4096 20 mars 13 :54 worker drwxr-xr-x. 2 root root 4096 20 mars 13 :54 certificates drwx------. 4 root root 4096 20 mars 13 :54 raft -rw-------. 1 root root 69 20 mars 13 :54 state.json D\u00e9ploiement d'un traefik avec docker swarm \u00b6 Modification du compose.yml : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 version : '3.9' networks : traefik-net : name : traefik-net services : proxy : image : traefik:latest command : |- --providers.docker.swarmMode=true --providers.docker.exposedByDefault=false --log.level=debug --entryPoints.http.address=:80 --api.insecure=true --api.dashboard=true networks : - traefik-net ports : - published : 80 target : 80 protocol : tcp volumes : - type : bind source : /var/run/docker.sock target : /var/run/docker.sock deploy : labels : - traefik.enable=true - \"traefik.http.routers.dashboard.rule=PathPrefix(`/traefik`) || PathPrefix(`/api`)\" - \"traefik.http.routers.dashboard.service=api@internal\" - \"traefik.http.middlewares.dashboard-stripprefix.stripprefix.prefixes=/traefik\" - \"traefik.http.routers.dashboard.middlewares=auth-dashboard,dashboard-stripprefix\" - \"traefik.http.middlewares.auth-dashboard.basicauth.users=dashuser:$$apr1$$nWuK9JVS$$Cm580WakVYahBvJyVuYNI1\" - \"traefik.http.services.dashboard.loadbalancer.server.port=8080\" whoami : image : traefik/whoami networks : - traefik-net deploy : labels : - traefik.http.routers.whoami.rule=Path(`/whoami`) - traefik.http.services.whoami.loadbalancer.server.port=80 Mise en place d'un cleaner via gitlab \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 #!/bin/bash PROJECT_PATH = cs2ip16/valentin/srvdoc TOKEN = $( cat token_gitlab.txt ) curl -s --header \"PRIVATE-TOKEN: ${ TOKEN } \" \"https://gitlab.com/api/v4/projects/ ${ PROJECT_PATH // \\/ /%2F } /registry/repositories\" > /tmp/repo. $$ .json REPO_ID = $( jq '.[].id' < /tmp/repo. $$ .json ) PROJECT_ID = $( jq '.[].project_id' < /tmp/repo. $$ .json ) #GET /projects/:id/registry/repositories/:repository_id/tags curl -s --header \"PRIVATE-TOKEN: ${ TOKEN } \" \"https://gitlab.com/api/v4/projects/ ${ PROJECT_ID } /registry/repositories/ ${ REPO_ID } /tags\" > /tmp/tags. $$ .json jq < /tmp/tags. $$ .json #rm -f /tmp/repo.$$.json Mise en place des \u00e9l\u00e9ments de configurations et de secrets \u00b6 Info Pour plus d'information concernant les syntaxes courtes et longues, le document de r\u00e9f\u00e9rence est : https://docs.docker.com/compose/compose-file/#configs 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 version : \"3.9\" configs : maconfig : file : ./fichier-de-config.txt secrets : token1 : file : ./montoken.txt services : test : image : alpine:3.17 configs : - source : maconfig target : /etc/config-test uid : \"100\" gid : \"100\" mode : 0440 command : | sh -c \" ls -l /etc/config-test echo la config est : cat /etc/config-test\"","title":"Docker Swarm"},{"location":"Linux/Master/Conteneur%20et%20pipelines%20CICD/Docker-swarm/#docker-swarm","text":"","title":"Docker Swarm"},{"location":"Linux/Master/Conteneur%20et%20pipelines%20CICD/Docker-swarm/#presentation-et-definition-des-termes-dans-docker-swarm","text":"Info Ici on aborde docker swarm qui est une solution de virtualisation de conteneur. Cette solution fonctionne diff\u00e9rement que Kubernetes. Les nodes sont des noeuds. On manipule les nodes avec les commandes qui commencent par docker node COMMAND . On obtient les options suivantes : Commands: demote Demote one or more nodes from manager in the swarm inspect Display detailed information on one or more nodes ls List nodes in the swarm promote Promote one or more nodes to manager in the swarm ps List tasks running on one or more nodes, defaults to current node rm Remove one or more nodes from the swarm update Update a node Le swarm est un cluster. C'est orchestrateur de serveur docker. On demande au cluster d'excuter une t\u00e2che qui s'appelle un service . Lorsque on d\u00e9ploie un service, l'orchestrateur va executer une t\u00e2che . Cette t\u00e2che est un conteneur ex\u00e9cut\u00e9 sur une machine que nous ne connaissons pas car l'orchestrateur va d\u00e9cider sans nous en faire part. Sch\u00e9ma du swarm Info sur les managers Par d\u00e9faut, dans docker swarm, le manager est aussi un worker .","title":"Pr\u00e9sentation et d\u00e9finition des termes dans docker swarm"},{"location":"Linux/Master/Conteneur%20et%20pipelines%20CICD/Docker-swarm/#demarrage-de-docker-swarm","text":"","title":"D\u00e9marrage de docker swarm"},{"location":"Linux/Master/Conteneur%20et%20pipelines%20CICD/Docker-swarm/#demarrage-de-son-propre-cluster","text":"D\u00e9marrage d'un swarm : docker swarm init Attention lors d'une configuration avec plusieurs cartes r\u00e9seau Si vous avez plusieurs cartes r\u00e9seau, il faut en sp\u00e9cifier une carte via l'option --advertise-addr : docker swarm init --advertise-addr eth2","title":"D\u00e9marrage de son propre cluster"},{"location":"Linux/Master/Conteneur%20et%20pipelines%20CICD/Docker-swarm/#partir-dun-cluster","text":"Si on doit rejoindre un nouveau cluster, on doit partir de son cluster cr\u00e9e pr\u00e9cedement. On utilise la commande : docker swarm leave --force Info Ici on utilise le param\u00e8tre --force pour forcer de quitter le cluster. On obtient un message de confirmation : [ root@LG-stream9-1 ~ ] # docker swarm leave -f Node left the swarm.","title":"Partir d'un cluster"},{"location":"Linux/Master/Conteneur%20et%20pipelines%20CICD/Docker-swarm/#rejoindre-un-cluster-existant","text":"Pour rejoindre un cluster, on utilise les commandes docker swarm : Commands: ca Display and rotate the root CA init Initialize a swarm join Join a swarm as a node and/or manager join-token Manage join tokens leave Leave the swarm unlock Unlock swarm unlock-key Manage the unlock key update Update the swarm Ici on ouvre le firewall pour le r\u00e9seau interne avec firewall-cmd : firewall-cmd --zone = trusted --add-source = 10 .56.126.0/24 --permanent On arrive dans un cluster avec un r\u00f4le de worker . Pour promouvoir une machine en manager , on utilise : docker node promote ID","title":"Rejoindre un cluster existant"},{"location":"Linux/Master/Conteneur%20et%20pipelines%20CICD/Docker-swarm/#lancement-dun-premier-service","text":"Le lancement d'un service se fait avec : docker service create [ OPTIONS ] IMAGE [ COMMAND ] [ ARG... ] Exemple de cr\u00e9ation : docker service create --name test --publish 80 :80 containous/whoami Pour dupliquer le service, on utilise : docker service scale test = 5 Info Ici on ajoute 4 services en plus On peux voir les logs avec docker service ps test : ID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR PORTS y8czfynfhgw4 test.1 containous/whoami:latest alma9-jg.local Running Running 6 minutes ago 0ri8oj6ixygl test.2 containous/whoami:latest alma9-AC Running Running 4 minutes ago vdzrheeflpo2 test.3 containous/whoami:latest alma9-fm.local Running Running 4 minutes ago mzrx1dcukyd0 test.4 containous/whoami:latest LG-stream9-1.local Running Running 22 seconds ago df8zp8cp3tqn \\_ test.4 containous/whoami:latest stream-anto Shutdown Running 4 minutes ago bzmko7hsn59j test.5 containous/whoami:latest LG-stream9-1.local Running Running 2 minutes ago lt35aa0y1pwi \\_ test.5 containous/whoami:latest alma9-1-vg.formation.local Shutdown Shutdown 2 minutes ago 3uxy6hqg364r \\_ test.5 containous/whoami:latest alma9-1-vg.formation.local Shutdown Rejected 3 minutes ago \"No such image: containous/who\u2026\" Des probl\u00e8mes dans des noeuds Ici on a la machine alma9-1-vg.formation.local qui \u00e0 un probl\u00e8me de DNS. On a pass\u00e9 la machine en DRAIN . Cela veux dire qu'il prend uniquements des t\u00e2ches de management. Tip docker node update --availability drain alma9-1-vg.formation.local Le service est donc report\u00e9 sur un autre noeud : LG-stream9-1.local Si un noeud est down, docker swarm reporte encore le service vers un autre noeud. On r\u00e9alise une mise \u00e0 jour des noeuds afin de d\u00e9ployer une nouvelle application. Dans un premier temps, on change le parall\u00e9lisme et le delai lors des mises \u00e0 jours : docker service update --detach --update-deplay 2s --update-parallelism 1 test On met en suite en place la nouvelle application : docker service update --detach --image traefik/whoami test L'option rollback On peux faire un rollback d'une ancienne configuration : docker service rollback test On peux trier les outputs avec : docker service ps -f \"desired-state=running\" test","title":"Lancement d'un premier service"},{"location":"Linux/Master/Conteneur%20et%20pipelines%20CICD/Docker-swarm/#creation-dun-service-via-un-fichier-de-composeyml","text":"Cr\u00e9ation du fichier de compose.yml : 1 2 3 4 5 6 7 8 9 10 11 12 version : \"3.9\" services : whoami : image : \"containous/whoami\" container_name : \"lguilloux-whoami\" ports : - \"8003:80\" deploy : mode : replicated replicas : 12 Info On peux utiliser plusieurs options : mode: global qui permet de d\u00e9ployer sur tout les noeuds mode: replicated qui demande une option suppl\u00e9mentaire avec le nombre de r\u00e9plicats avec replicas: 12 Failure Si on passe d'un mode global \u00e0 un mode replicated, il faut absolument enlever le service pour ensuite le recr\u00e9er. Attention \u00e0 la rapidit\u00e9 d'exection qui peut-\u00eatre probl\u00e9matique lors de la nouvelle cr\u00e9ation du network Lancement du service avec : docker stack deploy -c compose.yml leo Pour observer, les services on peux utliser 2 commandes : docker stack services [NOM_DU_SERVICE] docker service ls Emplacement des fichiers de swarm On retrouve tout les fichiers de swarm dans le dossier suivant /var/lib/docker/swarm/ : ls -trl /var/lib/docker/swarm/ Sortie de la commande avec tout les fichiers : total 20 -rw-------. 1 root root 213 20 mars 13 :54 docker-state.json drwxr-xr-x. 2 root root 4096 20 mars 13 :54 worker drwxr-xr-x. 2 root root 4096 20 mars 13 :54 certificates drwx------. 4 root root 4096 20 mars 13 :54 raft -rw-------. 1 root root 69 20 mars 13 :54 state.json","title":"Cr\u00e9ation d'un service via un fichier de compose.yml"},{"location":"Linux/Master/Conteneur%20et%20pipelines%20CICD/Docker-swarm/#deploiement-dun-traefik-avec-docker-swarm","text":"Modification du compose.yml : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 version : '3.9' networks : traefik-net : name : traefik-net services : proxy : image : traefik:latest command : |- --providers.docker.swarmMode=true --providers.docker.exposedByDefault=false --log.level=debug --entryPoints.http.address=:80 --api.insecure=true --api.dashboard=true networks : - traefik-net ports : - published : 80 target : 80 protocol : tcp volumes : - type : bind source : /var/run/docker.sock target : /var/run/docker.sock deploy : labels : - traefik.enable=true - \"traefik.http.routers.dashboard.rule=PathPrefix(`/traefik`) || PathPrefix(`/api`)\" - \"traefik.http.routers.dashboard.service=api@internal\" - \"traefik.http.middlewares.dashboard-stripprefix.stripprefix.prefixes=/traefik\" - \"traefik.http.routers.dashboard.middlewares=auth-dashboard,dashboard-stripprefix\" - \"traefik.http.middlewares.auth-dashboard.basicauth.users=dashuser:$$apr1$$nWuK9JVS$$Cm580WakVYahBvJyVuYNI1\" - \"traefik.http.services.dashboard.loadbalancer.server.port=8080\" whoami : image : traefik/whoami networks : - traefik-net deploy : labels : - traefik.http.routers.whoami.rule=Path(`/whoami`) - traefik.http.services.whoami.loadbalancer.server.port=80","title":"D\u00e9ploiement d'un traefik avec docker swarm"},{"location":"Linux/Master/Conteneur%20et%20pipelines%20CICD/Docker-swarm/#mise-en-place-dun-cleaner-via-gitlab","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 #!/bin/bash PROJECT_PATH = cs2ip16/valentin/srvdoc TOKEN = $( cat token_gitlab.txt ) curl -s --header \"PRIVATE-TOKEN: ${ TOKEN } \" \"https://gitlab.com/api/v4/projects/ ${ PROJECT_PATH // \\/ /%2F } /registry/repositories\" > /tmp/repo. $$ .json REPO_ID = $( jq '.[].id' < /tmp/repo. $$ .json ) PROJECT_ID = $( jq '.[].project_id' < /tmp/repo. $$ .json ) #GET /projects/:id/registry/repositories/:repository_id/tags curl -s --header \"PRIVATE-TOKEN: ${ TOKEN } \" \"https://gitlab.com/api/v4/projects/ ${ PROJECT_ID } /registry/repositories/ ${ REPO_ID } /tags\" > /tmp/tags. $$ .json jq < /tmp/tags. $$ .json #rm -f /tmp/repo.$$.json","title":"Mise en place d'un cleaner via gitlab"},{"location":"Linux/Master/Conteneur%20et%20pipelines%20CICD/Docker-swarm/#mise-en-place-des-elements-de-configurations-et-de-secrets","text":"Info Pour plus d'information concernant les syntaxes courtes et longues, le document de r\u00e9f\u00e9rence est : https://docs.docker.com/compose/compose-file/#configs 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 version : \"3.9\" configs : maconfig : file : ./fichier-de-config.txt secrets : token1 : file : ./montoken.txt services : test : image : alpine:3.17 configs : - source : maconfig target : /etc/config-test uid : \"100\" gid : \"100\" mode : 0440 command : | sh -c \" ls -l /etc/config-test echo la config est : cat /etc/config-test\"","title":"Mise en place des \u00e9l\u00e9ments de configurations et de secrets"},{"location":"Linux/Master/Conteneur%20et%20pipelines%20CICD/Docker/","text":"Docker \u00b6 Pr\u00e9paration de l'installation docker \u00b6 Cr\u00e9ation d'un syst\u00e8me de fichier \u00b6 Cr\u00e9ation d'un dossier /var/lib/docker : mkdir -p /var/lib/docker Cr\u00e9ation d'un d'un volume groupe : lvcreate -L 5G -n rootvg/lvdocker Tip option -L pour sp\u00e9cifier la taille (ou sinon l'option --size ) option -n pour sp\u00e9cifier le nom du volume groupe V\u00e9rification de la cr\u00e9ation du volume groupe avec lvscan : ACTIVE '/dev/rootvg/rootlv' [ 32 ,50 GiB ] inherit ACTIVE '/dev/rootvg/lvdocker' [ 5 ,00 GiB ] inherit Formatage du volume en ext4 : mkfs.ext4 /dev/rootvg/lvdocker Enregistrement du fichier dans fstab : echo \"/dev/rootvg/lvdocker /var/lib/docker ext4 defaults\" >> /etc/fstab Montage du volume : mount -a V\u00e9rification du montage avec df : /dev/mapper/rootvg-lvdocker 5074592 24 4796040 1 % /var/lib/docker Installation de docker \u00b6 R\u00e9cup\u00e9ration du fichier d'installation docker : curl -sSL https://get.docker.com > get-docker.sh Ex\u00e9cution du script : bash get-docker.sh Si la machine est en almalinux, on modifie le script pour autoriser l'installation du alma : 350 : almalinux | centos | rhel | sles ) 458 : almalinux | centos | fedora | rhel ) Failure Si on excute le script modifi\u00e9, on obtiendra une erreur sur les repository de docker. La solution n'est pas maintenable !!! R\u00e9cup\u00e9ration du repo : curl -s https://download.docker.com/linux/centos/docker-ce.repo > /etc/yum.repos.d/docker-ce.repo Installation de docker : dnf -y install docker-ce Cr\u00e9ation d'une arbor\u00e9sence : \u251c\u2500\u2500 docker \u2502 \u2514\u2500\u2500 compose \u2502 \u2514\u2500\u2500 test Activation du service et du socket : systemctl enable --now docker.socket systemctl enable --now docker.service Test du docker compose V2 \u00b6 Docker compose prend en charge 4 noms de fichier : docker-compose.yml docker-compose.yaml compose.yml compose.yaml Cr\u00e9ation d'un fichier /root/docker/compose/test/compose.yml : services: app: image: traefik/whoami ports: - published: 8080 target: 80 Test de la configuration avec : docker compose config docker compose convert Activation du conteneur avec docker compose : docker compose up -d Tip L'option -d permet de lancer le conteneur en mode d\u00e9tach\u00e9 pour ne pas voir les logs Verification du lancement du conteneur avec docker container ls : CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 36a318e3ec0e traefik/whoami \"/whoami\" 2 minutes ago Up 2 minutes 0 .0.0.0:8080->80/tcp, :::8080->80/tcp test-app-1 Docker compose et les builds \u00b6 Cr\u00e9ation d'un dossier sitedoc , build ainsi que de 2 fichiers suppl\u00e9mentaires: . \u251c\u2500\u2500 sitedoc \u2502 \u251c\u2500\u2500 build \u2502 \u2502 \u2514\u2500\u2500 Dockerfile \u2502 \u2514\u2500\u2500 compose.yml Mise en place du fichier dockerfile : FROM registry.actilis.net/docker-images/httpd:2.4-alpine Mise en place du compose.yml services : app : #image: build : context : build dockerfile : Dockerfile ports : - published : 8080 target : 80 Tip Pour la d\u00e9claration des ports, 2 synthaxes sont possibles avec une short et une long Documentation de docker disponible : Ref\u00e9rence docker Pour forcer un rebuild d'un docker compose, la commande \u00e0 un ajout d'une option pour forcer le build : docker compose up -d --build Modification de docker file pour ajouter le contenu d'un dossier : FROM registry.actilis.net/docker-images/httpd:2.4-alpine COPY site-content/ /var/www/html Ajout du dossier site-content et d'un fichier d'index.html : . \u251c\u2500\u2500 build \u2502 \u251c\u2500\u2500 Dockerfile \u2502 \u2514\u2500\u2500 site-content \u2502 \u2514\u2500\u2500 index.html \u2514\u2500\u2500 compose.yml Docker compose et mkdocs \u00b6 Ajout d'un fichier mkdocs.yml dans le dossier build et ajout de la configuration. Ajout d'un dockerfile : #### Build en deux \u00e9tapes ## Premi\u00e8re \u00e9tape : Compiler la documentation dans un dossier FROM registry.actilis.net/docker-images/mkdocs:latest as constructeur COPY .git .git COPY mkdocs.yml /docs COPY src /docs/src #COPY includes /docs/includes RUN mkdocs build ## Deuxi\u00e8me \u00e9tape : Construire l'image bas\u00e9e sur nginx FROM registry.actilis.net/docker-images/httpd:2.4-alpine COPY --from = constructeur --chown = www-data /docs/site /var/www/html Ajout d'un docker compose pour directement lancer l'application : services: dev-serv: image: registry.actilis.net/docker-images/mkdocs:latest command: serve -a 0.0.0.0:80 restart: on-failure ports: - 8000:80 volumes: - ./:/docs Cr\u00e9ation d'un makefile : serve: docker compose -f dev.yml up -d build: docker compose build deploy: docker compose up -d --build Configuration de Github pour l'envoie d'images \u00b6 Info On cherche \u00e0 uploder une image docker faite maison sur github. On g\u00e9n\u00e8re une cl\u00e9 d'acc\u00e8s avec Github dans : Settings du compte Developer settings Personal acess tokens Generate new token Warning A la cr\u00e9ation du token, github affiche 1 seule et unique fois le token . Il faut absolument garder ce token hors d'un environement sous git !! Connexion \u00e0 git : docker login ghcr.io -u poseidon974 --password-stdin < /home/user/token.txt Modification du docker compose : 1 2 3 4 5 6 7 8 9 services: app: image: ghcr.io/poseidon974/cours: ${ VERSION :- latest } build: context: ./ dockerfile: Dockerfile ports: - published: 8080 target: 80 Modification du makefile : build : docker compose build docker compose push Pour push et build on utilise la commande : make build On push build et push directement sur github. On peux retrouver les package : https://github.com/USERNAME?tab=packages","title":"Docker"},{"location":"Linux/Master/Conteneur%20et%20pipelines%20CICD/Docker/#docker","text":"","title":"Docker"},{"location":"Linux/Master/Conteneur%20et%20pipelines%20CICD/Docker/#preparation-de-linstallation-docker","text":"","title":"Pr\u00e9paration de l'installation docker"},{"location":"Linux/Master/Conteneur%20et%20pipelines%20CICD/Docker/#creation-dun-systeme-de-fichier","text":"Cr\u00e9ation d'un dossier /var/lib/docker : mkdir -p /var/lib/docker Cr\u00e9ation d'un d'un volume groupe : lvcreate -L 5G -n rootvg/lvdocker Tip option -L pour sp\u00e9cifier la taille (ou sinon l'option --size ) option -n pour sp\u00e9cifier le nom du volume groupe V\u00e9rification de la cr\u00e9ation du volume groupe avec lvscan : ACTIVE '/dev/rootvg/rootlv' [ 32 ,50 GiB ] inherit ACTIVE '/dev/rootvg/lvdocker' [ 5 ,00 GiB ] inherit Formatage du volume en ext4 : mkfs.ext4 /dev/rootvg/lvdocker Enregistrement du fichier dans fstab : echo \"/dev/rootvg/lvdocker /var/lib/docker ext4 defaults\" >> /etc/fstab Montage du volume : mount -a V\u00e9rification du montage avec df : /dev/mapper/rootvg-lvdocker 5074592 24 4796040 1 % /var/lib/docker","title":"Cr\u00e9ation d'un syst\u00e8me de fichier"},{"location":"Linux/Master/Conteneur%20et%20pipelines%20CICD/Docker/#installation-de-docker","text":"R\u00e9cup\u00e9ration du fichier d'installation docker : curl -sSL https://get.docker.com > get-docker.sh Ex\u00e9cution du script : bash get-docker.sh Si la machine est en almalinux, on modifie le script pour autoriser l'installation du alma : 350 : almalinux | centos | rhel | sles ) 458 : almalinux | centos | fedora | rhel ) Failure Si on excute le script modifi\u00e9, on obtiendra une erreur sur les repository de docker. La solution n'est pas maintenable !!! R\u00e9cup\u00e9ration du repo : curl -s https://download.docker.com/linux/centos/docker-ce.repo > /etc/yum.repos.d/docker-ce.repo Installation de docker : dnf -y install docker-ce Cr\u00e9ation d'une arbor\u00e9sence : \u251c\u2500\u2500 docker \u2502 \u2514\u2500\u2500 compose \u2502 \u2514\u2500\u2500 test Activation du service et du socket : systemctl enable --now docker.socket systemctl enable --now docker.service","title":"Installation de docker"},{"location":"Linux/Master/Conteneur%20et%20pipelines%20CICD/Docker/#test-du-docker-compose-v2","text":"Docker compose prend en charge 4 noms de fichier : docker-compose.yml docker-compose.yaml compose.yml compose.yaml Cr\u00e9ation d'un fichier /root/docker/compose/test/compose.yml : services: app: image: traefik/whoami ports: - published: 8080 target: 80 Test de la configuration avec : docker compose config docker compose convert Activation du conteneur avec docker compose : docker compose up -d Tip L'option -d permet de lancer le conteneur en mode d\u00e9tach\u00e9 pour ne pas voir les logs Verification du lancement du conteneur avec docker container ls : CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 36a318e3ec0e traefik/whoami \"/whoami\" 2 minutes ago Up 2 minutes 0 .0.0.0:8080->80/tcp, :::8080->80/tcp test-app-1","title":"Test du docker compose V2"},{"location":"Linux/Master/Conteneur%20et%20pipelines%20CICD/Docker/#docker-compose-et-les-builds","text":"Cr\u00e9ation d'un dossier sitedoc , build ainsi que de 2 fichiers suppl\u00e9mentaires: . \u251c\u2500\u2500 sitedoc \u2502 \u251c\u2500\u2500 build \u2502 \u2502 \u2514\u2500\u2500 Dockerfile \u2502 \u2514\u2500\u2500 compose.yml Mise en place du fichier dockerfile : FROM registry.actilis.net/docker-images/httpd:2.4-alpine Mise en place du compose.yml services : app : #image: build : context : build dockerfile : Dockerfile ports : - published : 8080 target : 80 Tip Pour la d\u00e9claration des ports, 2 synthaxes sont possibles avec une short et une long Documentation de docker disponible : Ref\u00e9rence docker Pour forcer un rebuild d'un docker compose, la commande \u00e0 un ajout d'une option pour forcer le build : docker compose up -d --build Modification de docker file pour ajouter le contenu d'un dossier : FROM registry.actilis.net/docker-images/httpd:2.4-alpine COPY site-content/ /var/www/html Ajout du dossier site-content et d'un fichier d'index.html : . \u251c\u2500\u2500 build \u2502 \u251c\u2500\u2500 Dockerfile \u2502 \u2514\u2500\u2500 site-content \u2502 \u2514\u2500\u2500 index.html \u2514\u2500\u2500 compose.yml","title":"Docker compose et les builds"},{"location":"Linux/Master/Conteneur%20et%20pipelines%20CICD/Docker/#docker-compose-et-mkdocs","text":"Ajout d'un fichier mkdocs.yml dans le dossier build et ajout de la configuration. Ajout d'un dockerfile : #### Build en deux \u00e9tapes ## Premi\u00e8re \u00e9tape : Compiler la documentation dans un dossier FROM registry.actilis.net/docker-images/mkdocs:latest as constructeur COPY .git .git COPY mkdocs.yml /docs COPY src /docs/src #COPY includes /docs/includes RUN mkdocs build ## Deuxi\u00e8me \u00e9tape : Construire l'image bas\u00e9e sur nginx FROM registry.actilis.net/docker-images/httpd:2.4-alpine COPY --from = constructeur --chown = www-data /docs/site /var/www/html Ajout d'un docker compose pour directement lancer l'application : services: dev-serv: image: registry.actilis.net/docker-images/mkdocs:latest command: serve -a 0.0.0.0:80 restart: on-failure ports: - 8000:80 volumes: - ./:/docs Cr\u00e9ation d'un makefile : serve: docker compose -f dev.yml up -d build: docker compose build deploy: docker compose up -d --build","title":"Docker compose et mkdocs"},{"location":"Linux/Master/Conteneur%20et%20pipelines%20CICD/Docker/#configuration-de-github-pour-lenvoie-dimages","text":"Info On cherche \u00e0 uploder une image docker faite maison sur github. On g\u00e9n\u00e8re une cl\u00e9 d'acc\u00e8s avec Github dans : Settings du compte Developer settings Personal acess tokens Generate new token Warning A la cr\u00e9ation du token, github affiche 1 seule et unique fois le token . Il faut absolument garder ce token hors d'un environement sous git !! Connexion \u00e0 git : docker login ghcr.io -u poseidon974 --password-stdin < /home/user/token.txt Modification du docker compose : 1 2 3 4 5 6 7 8 9 services: app: image: ghcr.io/poseidon974/cours: ${ VERSION :- latest } build: context: ./ dockerfile: Dockerfile ports: - published: 8080 target: 80 Modification du makefile : build : docker compose build docker compose push Pour push et build on utilise la commande : make build On push build et push directement sur github. On peux retrouver les package : https://github.com/USERNAME?tab=packages","title":"Configuration de Github pour l'envoie d'images"},{"location":"Linux/Master/Conteneur%20et%20pipelines%20CICD/Runners/","text":"Deploiement de runners et execution de pipelines \u00b6 Gitlab \u00b6 Objectifs On cherche \u00e0 utiliser un seul et unqiue runner. Sous gitlab, si on utilise les runners fournis par le site, on utilisera pas forcement le m\u00eame runner pour toutes les actions CI/CD. D\u00e9ploiement du runner local \u00b6 Lien pour un runner gitlab by F.micaux https://gitlab.actilis.net/formation/gitlab/deploy-runner/-/tree/main/ On clone le repo afin de pouvoir utiliser le runner en local. Apr\u00e8s le clone, on modifie le fichier formation.env pour modifier le token, le serveur et le nom du projet : 1 2 3 COMPOSE_PROJECT_NAME = runner-cours-cs2i GITLAB_SERVER_URL = https://gitlab.com/ RUNNER_TOKEN = GR1348941tjJ6Vjq-xhxNzbPBqKx2 Lancement du runner avec docker : docker compose --env-file formation.env up -d Cr\u00e9ation du fichier de pipeline \u00b6 Ecriture du fichier CI de d\u00e9but nomm\u00e9 .gitlab-ci.yml : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 image : docker:stable variables : IMAGE_NAME : ${CI_REGISTRY}/${CI_PROJECT_PATH} # D\u00e9finition des \u00e9tapes du pipeline (ordre \u00e0 bien respecter) stages : - prebuild - build # Etape n\u00b01 : # Permet d'afficher toutes les variables disponibles Prebuild : stage : prebuild script : - set # Etape N\u00b02: Build de l'image et push Construction : stage : build script : #Build de l'image avec le nom de l'image (ici le repo) - docker image build -t ${IMAGE_NAME}:build-temp . #Ajout d'un tag \u00e0 l'image. Si pas de tag sp\u00e9cifi\u00e9, cela utilisera l'option -devel - docker image tag ${IMAGE_NAME}:build-temp ${IMAGE_NAME}:${CI_COMMIT_TAG:-devel} #Connexion - echo ${CI_REGISTRY_PASSWORD} | docker login ${CI_REGISTRY} -u ${CI_REGISTRY_USER} --password-stdin #Push de l'image - docker image push ${IMAGE_NAME}:${CI_COMMIT_TAG:-devel} #Fermeture de la connexion - docker logout after_script : #Clean du runner - docker image rm ${IMAGE_NAME}:build-temp ${IMAGE_NAME}:${CI_COMMIT_TAG:-devel} Info La documentation de toutes les variables est disponible sur Gitlab . Modification du script afin d'optimiser le runner local : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 image : docker:stable variables : IMAGE_NAME : ${CI_REGISTRY}/${CI_PROJECT_PATH} stages : - build - push Construction : stage : build before_script : - set script : - docker image build -t ${IMAGE_NAME}:build-temp . publication de l'image : stage : push script : - docker image tag ${IMAGE_NAME}:build-temp ${IMAGE_NAME}:${CI_COMMIT_TAG:-devel} - echo ${CI_REGISTRY_PASSWORD} | docker login ${CI_REGISTRY} -u ${CI_REGISTRY_USER} --password-stdin - docker image push ${IMAGE_NAME}:${CI_COMMIT_TAG:-devel} - docker logout after_script : - docker image rm ${IMAGE_NAME}:build-temp ${IMAGE_NAME}:${CI_COMMIT_TAG:-devel} Ajout d'une recherche de vuln\u00e9rabilit\u00e9 \u00b6 Ajout d'un module de s\u00e9cuit\u00e9 : 1 2 3 4 5 6 7 8 9 10 11 12 vul-scan : # renomm\u00e9 \"vul-scan\" au lieu de \"scan de vuln\u00e9rabilit\u00e9\" stage : vul-scan script : # On s'assure que le dossier de rapport existe - mkdir -p -m 2770 ./scan-result # Lancement du scan - docker container run --rm -v /var/run/docker.sock:/var/run/docker.sock -v trivy-cache:/root/.cache/ aquasec/trivy --cache-dir /root/.cache/ image --scanners vuln --no-progress ${IMAGE_NAME}:build-temp | tee ./scan-result/scan-${CI_PROJECT_NAME}.log # Inspection du rapport pour contorle si il y a des VULN et le cas \u00e9ch\u00e9ant si on doit ou pas s'arr\u00eater - | grep -q \"CRITICAL: [^0]\" ./scan-result/scan-${CI_PROJECT_NAME}.log && if [ ${STOP_IF_VULNERABILITY_FOUND:-0} != 0 ] ; then echo \"Vuln\u00e9rabilit\u00e9 CRITICAL d\u00e9tect\u00e9e, arr\u00eat du pipeline\" && exit 1 ; fi ; true Github \u00b6 Info Ici on r\u00e9alise une comparaison des fichier entre github et gitlab Cr\u00e9ation du runner \u00b6 Pour r\u00e9aliser un runner, on utilise une image disponible sur le web. On clone donc un repository github : git clone https://github.com/tcardonne/docker-github-runner Dans le dossier \u00e0 la racine ./docker-github-runner/ , on va cr\u00e9er un fichier .env : RUNNER_REPOSITORY_URL = https://github.com/poseidon974/cours GITHUB_ACCESS_TOKEN = votre_token Comment g\u00e9n\u00e9rer votre token Pour g\u00e9n\u00e9rer votre token, veuillez vous rendre sur github : Settings Developper settings Personnal access tokens Generate new token Copier et garder bien le token car il sera affich\u00e9 uniquement 1 fois. Modification du make file pour ajouter une commande nomm\u00e9e compose : compose: docker compose up -d --scale runner = 4 sleep 1 docker compose ps Pour lancer le runner, vous devez build l'image docker qui servira de runner. make build Attention Avant de lancer le build, je vous conseille de mettre le plus de reesources sur votre machine virtuelle car cela peut prendre beacuoup du temps . Pour lancer l'image que vous venez de build, utiliser la commande : make compose Ecriture du pipeline \u00b6 Warning L'ecriture de la documentation du pipeline n'est termin\u00e9e En premi\u00e8re \u00e9tape, nous allons pouvoir observer avec l'\u00e9criture d'un premier pipeline toutes les variables disponibles : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 name : Permier-deploiement on : push : branches : - main jobs : check : runs-on : self-hosted steps : - name : Affichage Envvars uses : actions/checkout@v3 - run : | set Info Les options pr\u00e9sentes ci-dessus permettent : runs-on : permet d'utiliser le runner h\u00e9berg\u00e9 localement run : set : permet d'afffihcer les variables d'environement On va ensuite tester la connexion \u00e0 ghcr.io avec le pipeline : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 name : Test_login on : push : branches : - main jobs : logingit : runs-on : self-hosted steps : - name : Login to Github Packages uses : docker/login-action@v2 with : registry : ghcr.io username : ${{ github.actor }} password : ${{ secrets.GITHUB_TOKEN }} Info On utlise ici des variables d'environement mises \u00e0 disposition par Github : - ${{ github.actor }} : permet d'afficher le nom d'utilisateur du propri\u00e8taire - ${{ secrets.GITHUB_TOKEN }} : permet d'utiliser le token de github pour se connecter 1 2 3 4 5 6 7 8 9 10 11 12 13 14 name : Test_build on : push : branches : - main jobs : buildimage : runs-on : self-hosted steps : - name : Checkout code uses : actions/checkout@v2 - name : Build image run : docker build -t ${{ github.repository }}:build-temp . Info On utlise ici des variables d'environement mises \u00e0 disposition par Github : - ${{ github.repository }} : permet d'afficher le nom de repository Cr\u00e9ation du block pour push l'image sur ghcr.io : name : Deployment sitedocs on : push : branches : - main jobs : buildimage : runs-on : self-hosted steps : - name : Checkout code uses : actions/checkout@v2 - name : Build image run : docker build -t ${{ github.repository }}:build-temp . pushimage : runs-on : self-hosted needs : [ buildimage ] steps : - name : Push image run : | echo ${{ secrets.GITHUB_TOKEN }} | docker login ghcr.io -u ${{ github.actor }} --password-stdin docker tag ${{ github.repository }}:build-temp ghcr.io/${{ github.repository }}:0.4 docker push ghcr.io/${{ github.repository }}:0.4 docker logout Erreurs d'\u00e9critures On retrouve plusieurs erreurs de permissions d'\u00e9critures. Pour r\u00e9soudre les erreurs, il faut dans un premier temps modifier le fichier YML en ajoutant les permissions dessus : permissions : write-all On modifie sur le package les droits d'\u00e9criture d'un repository. - Rendez vous sur la page du package - Allez dans les Pakages settings en bas \u00e0 droite - Ajoutez un repository (ici le repo dont le quel vous executez le pipeline) - Mettez lui au minimun le role Write Voici le fichier complet : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 name : Deployment sitedocs permissions : write-all on : push : branches : - main jobs : check : runs-on : self-hosted steps : - name : Affichage Envvars uses : actions/checkout@v3 - run : | set - run : echo \"tag name ${{ github.ref_name }}\" - name : Set variables run : | if [ ${{ github.ref_name }} = 'main' ] ; then $VARIABLE_TAG='devel' ; else $VARIABLE_TAG=${{github.ref_name}} ; fi logingit : runs-on : self-hosted steps : - name : Login to Github Packages uses : docker/login-action@v2 with : registry : ghcr.io username : ${{ github.actor }} password : ${{ secrets.GITHUB_TOKEN }} buildimage : runs-on : self-hosted needs : [ logingit ] steps : - name : Checkout code uses : actions/checkout@v2 - name : Build image run : docker build -t ${{ github.repository }}:build-temp . pushimage : runs-on : self-hosted needs : [ buildimage ] steps : - name : Push image run : | echo ${{ secrets.GITHUB_TOKEN }} | docker login ghcr.io -u ${{ github.actor }} --password-stdin docker tag ${{ github.repository }}:build-temp ghcr.io/${{ github.repository }}:0.4 docker push ghcr.io/${{ github.repository }}:0.4 docker logout Tag image Ici dans le code, on utilise le tag 0.4. Vous pouvez modifier ce tag manuellement","title":"Deploiement de runners et execution de pipelines"},{"location":"Linux/Master/Conteneur%20et%20pipelines%20CICD/Runners/#deploiement-de-runners-et-execution-de-pipelines","text":"","title":"Deploiement de runners et execution de pipelines"},{"location":"Linux/Master/Conteneur%20et%20pipelines%20CICD/Runners/#gitlab","text":"Objectifs On cherche \u00e0 utiliser un seul et unqiue runner. Sous gitlab, si on utilise les runners fournis par le site, on utilisera pas forcement le m\u00eame runner pour toutes les actions CI/CD.","title":"Gitlab"},{"location":"Linux/Master/Conteneur%20et%20pipelines%20CICD/Runners/#deploiement-du-runner-local","text":"Lien pour un runner gitlab by F.micaux https://gitlab.actilis.net/formation/gitlab/deploy-runner/-/tree/main/ On clone le repo afin de pouvoir utiliser le runner en local. Apr\u00e8s le clone, on modifie le fichier formation.env pour modifier le token, le serveur et le nom du projet : 1 2 3 COMPOSE_PROJECT_NAME = runner-cours-cs2i GITLAB_SERVER_URL = https://gitlab.com/ RUNNER_TOKEN = GR1348941tjJ6Vjq-xhxNzbPBqKx2 Lancement du runner avec docker : docker compose --env-file formation.env up -d","title":"D\u00e9ploiement du runner local"},{"location":"Linux/Master/Conteneur%20et%20pipelines%20CICD/Runners/#creation-du-fichier-de-pipeline","text":"Ecriture du fichier CI de d\u00e9but nomm\u00e9 .gitlab-ci.yml : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 image : docker:stable variables : IMAGE_NAME : ${CI_REGISTRY}/${CI_PROJECT_PATH} # D\u00e9finition des \u00e9tapes du pipeline (ordre \u00e0 bien respecter) stages : - prebuild - build # Etape n\u00b01 : # Permet d'afficher toutes les variables disponibles Prebuild : stage : prebuild script : - set # Etape N\u00b02: Build de l'image et push Construction : stage : build script : #Build de l'image avec le nom de l'image (ici le repo) - docker image build -t ${IMAGE_NAME}:build-temp . #Ajout d'un tag \u00e0 l'image. Si pas de tag sp\u00e9cifi\u00e9, cela utilisera l'option -devel - docker image tag ${IMAGE_NAME}:build-temp ${IMAGE_NAME}:${CI_COMMIT_TAG:-devel} #Connexion - echo ${CI_REGISTRY_PASSWORD} | docker login ${CI_REGISTRY} -u ${CI_REGISTRY_USER} --password-stdin #Push de l'image - docker image push ${IMAGE_NAME}:${CI_COMMIT_TAG:-devel} #Fermeture de la connexion - docker logout after_script : #Clean du runner - docker image rm ${IMAGE_NAME}:build-temp ${IMAGE_NAME}:${CI_COMMIT_TAG:-devel} Info La documentation de toutes les variables est disponible sur Gitlab . Modification du script afin d'optimiser le runner local : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 image : docker:stable variables : IMAGE_NAME : ${CI_REGISTRY}/${CI_PROJECT_PATH} stages : - build - push Construction : stage : build before_script : - set script : - docker image build -t ${IMAGE_NAME}:build-temp . publication de l'image : stage : push script : - docker image tag ${IMAGE_NAME}:build-temp ${IMAGE_NAME}:${CI_COMMIT_TAG:-devel} - echo ${CI_REGISTRY_PASSWORD} | docker login ${CI_REGISTRY} -u ${CI_REGISTRY_USER} --password-stdin - docker image push ${IMAGE_NAME}:${CI_COMMIT_TAG:-devel} - docker logout after_script : - docker image rm ${IMAGE_NAME}:build-temp ${IMAGE_NAME}:${CI_COMMIT_TAG:-devel}","title":"Cr\u00e9ation du fichier de pipeline"},{"location":"Linux/Master/Conteneur%20et%20pipelines%20CICD/Runners/#ajout-dune-recherche-de-vulnerabilite","text":"Ajout d'un module de s\u00e9cuit\u00e9 : 1 2 3 4 5 6 7 8 9 10 11 12 vul-scan : # renomm\u00e9 \"vul-scan\" au lieu de \"scan de vuln\u00e9rabilit\u00e9\" stage : vul-scan script : # On s'assure que le dossier de rapport existe - mkdir -p -m 2770 ./scan-result # Lancement du scan - docker container run --rm -v /var/run/docker.sock:/var/run/docker.sock -v trivy-cache:/root/.cache/ aquasec/trivy --cache-dir /root/.cache/ image --scanners vuln --no-progress ${IMAGE_NAME}:build-temp | tee ./scan-result/scan-${CI_PROJECT_NAME}.log # Inspection du rapport pour contorle si il y a des VULN et le cas \u00e9ch\u00e9ant si on doit ou pas s'arr\u00eater - | grep -q \"CRITICAL: [^0]\" ./scan-result/scan-${CI_PROJECT_NAME}.log && if [ ${STOP_IF_VULNERABILITY_FOUND:-0} != 0 ] ; then echo \"Vuln\u00e9rabilit\u00e9 CRITICAL d\u00e9tect\u00e9e, arr\u00eat du pipeline\" && exit 1 ; fi ; true","title":"Ajout d'une recherche de vuln\u00e9rabilit\u00e9"},{"location":"Linux/Master/Conteneur%20et%20pipelines%20CICD/Runners/#github","text":"Info Ici on r\u00e9alise une comparaison des fichier entre github et gitlab","title":"Github"},{"location":"Linux/Master/Conteneur%20et%20pipelines%20CICD/Runners/#creation-du-runner","text":"Pour r\u00e9aliser un runner, on utilise une image disponible sur le web. On clone donc un repository github : git clone https://github.com/tcardonne/docker-github-runner Dans le dossier \u00e0 la racine ./docker-github-runner/ , on va cr\u00e9er un fichier .env : RUNNER_REPOSITORY_URL = https://github.com/poseidon974/cours GITHUB_ACCESS_TOKEN = votre_token Comment g\u00e9n\u00e9rer votre token Pour g\u00e9n\u00e9rer votre token, veuillez vous rendre sur github : Settings Developper settings Personnal access tokens Generate new token Copier et garder bien le token car il sera affich\u00e9 uniquement 1 fois. Modification du make file pour ajouter une commande nomm\u00e9e compose : compose: docker compose up -d --scale runner = 4 sleep 1 docker compose ps Pour lancer le runner, vous devez build l'image docker qui servira de runner. make build Attention Avant de lancer le build, je vous conseille de mettre le plus de reesources sur votre machine virtuelle car cela peut prendre beacuoup du temps . Pour lancer l'image que vous venez de build, utiliser la commande : make compose","title":"Cr\u00e9ation du runner"},{"location":"Linux/Master/Conteneur%20et%20pipelines%20CICD/Runners/#ecriture-du-pipeline","text":"Warning L'ecriture de la documentation du pipeline n'est termin\u00e9e En premi\u00e8re \u00e9tape, nous allons pouvoir observer avec l'\u00e9criture d'un premier pipeline toutes les variables disponibles : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 name : Permier-deploiement on : push : branches : - main jobs : check : runs-on : self-hosted steps : - name : Affichage Envvars uses : actions/checkout@v3 - run : | set Info Les options pr\u00e9sentes ci-dessus permettent : runs-on : permet d'utiliser le runner h\u00e9berg\u00e9 localement run : set : permet d'afffihcer les variables d'environement On va ensuite tester la connexion \u00e0 ghcr.io avec le pipeline : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 name : Test_login on : push : branches : - main jobs : logingit : runs-on : self-hosted steps : - name : Login to Github Packages uses : docker/login-action@v2 with : registry : ghcr.io username : ${{ github.actor }} password : ${{ secrets.GITHUB_TOKEN }} Info On utlise ici des variables d'environement mises \u00e0 disposition par Github : - ${{ github.actor }} : permet d'afficher le nom d'utilisateur du propri\u00e8taire - ${{ secrets.GITHUB_TOKEN }} : permet d'utiliser le token de github pour se connecter 1 2 3 4 5 6 7 8 9 10 11 12 13 14 name : Test_build on : push : branches : - main jobs : buildimage : runs-on : self-hosted steps : - name : Checkout code uses : actions/checkout@v2 - name : Build image run : docker build -t ${{ github.repository }}:build-temp . Info On utlise ici des variables d'environement mises \u00e0 disposition par Github : - ${{ github.repository }} : permet d'afficher le nom de repository Cr\u00e9ation du block pour push l'image sur ghcr.io : name : Deployment sitedocs on : push : branches : - main jobs : buildimage : runs-on : self-hosted steps : - name : Checkout code uses : actions/checkout@v2 - name : Build image run : docker build -t ${{ github.repository }}:build-temp . pushimage : runs-on : self-hosted needs : [ buildimage ] steps : - name : Push image run : | echo ${{ secrets.GITHUB_TOKEN }} | docker login ghcr.io -u ${{ github.actor }} --password-stdin docker tag ${{ github.repository }}:build-temp ghcr.io/${{ github.repository }}:0.4 docker push ghcr.io/${{ github.repository }}:0.4 docker logout Erreurs d'\u00e9critures On retrouve plusieurs erreurs de permissions d'\u00e9critures. Pour r\u00e9soudre les erreurs, il faut dans un premier temps modifier le fichier YML en ajoutant les permissions dessus : permissions : write-all On modifie sur le package les droits d'\u00e9criture d'un repository. - Rendez vous sur la page du package - Allez dans les Pakages settings en bas \u00e0 droite - Ajoutez un repository (ici le repo dont le quel vous executez le pipeline) - Mettez lui au minimun le role Write Voici le fichier complet : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 name : Deployment sitedocs permissions : write-all on : push : branches : - main jobs : check : runs-on : self-hosted steps : - name : Affichage Envvars uses : actions/checkout@v3 - run : | set - run : echo \"tag name ${{ github.ref_name }}\" - name : Set variables run : | if [ ${{ github.ref_name }} = 'main' ] ; then $VARIABLE_TAG='devel' ; else $VARIABLE_TAG=${{github.ref_name}} ; fi logingit : runs-on : self-hosted steps : - name : Login to Github Packages uses : docker/login-action@v2 with : registry : ghcr.io username : ${{ github.actor }} password : ${{ secrets.GITHUB_TOKEN }} buildimage : runs-on : self-hosted needs : [ logingit ] steps : - name : Checkout code uses : actions/checkout@v2 - name : Build image run : docker build -t ${{ github.repository }}:build-temp . pushimage : runs-on : self-hosted needs : [ buildimage ] steps : - name : Push image run : | echo ${{ secrets.GITHUB_TOKEN }} | docker login ghcr.io -u ${{ github.actor }} --password-stdin docker tag ${{ github.repository }}:build-temp ghcr.io/${{ github.repository }}:0.4 docker push ghcr.io/${{ github.repository }}:0.4 docker logout Tag image Ici dans le code, on utilise le tag 0.4. Vous pouvez modifier ce tag manuellement","title":"Ecriture du pipeline"},{"location":"Linux/Master/Conteneur%20et%20pipelines%20CICD/Traefik/","text":"Traefik \u00b6 Deploiement d'un traefik sous docker \u00b6 Deploiement simple \u00b6 Cr\u00e9ation d'un fichier compose.yml : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 networks : rp : name : traefik-net services : proxy : image : traefik command : |- --providers.docker --log.level=debug --entryPoints.http.address=:80 restart : always networks : - rp ports : - \"80:80\" volumes : - type : bind source : /var/run/docker.sock target : /var/run/docker.sock whoami : image : traefik/whoami networks : - rp labels : - traefik.http.routers.whoami.rule=Path(`/whoami`) Lancement des conteneur : docker compose up -d Info L'option -d est tr\u00e8s utile pour lancer les conteneurs en mode d\u00e9tach\u00e9s. Verification du lancement du traefik avec un curl 127.0.0.1/whoami : Hostname: ab75b31dfcab IP: 127 .0.0.1 IP: 172 .19.0.2 RemoteAddr: 172 .19.0.3:56660 GET /whoami HTTP/1.1 Host: 127 .0.0.1 User-Agent: curl/7.76.1 Accept: */* Accept-Encoding: gzip X-Forwarded-For: 172 .19.0.1 X-Forwarded-Host: 127 .0.0.1 X-Forwarded-Port: 80 X-Forwarded-Proto: http X-Forwarded-Server: bb18d45e752b X-Real-Ip: 172 .19.0.1 Modification de rule en utilisant le Host. On modifie donc le fichier sur les derni\u00e8re lignes : 1 2 3 4 5 6 7 whoami : image : traefik/whoami networks : - rp labels : # - traefik.http.routers.whoami.rule=Path(`/whoami`) - traefik.http.routers.whaomi.rule=Host(`truc.local`) On relance les conteneurs pour la modification : docker compose up -d On teste la modification avec la commande curl : curl -H \"Host: truc.local\" http://127.0.0.1/ R\u00e9alisation de plusieurs services avec du loadbalancing : docker compose up -d --scale whoami = 2 On cr\u00e9\u00e9 2 conteneurs diff\u00e9rents : 1 2 3 4 [ + ] Running 3 /3 \u283f Container root-whoami-2 Started 0 .6s \u283f Container root-proxy-1 Running 0 .0s \u283f Container root-whoami-1 Started 0 .9s Ajout d'un dashbord \u00b6 Ajout de configuration dans le compose.yml : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 proxy : image : traefik command : |- --providers.docker --log.level=debug --entryPoints.http.address=:80 --api.insecure=true restart : always networks : - rp ports : - \"80:80\" volumes : - type : bind source : /var/run/docker.sock target : /var/run/docker.sock labels : - \"traefik.http.routers.dashboard.rule=PathPrefix(`/traefik`) || PathPrefix(`/api`)\" - \"traefik.http.routers.dashboard.service=api@internal\" - \"traefik.http.routers.dashboard.middlewares=dashboard-stripprefix\" - \"traefik.http.middlewares.dashboard-stripprefix.stripprefix.prefixes=/traefik\" On relance le conteneur afin de pouvoir tester les modifications. Verification du dashbord http://10.56.126.223/traefik : Image du dashbord traefik Ajout d'une authentification \u00b6 Ajout d'une ligne pour utiliser le middleware auth-dashboard : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 proxy : image : traefik command : |- --providers.docker --log.level=debug --entryPoints.http.address=:80 --api.insecure=true restart : always networks : - rp ports : - \"80:80\" volumes : - type : bind source : /var/run/docker.sock target : /var/run/docker.sock labels : - \"traefik.http.routers.dashboard.rule=PathPrefix(`/traefik`) || PathPrefix(`/api`)\" - \"traefik.http.routers.dashboard.service=api@internal\" - \"traefik.http.middlewares.dashboard-stripprefix.stripprefix.prefixes=/traefik\" - \"traefik.http.routers.dashboard.middlewares=auth-dashboard,dashboard-stripprefix\" G\u00e9nration d'un mot de passe password qui nous donnera un hash: echo password | openssl passwd -apr1 -stdin Modification du fichier compose.yml pour lui passer la ligne avec le mot de passe : labels : - \"traefik.http.routers.dashboard.rule=PathPrefix(`/traefik`) || PathPrefix(`/api`)\" - \"traefik.http.routers.dashboard.service=api@internal\" - \"traefik.http.middlewares.dashboard-stripprefix.stripprefix.prefixes=/traefik\" - \"traefik.http.routers.dashboard.middlewares=auth-dashboard,dashboard-stripprefix\" - \"traefik.http.middlewares.auth-dashboard.basicauth.users=dashuser:$ YOUR_HACH_PASSWD\" Attention Dans le mot de passe hash\u00e9, vous pouvez avoir des $ . Si vous avez ce symbole, vous devez absolument le doubler. On relance ensuite les containers et on teste la connexion avec mot de passe. Ajout de l'obligation de d'exposition de services \u00b6 Modification du fichier compose avec les nouveaut\u00e9s : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 services : proxy : image : traefik command : |- --providers.docker --log.level=debug --providers.docker.exposedbydefault=false --entryPoints.http.address=:80 --api.insecure=true restart : always networks : - rp ports : - \"80:80\" volumes : - type : bind source : /var/run/docker.sock target : /var/run/docker.sock labels : - traefik.enable=true - \"traefik.http.routers.dashboard.rule=PathPrefix(`/traefik`) || PathPrefix(`/api`)\" - \"traefik.http.routers.dashboard.service=api@internal\" - \"traefik.http.middlewares.dashboard-stripprefix.stripprefix.prefixes=/traefik\" - \"traefik.http.routers.dashboard.middlewares=auth-dashboard,dashboard-stripprefix\" - \"traefik.http.middlewares.auth-dashboard.basicauth.users=dashuser:$$apr1$$nWuK9JVS$$Cm580WakVYahBvJyVuYNI1\" Les doubles cotes sur les labels Les doubles cotes ne sont pas obligatoire dans la d\u00e9claration d'un label. On oublie pas de relancer les conteneurs pour prendre en compte la modification. Deploiement sous gitlab \u00b6 Cr\u00e9ation d'une nouvelle arborescence sous git : whoami/ \u251c\u2500\u2500 compose.yaml \u251c\u2500\u2500 .git \u2514\u2500\u2500 .gitlab-ci.yml","title":"Traefik"},{"location":"Linux/Master/Conteneur%20et%20pipelines%20CICD/Traefik/#traefik","text":"","title":"Traefik"},{"location":"Linux/Master/Conteneur%20et%20pipelines%20CICD/Traefik/#deploiement-dun-traefik-sous-docker","text":"","title":"Deploiement d'un traefik sous docker"},{"location":"Linux/Master/Conteneur%20et%20pipelines%20CICD/Traefik/#deploiement-simple","text":"Cr\u00e9ation d'un fichier compose.yml : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 networks : rp : name : traefik-net services : proxy : image : traefik command : |- --providers.docker --log.level=debug --entryPoints.http.address=:80 restart : always networks : - rp ports : - \"80:80\" volumes : - type : bind source : /var/run/docker.sock target : /var/run/docker.sock whoami : image : traefik/whoami networks : - rp labels : - traefik.http.routers.whoami.rule=Path(`/whoami`) Lancement des conteneur : docker compose up -d Info L'option -d est tr\u00e8s utile pour lancer les conteneurs en mode d\u00e9tach\u00e9s. Verification du lancement du traefik avec un curl 127.0.0.1/whoami : Hostname: ab75b31dfcab IP: 127 .0.0.1 IP: 172 .19.0.2 RemoteAddr: 172 .19.0.3:56660 GET /whoami HTTP/1.1 Host: 127 .0.0.1 User-Agent: curl/7.76.1 Accept: */* Accept-Encoding: gzip X-Forwarded-For: 172 .19.0.1 X-Forwarded-Host: 127 .0.0.1 X-Forwarded-Port: 80 X-Forwarded-Proto: http X-Forwarded-Server: bb18d45e752b X-Real-Ip: 172 .19.0.1 Modification de rule en utilisant le Host. On modifie donc le fichier sur les derni\u00e8re lignes : 1 2 3 4 5 6 7 whoami : image : traefik/whoami networks : - rp labels : # - traefik.http.routers.whoami.rule=Path(`/whoami`) - traefik.http.routers.whaomi.rule=Host(`truc.local`) On relance les conteneurs pour la modification : docker compose up -d On teste la modification avec la commande curl : curl -H \"Host: truc.local\" http://127.0.0.1/ R\u00e9alisation de plusieurs services avec du loadbalancing : docker compose up -d --scale whoami = 2 On cr\u00e9\u00e9 2 conteneurs diff\u00e9rents : 1 2 3 4 [ + ] Running 3 /3 \u283f Container root-whoami-2 Started 0 .6s \u283f Container root-proxy-1 Running 0 .0s \u283f Container root-whoami-1 Started 0 .9s","title":"Deploiement simple"},{"location":"Linux/Master/Conteneur%20et%20pipelines%20CICD/Traefik/#ajout-dun-dashbord","text":"Ajout de configuration dans le compose.yml : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 proxy : image : traefik command : |- --providers.docker --log.level=debug --entryPoints.http.address=:80 --api.insecure=true restart : always networks : - rp ports : - \"80:80\" volumes : - type : bind source : /var/run/docker.sock target : /var/run/docker.sock labels : - \"traefik.http.routers.dashboard.rule=PathPrefix(`/traefik`) || PathPrefix(`/api`)\" - \"traefik.http.routers.dashboard.service=api@internal\" - \"traefik.http.routers.dashboard.middlewares=dashboard-stripprefix\" - \"traefik.http.middlewares.dashboard-stripprefix.stripprefix.prefixes=/traefik\" On relance le conteneur afin de pouvoir tester les modifications. Verification du dashbord http://10.56.126.223/traefik : Image du dashbord traefik","title":"Ajout d'un dashbord"},{"location":"Linux/Master/Conteneur%20et%20pipelines%20CICD/Traefik/#ajout-dune-authentification","text":"Ajout d'une ligne pour utiliser le middleware auth-dashboard : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 proxy : image : traefik command : |- --providers.docker --log.level=debug --entryPoints.http.address=:80 --api.insecure=true restart : always networks : - rp ports : - \"80:80\" volumes : - type : bind source : /var/run/docker.sock target : /var/run/docker.sock labels : - \"traefik.http.routers.dashboard.rule=PathPrefix(`/traefik`) || PathPrefix(`/api`)\" - \"traefik.http.routers.dashboard.service=api@internal\" - \"traefik.http.middlewares.dashboard-stripprefix.stripprefix.prefixes=/traefik\" - \"traefik.http.routers.dashboard.middlewares=auth-dashboard,dashboard-stripprefix\" G\u00e9nration d'un mot de passe password qui nous donnera un hash: echo password | openssl passwd -apr1 -stdin Modification du fichier compose.yml pour lui passer la ligne avec le mot de passe : labels : - \"traefik.http.routers.dashboard.rule=PathPrefix(`/traefik`) || PathPrefix(`/api`)\" - \"traefik.http.routers.dashboard.service=api@internal\" - \"traefik.http.middlewares.dashboard-stripprefix.stripprefix.prefixes=/traefik\" - \"traefik.http.routers.dashboard.middlewares=auth-dashboard,dashboard-stripprefix\" - \"traefik.http.middlewares.auth-dashboard.basicauth.users=dashuser:$ YOUR_HACH_PASSWD\" Attention Dans le mot de passe hash\u00e9, vous pouvez avoir des $ . Si vous avez ce symbole, vous devez absolument le doubler. On relance ensuite les containers et on teste la connexion avec mot de passe.","title":"Ajout d'une authentification"},{"location":"Linux/Master/Conteneur%20et%20pipelines%20CICD/Traefik/#ajout-de-lobligation-de-dexposition-de-services","text":"Modification du fichier compose avec les nouveaut\u00e9s : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 services : proxy : image : traefik command : |- --providers.docker --log.level=debug --providers.docker.exposedbydefault=false --entryPoints.http.address=:80 --api.insecure=true restart : always networks : - rp ports : - \"80:80\" volumes : - type : bind source : /var/run/docker.sock target : /var/run/docker.sock labels : - traefik.enable=true - \"traefik.http.routers.dashboard.rule=PathPrefix(`/traefik`) || PathPrefix(`/api`)\" - \"traefik.http.routers.dashboard.service=api@internal\" - \"traefik.http.middlewares.dashboard-stripprefix.stripprefix.prefixes=/traefik\" - \"traefik.http.routers.dashboard.middlewares=auth-dashboard,dashboard-stripprefix\" - \"traefik.http.middlewares.auth-dashboard.basicauth.users=dashuser:$$apr1$$nWuK9JVS$$Cm580WakVYahBvJyVuYNI1\" Les doubles cotes sur les labels Les doubles cotes ne sont pas obligatoire dans la d\u00e9claration d'un label. On oublie pas de relancer les conteneurs pour prendre en compte la modification.","title":"Ajout de l'obligation de d'exposition de services"},{"location":"Linux/Master/Conteneur%20et%20pipelines%20CICD/Traefik/#deploiement-sous-gitlab","text":"Cr\u00e9ation d'une nouvelle arborescence sous git : whoami/ \u251c\u2500\u2500 compose.yaml \u251c\u2500\u2500 .git \u2514\u2500\u2500 .gitlab-ci.yml","title":"Deploiement sous gitlab"},{"location":"Linux/Master/Serveurs%20web/Apache/","text":"Apache \u00b6 D\u00e9finition de apache \u00b6 Apache est un logiciel open source. Plusieurs r\u00e8gles s'applique aux logiciels open source et donc ici \u00e0 apache : R\u00e9activit\u00e9 importante des d\u00e9veloppeurs en cas de \u00ab bug \u00bb Correctifs de s\u00e9curit\u00e9 \u00e0 appliquer... Mises \u00e0 jour et \u00e9volutions fr\u00e9quentes Obsolescence rapide des paquetages binaires Apcahe utilise un server NPM de type prefork. Installation de apache \u00b6 Pour installer apache, on utilise dnf : dnf install -y httpd Suivant les syst\u00e8mes, on trouve les fichiers de configuration \u00e0 deux endroits diff\u00e9rents : Debian Redhat /etc/apache2/apache2.conf /etc/httpd/conf/httpd.conf On ne va pas modifier le fichier de configuration de apache mais on va utiliser les includes. Debian Redhat On cherche tout les fichier pour apache : grep -nri --color \"^*Include\" /etc/apache2 On cherche tout les fichier pour apache : grep -nri --color \"^Include\" /etc/httpd On obtient les fichiers suivants : 1 2 3 4 /etc/httpd/conf/httpd.conf.rpmsave:61:Include conf.modules.d/*.conf /etc/httpd/conf/httpd.conf.rpmsave:358:IncludeOptional conf.d/*.conf /etc/httpd/conf/httpd.conf:61:Include conf.modules.d/*.conf /etc/httpd/conf/httpd.conf:358:IncludeOptional conf.d/*.conf Structuration de la configuration de apache \u00b6 La configuration est d\u00e9coup\u00e9e en plusieurs contextes : Server-config : Configuration du serveur VirtualHost : Configuration d'un serveur Virtuel Directory : Configuration relative \u00e0 un dossier Htaccess : Dans un fichier .htaccess Les formes de contextes sont les suivantes : <Directory ...> <Location ...> <Files ...> Le fichier de configuration .htaccess porte des directives d'acc\u00e8s. C'est de la d\u00e9l\u00e9gation de pourvoir d'acc\u00e8s. Le fichier de configuration accepte les fautes de configurations dans son fichier. La configuration est comme saut\u00e9e si il y a un probl\u00e8me de configuration. Si on cherche les fichiers de logs avec grep -nri --color ErrorLog /etc/httpd : 1 2 3 /etc/httpd/conf/httpd.conf:181:# ErrorLog: The location of the error log file. /etc/httpd/conf/httpd.conf:182:# If you do not specify an ErrorLog directive within a <VirtualHost> /etc/httpd/conf/httpd.conf:187:ErrorLog \"logs/error_log\" Les liens symboliques Les logs sont stock\u00e9s dans le dossier /etc/httpd/logs/ mais en r\u00e9el, nous avons une redirection avec un lien symbolique ( ls -l /etc/httpd ): 1 2 3 4 5 6 7 8 total 12 drwxr-xr-x. 2 root root 4096 21 mars 11 :11 conf drwxr-xr-x. 2 root root 4096 21 mars 11 :11 conf.d drwxr-xr-x. 2 root root 4096 21 mars 11 :11 conf.modules.d lrwxrwxrwx. 1 root root 19 31 janv. 17 :10 logs -> ../../var/log/httpd lrwxrwxrwx. 1 root root 29 31 janv. 17 :10 modules -> ../../usr/lib64/httpd/modules lrwxrwxrwx. 1 root root 10 31 janv. 17 :10 run -> /run/httpd lrwxrwxrwx. 1 root root 19 31 janv. 17 :10 state -> ../../var/lib/httpd Pour avoir une installation minimale, on d\u00e9sactive tout les modules : 1 2 3 cd /etc/httpd/conf.modules.d/ sed -i 's,^LoadModule,#LoadModule,' *.conf systemctl restart httpd On obtiens une erreur lors du red\u00e9marrage du service : Job for httpd.service failed because the control process exited with error code. See \"systemctl status httpd.service\" and \"journalctl -xeu httpd.service\" for details. On cherche ensuite quelle est l'erreur avec la commande journalctl -u httpd.service | tail : 1 2 3 4 5 mars 21 12 :02:32 LG-stream9-1.local systemd [ 1 ] : Starting The Apache HTTP Server... mars 21 12 :02:32 LG-stream9-1.local httpd [ 540060 ] : AH00534: httpd: Configuration error: No MPM loaded. mars 21 12 :02:32 LG-stream9-1.local systemd [ 1 ] : httpd.service: Main process exited, code = exited, status = 1 /FAILURE mars 21 12 :02:32 LG-stream9-1.local systemd [ 1 ] : httpd.service: Failed with result 'exit-code' . mars 21 12 :02:32 LG-stream9-1.local systemd [ 1 ] : Failed to start The Apache HTTP Server. Pour plus d'info sur apache La documentation globale est disponible sur https://httpd.apache.org/docs/2.4/ La documentation des modules est disponible sur https://httpd.apache.org/docs/2.4/mod/ La documentation des directives est disponible sur https://httpd.apache.org/docs/2.4/mod/quickreference.html On cherche les diff\u00e9rents modules \u00e0 activer : mpm_prefork_module unixd_module mod_authz_core mod_autoindex mod_alias mod_systemd Ici c'est la configuration minimale afin que apache se lance. Attention Il ne faut pas oublier de relancer le service httpd systemctl restart httpd Pour que apache puisse voir les fichiers d\u00e9pos\u00e9s dans le dossier \\var\\wwww\\html , il faut activer le module suivant : mod_dir Le fichier qui est affich\u00e9 si aucun fichier n'est pr\u00e9sent dans le dossier pr\u00e9cedent, il y a un fichier qui se trouve dans /etc/httpd/conf.d/welcome.conf : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 # # This configuration file enables the default \"Welcome\" page if there # is no default index page present for the root URL. To disable the # Welcome page, comment out all the lines below. # # NOTE: if this file is removed, it will be restored on upgrades. # < LocationMatch \"^/+$\" > Options -Indexes ErrorDocument 403 /.noindex.html </ LocationMatch > < Directory / usr / share / httpd / noindex > AllowOverride None Require all granted </ Directory > Alias /.noindex.html /usr/share/httpd/noindex/index.html Alias /poweredby.png /usr/share/httpd/icons/apache_pb3.png Alias /system_noindex_logo.png /usr/share/httpd/icons/system_noindex_logo.png Test de charge de apache \u00b6 On cherche \u00e0 activer le module mod_status . Information de la documentation officielle Les d\u00e9tails fournis pour le modile mod_status sont : Le nombre de processus servant les requ\u00eates Le nombre de processus inactifs L'\u00e9tat de chaque processus, le nombre de requ\u00eates qu'il a trait\u00e9es et le nombre total d'octets qu'il a servis (*) Le nombre total d'acc\u00e8s effectu\u00e9s et d'octets servis (*) Le moment o\u00f9 le serveur a \u00e9t\u00e9 d\u00e9marr\u00e9/red\u00e9marr\u00e9 et le temps \u00e9coul\u00e9 depuis Les valeurs moyennes du nombre de requ\u00eates par seconde, du nombre d'octets servis par seconde et du nombre d'octets par requ\u00eate (*) Le pourcentage CPU instantan\u00e9 utilis\u00e9 par chaque processus et par l'ensemble des processus (*) Les h\u00f4tes et requ\u00eates actuellement en cours de traitement (*) On ajoute un fichier de configuration dans le dossier /etc/httpd/config.d qui se nomme status.conf : < IfModule status_module > < location \"/ etat-serveur \" > SetHandler server-status </ location > </ ifmodule > Authentification avec apache \u00b6 Authentification par IP \u00b6 Tache: Acc\u00e8der \u00e0 l'url /etat-serveur uniquement avec l'ip 127.0.0.1 Activer le plugin pour faire de l'acc\u00e8s par IP Modifier le fichier de configuration pour accorder l'acc\u00e8s \u00e0 une seule IP : 127.0.0.1 Ajout d'un nouveau plugin : mod_authz_host Modification du fichier status.conf : 1 2 3 4 5 6 7 8 < IfModule status_module > < location \"/ etat-serveur \" > SetHandler server-status < RequireAny > Require ip 127.0.0.1 </ Requireany > </ location > </ ifmodule > Authentification par Token \u00b6 Tache: Acc\u00e8der \u00e0 l'url /etat-serveur uniquement avec un token Activer le plugin pour l'authentification avec token Modifier le fichier de configuration pour accorder les utilisateurs qui ont LeBonToken Ajout d'un nouveau plugin : mod_setenvif Modification du fichier status.conf : 1 2 3 4 5 6 7 8 9 10 11 12 < IfModule setenvif_module > SetEnvIf MonToken LeBonToken on_a_le_bon_token </ IfModule > < IfModule status_module > < location \"/ etat-serveur \" > SetHandler server-status < RequireAny > Require ip 127.0.0.1 Require env on_a_le_bon_token </ RequireAny > </ location > </ ifmodule > On test avec curl si l'authentification fonctionne bien : curl -v -s -w '%{stderr}%{http_code}\\n' -H \"MonToken: LeBonToken\" http://10.56.126.223/etat-serveur Configuration avec des fichiers de configuration \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 < IfModule setenvif_module > SetEnvIf MonToken LeBonToken on_a_le_bon_token </ IfModule > < IfModule status_module > < location \"/ etat-serveur \" > AuthType BAsic AuthNAme ServerStatus AuthBasicProvider file AuthUserFile /etc/httpd/auth.site1 < RequireAny > Require ip 127.0.0.1 Require env on_a_le_bon_token Require valid-user </ RequireAny > SethHandler server-status </ location > </ ifmodule > Apache et son proxy \u00b6 Cr\u00e9ation du fichier de configuration \u00b6 On utilise un package docker afin d'avoir des conteneurs apaches avec le git suivant : Git_moe On lance les conteneurs apache avec un scale \u00e0 2 : docker compose up -d --scale apache = 2 apache On cr\u00e9e un fichier de configuration dans /etc/http/conf.d : <VirtualHost *:80> # DocumentRoot /var/www/html/site ServerName site.local ProxyPass / http://10.0.0.1/ </VirtualHost> Activation des plugins \u00b6 Des plugins sont n\u00e9c\u00e9ssaires comme le plugin proxy, mime. Pour chercher les plugins : grep -nri nom_du_plugin On d\u00e9commente des plugins et on restart Apache. On obtient maintenant une erreur 503 : <!DOCTYPE HTML PUBLIC \"-//IETF//DTD HTML 2.0//EN\"> < html >< head > < title > 503 Service Unavailable </ title > </ head >< body > < h1 > Service Unavailable </ h1 > < p > The server is temporarily unable to service your request due to maintenance downtime or capacity problems. Please try again later. </ p > </ body ></ html > Activation des r\u00e8gles SElinux \u00b6 Selinux prot\u00e8ge la connexion, on active alors la r\u00e8gle SELinux correspondante : setsebool httpd_can_network_connect on On obtient maintenant le bon affichage : <!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 3.2 Final//EN\"> < html > < head > < title > Index of / </ title > </ head > < body > < h1 > Index of / </ h1 > < ul >< li >< a href = \"cpuload.php\" > cpuload.php </ a ></ li > < li >< a href = \"image.gif\" > image.gif </ a ></ li > < li >< a href = \"image.png\" > image.png </ a ></ li > < li >< a href = \"info.php\" > info.php </ a ></ li > < li >< a href = \"memload.php\" > memload.php </ a ></ li > < li >< a href = \"menu.html\" > menu.html </ a ></ li > < li >< a href = \"server-ip.php\" > server-ip.php </ a ></ li > < li >< a href = \"session/\" > session/ </ a ></ li > < li >< a href = \"sleep.php\" > sleep.php </ a ></ li > < li >< a href = \"sqlinject.php\" > sqlinject.php </ a ></ li > < li >< a href = \"status.html\" > status.html </ a ></ li > < li >< a href = \"status.php\" > status.php </ a ></ li > </ ul > < address > Apache/2.4.56 (Unix) Server at 10.0.0.1 Port 80 </ address > </ body ></ html > Activation du du proxymatch \u00b6 But de la manoeuvre Ici nous cherchons que le conteneur 1 r\u00e9ponde pour les .gif et que le serveur 2 reponde pour les .png 1 2 3 4 5 6 7 8 9 10 11 12 <VirtualHost *:80> DocumentRoot /var/www/html/site ServerName site.local ProxyPass /favicon.ico ! ProxyPassMatch ^/ ( .* \\. gif ) $ http://10.0.0.1/ $1 ProxyPassMatch ^/ ( .* \\. png ) $ http://10.0.0.2/ $1 ProxyPass / http://10.0.0.1/ </VirtualHost> Si on regarde les logs du compose ( docker compose logs -f ): moe-apache-2 | 10 .56.126.94 - - [ 12 /Apr/2023:10:15:47 +0200 ] \"GET /image.gif HTTP/1.1\" 304 - \"http://10.56.126.223/\" \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/111.0.0.0 Safari/537.36\" moe-apache-2 | 10 .56.126.94 - - [ 12 /Apr/2023:10:15:47 +0200 ] \"GET /image.gif HTTP/1.1\" 304 - \"http://10.56.126.223/\" \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/111.0.0.0 Safari/537.36\" moe-apache-3 | [ Wed Apr 12 10 :15:54.305280 2023 ] [ authz_core:error ] [ pid 32 ] [ client 10 .0.0.254:52844 ] AH01630: client denied by server configuration: /var/www/html/.htaccess moe-apache-3 | 10 .56.126.94 - - [ 12 /Apr/2023:10:15:54 +0200 ] \"GET / HTTP/1.1\" 200 782 \"-\" \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/111.0.0.0 Safari/537.36\" Activation du loadbalancer \u00b6 R\u00e9alisation du fichier de configuration : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 <VirtualHost *:80> DocumentRoot /var/www/html/site ServerName site.local ProxyPass /favicon.ico ! ProxyPassMatch ^/ ( .* \\. php ) $ balancer://poolphp/ $1 <Proxy balancer://poolphp> BalancerMember http://10.0.0.1 BalancerMember http://10.0.0.2 </Proxy> ProxyPassMatch ^/ ( .* \\. gif ) $ http://10.0.0.1/ $1 ProxyPassMatch ^/ ( .* \\. png ) $ http://10.0.0.2/ $1 ProxyPass / http://10.0.0.1/ </VirtualHost> Actviation des modules suivants : - mod_proxy_balancer","title":"Apache"},{"location":"Linux/Master/Serveurs%20web/Apache/#apache","text":"","title":"Apache"},{"location":"Linux/Master/Serveurs%20web/Apache/#definition-de-apache","text":"Apache est un logiciel open source. Plusieurs r\u00e8gles s'applique aux logiciels open source et donc ici \u00e0 apache : R\u00e9activit\u00e9 importante des d\u00e9veloppeurs en cas de \u00ab bug \u00bb Correctifs de s\u00e9curit\u00e9 \u00e0 appliquer... Mises \u00e0 jour et \u00e9volutions fr\u00e9quentes Obsolescence rapide des paquetages binaires Apcahe utilise un server NPM de type prefork.","title":"D\u00e9finition de apache"},{"location":"Linux/Master/Serveurs%20web/Apache/#installation-de-apache","text":"Pour installer apache, on utilise dnf : dnf install -y httpd Suivant les syst\u00e8mes, on trouve les fichiers de configuration \u00e0 deux endroits diff\u00e9rents : Debian Redhat /etc/apache2/apache2.conf /etc/httpd/conf/httpd.conf On ne va pas modifier le fichier de configuration de apache mais on va utiliser les includes. Debian Redhat On cherche tout les fichier pour apache : grep -nri --color \"^*Include\" /etc/apache2 On cherche tout les fichier pour apache : grep -nri --color \"^Include\" /etc/httpd On obtient les fichiers suivants : 1 2 3 4 /etc/httpd/conf/httpd.conf.rpmsave:61:Include conf.modules.d/*.conf /etc/httpd/conf/httpd.conf.rpmsave:358:IncludeOptional conf.d/*.conf /etc/httpd/conf/httpd.conf:61:Include conf.modules.d/*.conf /etc/httpd/conf/httpd.conf:358:IncludeOptional conf.d/*.conf","title":"Installation de apache"},{"location":"Linux/Master/Serveurs%20web/Apache/#structuration-de-la-configuration-de-apache","text":"La configuration est d\u00e9coup\u00e9e en plusieurs contextes : Server-config : Configuration du serveur VirtualHost : Configuration d'un serveur Virtuel Directory : Configuration relative \u00e0 un dossier Htaccess : Dans un fichier .htaccess Les formes de contextes sont les suivantes : <Directory ...> <Location ...> <Files ...> Le fichier de configuration .htaccess porte des directives d'acc\u00e8s. C'est de la d\u00e9l\u00e9gation de pourvoir d'acc\u00e8s. Le fichier de configuration accepte les fautes de configurations dans son fichier. La configuration est comme saut\u00e9e si il y a un probl\u00e8me de configuration. Si on cherche les fichiers de logs avec grep -nri --color ErrorLog /etc/httpd : 1 2 3 /etc/httpd/conf/httpd.conf:181:# ErrorLog: The location of the error log file. /etc/httpd/conf/httpd.conf:182:# If you do not specify an ErrorLog directive within a <VirtualHost> /etc/httpd/conf/httpd.conf:187:ErrorLog \"logs/error_log\" Les liens symboliques Les logs sont stock\u00e9s dans le dossier /etc/httpd/logs/ mais en r\u00e9el, nous avons une redirection avec un lien symbolique ( ls -l /etc/httpd ): 1 2 3 4 5 6 7 8 total 12 drwxr-xr-x. 2 root root 4096 21 mars 11 :11 conf drwxr-xr-x. 2 root root 4096 21 mars 11 :11 conf.d drwxr-xr-x. 2 root root 4096 21 mars 11 :11 conf.modules.d lrwxrwxrwx. 1 root root 19 31 janv. 17 :10 logs -> ../../var/log/httpd lrwxrwxrwx. 1 root root 29 31 janv. 17 :10 modules -> ../../usr/lib64/httpd/modules lrwxrwxrwx. 1 root root 10 31 janv. 17 :10 run -> /run/httpd lrwxrwxrwx. 1 root root 19 31 janv. 17 :10 state -> ../../var/lib/httpd Pour avoir une installation minimale, on d\u00e9sactive tout les modules : 1 2 3 cd /etc/httpd/conf.modules.d/ sed -i 's,^LoadModule,#LoadModule,' *.conf systemctl restart httpd On obtiens une erreur lors du red\u00e9marrage du service : Job for httpd.service failed because the control process exited with error code. See \"systemctl status httpd.service\" and \"journalctl -xeu httpd.service\" for details. On cherche ensuite quelle est l'erreur avec la commande journalctl -u httpd.service | tail : 1 2 3 4 5 mars 21 12 :02:32 LG-stream9-1.local systemd [ 1 ] : Starting The Apache HTTP Server... mars 21 12 :02:32 LG-stream9-1.local httpd [ 540060 ] : AH00534: httpd: Configuration error: No MPM loaded. mars 21 12 :02:32 LG-stream9-1.local systemd [ 1 ] : httpd.service: Main process exited, code = exited, status = 1 /FAILURE mars 21 12 :02:32 LG-stream9-1.local systemd [ 1 ] : httpd.service: Failed with result 'exit-code' . mars 21 12 :02:32 LG-stream9-1.local systemd [ 1 ] : Failed to start The Apache HTTP Server. Pour plus d'info sur apache La documentation globale est disponible sur https://httpd.apache.org/docs/2.4/ La documentation des modules est disponible sur https://httpd.apache.org/docs/2.4/mod/ La documentation des directives est disponible sur https://httpd.apache.org/docs/2.4/mod/quickreference.html On cherche les diff\u00e9rents modules \u00e0 activer : mpm_prefork_module unixd_module mod_authz_core mod_autoindex mod_alias mod_systemd Ici c'est la configuration minimale afin que apache se lance. Attention Il ne faut pas oublier de relancer le service httpd systemctl restart httpd Pour que apache puisse voir les fichiers d\u00e9pos\u00e9s dans le dossier \\var\\wwww\\html , il faut activer le module suivant : mod_dir Le fichier qui est affich\u00e9 si aucun fichier n'est pr\u00e9sent dans le dossier pr\u00e9cedent, il y a un fichier qui se trouve dans /etc/httpd/conf.d/welcome.conf : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 # # This configuration file enables the default \"Welcome\" page if there # is no default index page present for the root URL. To disable the # Welcome page, comment out all the lines below. # # NOTE: if this file is removed, it will be restored on upgrades. # < LocationMatch \"^/+$\" > Options -Indexes ErrorDocument 403 /.noindex.html </ LocationMatch > < Directory / usr / share / httpd / noindex > AllowOverride None Require all granted </ Directory > Alias /.noindex.html /usr/share/httpd/noindex/index.html Alias /poweredby.png /usr/share/httpd/icons/apache_pb3.png Alias /system_noindex_logo.png /usr/share/httpd/icons/system_noindex_logo.png","title":"Structuration de la configuration de apache"},{"location":"Linux/Master/Serveurs%20web/Apache/#test-de-charge-de-apache","text":"On cherche \u00e0 activer le module mod_status . Information de la documentation officielle Les d\u00e9tails fournis pour le modile mod_status sont : Le nombre de processus servant les requ\u00eates Le nombre de processus inactifs L'\u00e9tat de chaque processus, le nombre de requ\u00eates qu'il a trait\u00e9es et le nombre total d'octets qu'il a servis (*) Le nombre total d'acc\u00e8s effectu\u00e9s et d'octets servis (*) Le moment o\u00f9 le serveur a \u00e9t\u00e9 d\u00e9marr\u00e9/red\u00e9marr\u00e9 et le temps \u00e9coul\u00e9 depuis Les valeurs moyennes du nombre de requ\u00eates par seconde, du nombre d'octets servis par seconde et du nombre d'octets par requ\u00eate (*) Le pourcentage CPU instantan\u00e9 utilis\u00e9 par chaque processus et par l'ensemble des processus (*) Les h\u00f4tes et requ\u00eates actuellement en cours de traitement (*) On ajoute un fichier de configuration dans le dossier /etc/httpd/config.d qui se nomme status.conf : < IfModule status_module > < location \"/ etat-serveur \" > SetHandler server-status </ location > </ ifmodule >","title":"Test de charge de apache"},{"location":"Linux/Master/Serveurs%20web/Apache/#authentification-avec-apache","text":"","title":"Authentification avec apache"},{"location":"Linux/Master/Serveurs%20web/Apache/#authentification-par-ip","text":"Tache: Acc\u00e8der \u00e0 l'url /etat-serveur uniquement avec l'ip 127.0.0.1 Activer le plugin pour faire de l'acc\u00e8s par IP Modifier le fichier de configuration pour accorder l'acc\u00e8s \u00e0 une seule IP : 127.0.0.1 Ajout d'un nouveau plugin : mod_authz_host Modification du fichier status.conf : 1 2 3 4 5 6 7 8 < IfModule status_module > < location \"/ etat-serveur \" > SetHandler server-status < RequireAny > Require ip 127.0.0.1 </ Requireany > </ location > </ ifmodule >","title":"Authentification par IP"},{"location":"Linux/Master/Serveurs%20web/Apache/#authentification-par-token","text":"Tache: Acc\u00e8der \u00e0 l'url /etat-serveur uniquement avec un token Activer le plugin pour l'authentification avec token Modifier le fichier de configuration pour accorder les utilisateurs qui ont LeBonToken Ajout d'un nouveau plugin : mod_setenvif Modification du fichier status.conf : 1 2 3 4 5 6 7 8 9 10 11 12 < IfModule setenvif_module > SetEnvIf MonToken LeBonToken on_a_le_bon_token </ IfModule > < IfModule status_module > < location \"/ etat-serveur \" > SetHandler server-status < RequireAny > Require ip 127.0.0.1 Require env on_a_le_bon_token </ RequireAny > </ location > </ ifmodule > On test avec curl si l'authentification fonctionne bien : curl -v -s -w '%{stderr}%{http_code}\\n' -H \"MonToken: LeBonToken\" http://10.56.126.223/etat-serveur","title":"Authentification par Token"},{"location":"Linux/Master/Serveurs%20web/Apache/#configuration-avec-des-fichiers-de-configuration","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 < IfModule setenvif_module > SetEnvIf MonToken LeBonToken on_a_le_bon_token </ IfModule > < IfModule status_module > < location \"/ etat-serveur \" > AuthType BAsic AuthNAme ServerStatus AuthBasicProvider file AuthUserFile /etc/httpd/auth.site1 < RequireAny > Require ip 127.0.0.1 Require env on_a_le_bon_token Require valid-user </ RequireAny > SethHandler server-status </ location > </ ifmodule >","title":"Configuration avec des fichiers de configuration"},{"location":"Linux/Master/Serveurs%20web/Apache/#apache-et-son-proxy","text":"","title":"Apache et son proxy"},{"location":"Linux/Master/Serveurs%20web/Apache/#creation-du-fichier-de-configuration","text":"On utilise un package docker afin d'avoir des conteneurs apaches avec le git suivant : Git_moe On lance les conteneurs apache avec un scale \u00e0 2 : docker compose up -d --scale apache = 2 apache On cr\u00e9e un fichier de configuration dans /etc/http/conf.d : <VirtualHost *:80> # DocumentRoot /var/www/html/site ServerName site.local ProxyPass / http://10.0.0.1/ </VirtualHost>","title":"Cr\u00e9ation du fichier de configuration"},{"location":"Linux/Master/Serveurs%20web/Apache/#activation-des-plugins","text":"Des plugins sont n\u00e9c\u00e9ssaires comme le plugin proxy, mime. Pour chercher les plugins : grep -nri nom_du_plugin On d\u00e9commente des plugins et on restart Apache. On obtient maintenant une erreur 503 : <!DOCTYPE HTML PUBLIC \"-//IETF//DTD HTML 2.0//EN\"> < html >< head > < title > 503 Service Unavailable </ title > </ head >< body > < h1 > Service Unavailable </ h1 > < p > The server is temporarily unable to service your request due to maintenance downtime or capacity problems. Please try again later. </ p > </ body ></ html >","title":"Activation des plugins"},{"location":"Linux/Master/Serveurs%20web/Apache/#activation-des-regles-selinux","text":"Selinux prot\u00e8ge la connexion, on active alors la r\u00e8gle SELinux correspondante : setsebool httpd_can_network_connect on On obtient maintenant le bon affichage : <!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 3.2 Final//EN\"> < html > < head > < title > Index of / </ title > </ head > < body > < h1 > Index of / </ h1 > < ul >< li >< a href = \"cpuload.php\" > cpuload.php </ a ></ li > < li >< a href = \"image.gif\" > image.gif </ a ></ li > < li >< a href = \"image.png\" > image.png </ a ></ li > < li >< a href = \"info.php\" > info.php </ a ></ li > < li >< a href = \"memload.php\" > memload.php </ a ></ li > < li >< a href = \"menu.html\" > menu.html </ a ></ li > < li >< a href = \"server-ip.php\" > server-ip.php </ a ></ li > < li >< a href = \"session/\" > session/ </ a ></ li > < li >< a href = \"sleep.php\" > sleep.php </ a ></ li > < li >< a href = \"sqlinject.php\" > sqlinject.php </ a ></ li > < li >< a href = \"status.html\" > status.html </ a ></ li > < li >< a href = \"status.php\" > status.php </ a ></ li > </ ul > < address > Apache/2.4.56 (Unix) Server at 10.0.0.1 Port 80 </ address > </ body ></ html >","title":"Activation des r\u00e8gles SElinux"},{"location":"Linux/Master/Serveurs%20web/Apache/#activation-du-du-proxymatch","text":"But de la manoeuvre Ici nous cherchons que le conteneur 1 r\u00e9ponde pour les .gif et que le serveur 2 reponde pour les .png 1 2 3 4 5 6 7 8 9 10 11 12 <VirtualHost *:80> DocumentRoot /var/www/html/site ServerName site.local ProxyPass /favicon.ico ! ProxyPassMatch ^/ ( .* \\. gif ) $ http://10.0.0.1/ $1 ProxyPassMatch ^/ ( .* \\. png ) $ http://10.0.0.2/ $1 ProxyPass / http://10.0.0.1/ </VirtualHost> Si on regarde les logs du compose ( docker compose logs -f ): moe-apache-2 | 10 .56.126.94 - - [ 12 /Apr/2023:10:15:47 +0200 ] \"GET /image.gif HTTP/1.1\" 304 - \"http://10.56.126.223/\" \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/111.0.0.0 Safari/537.36\" moe-apache-2 | 10 .56.126.94 - - [ 12 /Apr/2023:10:15:47 +0200 ] \"GET /image.gif HTTP/1.1\" 304 - \"http://10.56.126.223/\" \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/111.0.0.0 Safari/537.36\" moe-apache-3 | [ Wed Apr 12 10 :15:54.305280 2023 ] [ authz_core:error ] [ pid 32 ] [ client 10 .0.0.254:52844 ] AH01630: client denied by server configuration: /var/www/html/.htaccess moe-apache-3 | 10 .56.126.94 - - [ 12 /Apr/2023:10:15:54 +0200 ] \"GET / HTTP/1.1\" 200 782 \"-\" \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/111.0.0.0 Safari/537.36\"","title":"Activation du du proxymatch"},{"location":"Linux/Master/Serveurs%20web/Apache/#activation-du-loadbalancer","text":"R\u00e9alisation du fichier de configuration : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 <VirtualHost *:80> DocumentRoot /var/www/html/site ServerName site.local ProxyPass /favicon.ico ! ProxyPassMatch ^/ ( .* \\. php ) $ balancer://poolphp/ $1 <Proxy balancer://poolphp> BalancerMember http://10.0.0.1 BalancerMember http://10.0.0.2 </Proxy> ProxyPassMatch ^/ ( .* \\. gif ) $ http://10.0.0.1/ $1 ProxyPassMatch ^/ ( .* \\. png ) $ http://10.0.0.2/ $1 ProxyPass / http://10.0.0.1/ </VirtualHost> Actviation des modules suivants : - mod_proxy_balancer","title":"Activation du loadbalancer"},{"location":"Linux/Master/Serveurs%20web/Nginx/","text":"Nginx \u00b6 Installation de Nginx \u00b6 Derni\u00e8re version : 1.23.4 (mars 2023) Installation de nginx : dnf install -y nginx D\u00e9marrage de nginx : systemctl start nginx Info On retrouve les fichiers de configuration dans /etc/nginx . Les sites se trouvent dans /usr/share/nginx/html . Rappel Pour rappel lorsqu'on a un dossier en .d pour les configurations, on utilise imp\u00e9rativement ce dossier qui prendra tout les fichiers et qui les int\u00e8gras dans la condiguration de nginx. Changement de configuration de Nginx \u00b6 Cr\u00e9ation d'un premier virtualhost \u00b6 Cr\u00e9ation d'un fichier de configuration pour \"surcharger\" la configuration de nginx (dans conf.d/ ) : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 server { listen 80 ; listen [ :: ] :80 ; server_name test.local ; root /var/www/html ; # Load configuration files for the default server block. include /etc/nginx/default.d/*.conf ; error_page 404 /404.html ; location = /404.html { } error_page 500 502 503 504 /50x.html ; location = /50x.html { } } Dans cette configuration, on utilise un autre r\u00e9pertoire que celui par d\u00e9faut (ligne en surbrillance). On peux v\u00e9rifier site le site est mis en ligne avec la commande : curl -H \"Host: test.local\" http://127.0.0.1:80 Cr\u00e9ation de mutliples virtualhosts \u00b6 On utilise plusieurs fichiers de configurations qui se trouvent dans le dossier conf.d . Les modifications des deux fichiers sont en surbrillances VirtalHost 1 : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 server { listen 80 ; listen [ :: ] :80 ; server_name test.local ; root /var/www/html/site ; # Load configuration files for the default server block. include /etc/nginx/default.d/*.conf ; error_page 404 /404.html ; location = /404.html { } error_page 500 502 503 504 /50x.html ; location = /50x.html { } } Virtalhost 2: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 server { listen 80 ; listen [ :: ] :80 ; server_name test1.local ; root /var/www/html/site1 ; # Load configuration files for the default server block. include /etc/nginx/default.d/*.conf ; error_page 404 /404.html ; location = /404.html { } error_page 500 502 503 504 /50x.html ; location = /50x.html { } } Si on regarde les r\u00e9sultats, on obtient 2 pages diff\u00e9rentes avec la commande curl -H \"Host: test.local\" http://127.0.0.1:80 et curl -H \"Host: test1.local\" http://127.0.0.1:80 : test.local test2.local hello world by nginx Site default hello world by nginx Site 2 Apllication d'un autoindex \u00b6 Modification du virtualhost : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 server { server_name site.local ; root /var/www/html/site ; location /sous-dossier/ { autoindex on ; } location /icons/ { root /usr/share/httpd ; # alias /usr/share/httpd/icons/; autoindex on ; } } Pour les diff\u00e9rents locations, on obtient les valeurs suivantes : Sous-dossier Icons Afin de d'avoir une valeur avec le curl, on cr\u00e9e dans /var/www/html un premier dossier sous-dossier et un second dossier dedans dossier1 1 2 3 4 5 6 7 < html > < head >< title > Index of /sous-dossier/ </ title ></ head > < body > < h1 > Index of /sous-dossier/ </ h1 >< hr >< pre >< a href = \"../\" > ../ </ a > < a href = \"dossier1/\" > dossier1/ </ a > 11-Apr-2023 09:43 - </ pre >< hr ></ body > </ html > < a href = \"small/\" > small/ </ a > 21-Mar-2023 10:11 - < a href = \"README\" > README </ a > 28-Aug-2007 10:47 5108 < a href = \"README.html\" > README.html </ a > 28-Aug-2007 10:47 36057 < a href = \"a.gif\" > a.gif </ a > 20-Nov-2004 20:16 246 < a href = \"a.png\" > a.png </ a > 11-Sep-2007 05:11 306 . . . . </ pre >< hr ></ body > </ html > Mise en place d'un controle d'acc\u00e8s \u00b6 Ajout d'une nouvelle r\u00e8gle : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 server { server_name site.local ; root /var/www/html/site ; location /sous-dossier/ { autoindex on ; } location /prive/ { allow 127 .0.0.1 ; deny all ; } location /icons/ { root /usr/share/httpd ; # alias /usr/share/httpd/icons/; autoindex on ; } } On cr\u00e9e un fichier index.html dans /var/www/html/site/prive et on obtient : hello-private Si on acc\u00e8de par l'IP de la machine (et non 127.0.0.1), on obtient : < html > < head >< title > 403 Forbidden </ title ></ head > < body > < center >< h1 > 403 Forbidden </ h1 ></ center > < hr >< center > nginx/1.22.1 </ center > </ body > </ html > Ajout d'erreurs \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 server { server_name site.local ; root /var/www/html/site ; location /sous-dossier/ { autoindex on ; } location /prive/ { allow 127 .0.0.1 ; deny all ; } location /icons/ { root /usr/share/httpd ; # alias /usr/share/httpd/icons/; autoindex on ; } location /errors/ { alias /var/www/errors ; } error_page 403 = 418 /errors/403.html ; error_page 418 /errors/418.html ; } Php-fpm \u00b6 Installation \u00b6 Installation de Php-fpm : dnf install -y php-fpm D\u00e9marrage et \u00e9criture de fichier \u00b6 Configuration On retrouve la configuration dans /etc/php-fpm.conf . Mise en place de la configuration dans le serveur nginx : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 server { server_name site.local ; root /var/www/html/site ; # Load configuration files for the default server block. include /etc/nginx/default.d/*.conf ; location /sous-dossier/ { autoindex on ; } location /prive/ { allow 127 .0.0.1 ; deny all ; } location /icons/ { root /usr/share/httpd ; # alias /usr/share/httpd/icons/; autoindex on ; } location /errors/ { alias /var/www/errors ; } error_page 403 = 418 /errors/403.html ; error_page 418 /errors/418.html ; } Ajout d'un fichier /var/www/html/site/index.php : <?php echo \"Avant<br>\" ; phpinfo (); echo \"Apr\u00e8s<br>\" ; ?> D\u00e9marrage du php-fpm : systemctl start php-fpm Restart du service nginx : systemctl reload nginx On obteint ensuite : Avant < br > <!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\" \"DTD/xhtml1-transitional.dtd\"> < html xmlns = \"http://www.w3.org/1999/xhtml\" >< head > < style type = \"text/css\" > . . . </ p > < p > If you did not receive a copy of the PHP license, or have any questions about PHP licensing, please contact license@php.net. </ p > </ td ></ tr > </ table > </ div ></ body ></ html > Apr\u00e8s < br >","title":"Nginx"},{"location":"Linux/Master/Serveurs%20web/Nginx/#nginx","text":"","title":"Nginx"},{"location":"Linux/Master/Serveurs%20web/Nginx/#installation-de-nginx","text":"Derni\u00e8re version : 1.23.4 (mars 2023) Installation de nginx : dnf install -y nginx D\u00e9marrage de nginx : systemctl start nginx Info On retrouve les fichiers de configuration dans /etc/nginx . Les sites se trouvent dans /usr/share/nginx/html . Rappel Pour rappel lorsqu'on a un dossier en .d pour les configurations, on utilise imp\u00e9rativement ce dossier qui prendra tout les fichiers et qui les int\u00e8gras dans la condiguration de nginx.","title":"Installation de Nginx"},{"location":"Linux/Master/Serveurs%20web/Nginx/#changement-de-configuration-de-nginx","text":"","title":"Changement de configuration de Nginx"},{"location":"Linux/Master/Serveurs%20web/Nginx/#creation-dun-premier-virtualhost","text":"Cr\u00e9ation d'un fichier de configuration pour \"surcharger\" la configuration de nginx (dans conf.d/ ) : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 server { listen 80 ; listen [ :: ] :80 ; server_name test.local ; root /var/www/html ; # Load configuration files for the default server block. include /etc/nginx/default.d/*.conf ; error_page 404 /404.html ; location = /404.html { } error_page 500 502 503 504 /50x.html ; location = /50x.html { } } Dans cette configuration, on utilise un autre r\u00e9pertoire que celui par d\u00e9faut (ligne en surbrillance). On peux v\u00e9rifier site le site est mis en ligne avec la commande : curl -H \"Host: test.local\" http://127.0.0.1:80","title":"Cr\u00e9ation d'un premier virtualhost"},{"location":"Linux/Master/Serveurs%20web/Nginx/#creation-de-mutliples-virtualhosts","text":"On utilise plusieurs fichiers de configurations qui se trouvent dans le dossier conf.d . Les modifications des deux fichiers sont en surbrillances VirtalHost 1 : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 server { listen 80 ; listen [ :: ] :80 ; server_name test.local ; root /var/www/html/site ; # Load configuration files for the default server block. include /etc/nginx/default.d/*.conf ; error_page 404 /404.html ; location = /404.html { } error_page 500 502 503 504 /50x.html ; location = /50x.html { } } Virtalhost 2: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 server { listen 80 ; listen [ :: ] :80 ; server_name test1.local ; root /var/www/html/site1 ; # Load configuration files for the default server block. include /etc/nginx/default.d/*.conf ; error_page 404 /404.html ; location = /404.html { } error_page 500 502 503 504 /50x.html ; location = /50x.html { } } Si on regarde les r\u00e9sultats, on obtient 2 pages diff\u00e9rentes avec la commande curl -H \"Host: test.local\" http://127.0.0.1:80 et curl -H \"Host: test1.local\" http://127.0.0.1:80 : test.local test2.local hello world by nginx Site default hello world by nginx Site 2","title":"Cr\u00e9ation de mutliples virtualhosts"},{"location":"Linux/Master/Serveurs%20web/Nginx/#apllication-dun-autoindex","text":"Modification du virtualhost : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 server { server_name site.local ; root /var/www/html/site ; location /sous-dossier/ { autoindex on ; } location /icons/ { root /usr/share/httpd ; # alias /usr/share/httpd/icons/; autoindex on ; } } Pour les diff\u00e9rents locations, on obtient les valeurs suivantes : Sous-dossier Icons Afin de d'avoir une valeur avec le curl, on cr\u00e9e dans /var/www/html un premier dossier sous-dossier et un second dossier dedans dossier1 1 2 3 4 5 6 7 < html > < head >< title > Index of /sous-dossier/ </ title ></ head > < body > < h1 > Index of /sous-dossier/ </ h1 >< hr >< pre >< a href = \"../\" > ../ </ a > < a href = \"dossier1/\" > dossier1/ </ a > 11-Apr-2023 09:43 - </ pre >< hr ></ body > </ html > < a href = \"small/\" > small/ </ a > 21-Mar-2023 10:11 - < a href = \"README\" > README </ a > 28-Aug-2007 10:47 5108 < a href = \"README.html\" > README.html </ a > 28-Aug-2007 10:47 36057 < a href = \"a.gif\" > a.gif </ a > 20-Nov-2004 20:16 246 < a href = \"a.png\" > a.png </ a > 11-Sep-2007 05:11 306 . . . . </ pre >< hr ></ body > </ html >","title":"Apllication d'un autoindex"},{"location":"Linux/Master/Serveurs%20web/Nginx/#mise-en-place-dun-controle-dacces","text":"Ajout d'une nouvelle r\u00e8gle : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 server { server_name site.local ; root /var/www/html/site ; location /sous-dossier/ { autoindex on ; } location /prive/ { allow 127 .0.0.1 ; deny all ; } location /icons/ { root /usr/share/httpd ; # alias /usr/share/httpd/icons/; autoindex on ; } } On cr\u00e9e un fichier index.html dans /var/www/html/site/prive et on obtient : hello-private Si on acc\u00e8de par l'IP de la machine (et non 127.0.0.1), on obtient : < html > < head >< title > 403 Forbidden </ title ></ head > < body > < center >< h1 > 403 Forbidden </ h1 ></ center > < hr >< center > nginx/1.22.1 </ center > </ body > </ html >","title":"Mise en place d'un controle d'acc\u00e8s"},{"location":"Linux/Master/Serveurs%20web/Nginx/#ajout-derreurs","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 server { server_name site.local ; root /var/www/html/site ; location /sous-dossier/ { autoindex on ; } location /prive/ { allow 127 .0.0.1 ; deny all ; } location /icons/ { root /usr/share/httpd ; # alias /usr/share/httpd/icons/; autoindex on ; } location /errors/ { alias /var/www/errors ; } error_page 403 = 418 /errors/403.html ; error_page 418 /errors/418.html ; }","title":"Ajout d'erreurs"},{"location":"Linux/Master/Serveurs%20web/Nginx/#php-fpm","text":"","title":"Php-fpm"},{"location":"Linux/Master/Serveurs%20web/Nginx/#installation","text":"Installation de Php-fpm : dnf install -y php-fpm","title":"Installation"},{"location":"Linux/Master/Serveurs%20web/Nginx/#demarrage-et-ecriture-de-fichier","text":"Configuration On retrouve la configuration dans /etc/php-fpm.conf . Mise en place de la configuration dans le serveur nginx : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 server { server_name site.local ; root /var/www/html/site ; # Load configuration files for the default server block. include /etc/nginx/default.d/*.conf ; location /sous-dossier/ { autoindex on ; } location /prive/ { allow 127 .0.0.1 ; deny all ; } location /icons/ { root /usr/share/httpd ; # alias /usr/share/httpd/icons/; autoindex on ; } location /errors/ { alias /var/www/errors ; } error_page 403 = 418 /errors/403.html ; error_page 418 /errors/418.html ; } Ajout d'un fichier /var/www/html/site/index.php : <?php echo \"Avant<br>\" ; phpinfo (); echo \"Apr\u00e8s<br>\" ; ?> D\u00e9marrage du php-fpm : systemctl start php-fpm Restart du service nginx : systemctl reload nginx On obteint ensuite : Avant < br > <!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\" \"DTD/xhtml1-transitional.dtd\"> < html xmlns = \"http://www.w3.org/1999/xhtml\" >< head > < style type = \"text/css\" > . . . </ p > < p > If you did not receive a copy of the PHP license, or have any questions about PHP licensing, please contact license@php.net. </ p > </ td ></ tr > </ table > </ div ></ body ></ html > Apr\u00e8s < br >","title":"D\u00e9marrage et \u00e9criture de fichier"},{"location":"Linux/Master/S%C3%A9curit%C3%A9/SElinux/","text":"Se linux \u00b6 Introduction \u00b6 SE Linux se base sur la s\u00e9curit\u00e9 de type MAC (Mandatory Access Control). La commande sestatus permet d'obtenir des informations concernant la protection de SE Linux Exemple de protection SE Linux SE Linux poss\u00e8de 2 modes : Enforcing : cette option bloque et log Permissive : cette option laisse tout faire et log Pour forcer le mode permissive on utilise la commande : Solution 1 Solution 2 setenforce 0 setenforce Permissive Pour forcer le mode enforcing on utilise la commande : Solution 1 Solution 2 setenforce 1 setenforce Enforcing Chaque fihcier et prossesus ont un label de s\u00e9curit\u00e9 (security context) avec une forme : user:role:type(files)/domaine(processus):mls Cette forme peut-etre lue avec les commandes : ls -Z /etc/hosts et ps -Zfax Info Z pour lister les labels f affiche sous forme d'arbre a pour lister les porcessus des autres utilisateurs x affiche les processus qui n'ont pas de terminal de controle Lister les r\u00e8gles d'une strat\u00e9gie : chcon -R -t Info -R pour recurcive -t pour le type Manipulations \u00b6 Mise \u00e0 z\u00e9ro de audit.log \u00b6 Arret du service auditd : systemctl stop auditd Si le service ne veux pas \u00eatre arr\u00e9t\u00e9 par le biais de systemctl , utilisez : service auditd stop Supprimez le fichier \\var\\log\\audit\\audit.log rm \\v ar \\l og \\a udit \\a udit.log On regarde ensuite les labels de s\u00e9curit\u00e9 du fichier : ls -lZ \\v ar \\l og \\a udit \\a udit.log Mise \u00e0 z\u00e9ro de SElinux \u00b6 Reconstitution des labels de s\u00e9curit\u00e9 \u00b6 Danger La reconsititution des labels de s\u00e9curit\u00e9s concerne tout les fichiers. Si des labels de s\u00e9curit\u00e9 ont \u00e9t\u00e9 modifi\u00e9s manuellement , ceux-ci seront r\u00e9initialis\u00e9s par la reconsititution sauf si ceux-ci ont \u00e9t\u00e9 rentr\u00e9s dans les configurations persistantes . Pour reconstruire les labels de s\u00e9curit\u00e9 : restorecon -R / Pour reconstruire les labels de s\u00e9curit\u00e9 au prochain d\u00e9marrage : touch /.autorelabel Au red\u00e9marrage on peut observe le relabel : Message au red\u00e9marrage de l'autorelabel Les templates sont stocker dans /etc/selinux/targeted . Contenu du dossier targeted Exemple d'un fichier (ici /etc/selinux/targeted/contexts/systemd_contexts ) : runtime = system_u:object_r:systemd_runtime_unit_file_t:s0 Travail sur un serveur FTP \u00b6 Abstract Installation du serveur : vsftpd On observe ensuite les labels de s\u00e9curit\u00e9 sur les dossiers /var/ftp et /var/ftp/pub . On remmarque que sur les labels de s\u00e9curit\u00e9, on retrouve un label public_content_t . On demarre le service avec systemctl start vsftpd . Note Le firewall bloque peut-\u00eatre les connexion au ftp via le navigateur (ftp:// ipmachine ). On active le service firewall FTP : firewall-cmd --add-service = ftp On se connecte avec un client ftp et une session comme root. On obteint un succ\u00e8s de connexion. On s'int\u00e9rresse maintenant au fichier de configuration /etc/vsftpd/vsftpd.conf . On retrouve la ligne : anonymous_enable = NO La ligne ci-dessus doit \u00eatre comment\u00e9e afin de pouvoir autoriser les connexions anonymes. Warning Il faut restart le service afin de prendre en compte le changement de configuration. On va cr\u00e9er les dossiers pour d\u00e9placer l'attache du ftp dans /home/ftp/pub Info On peut utiliser mkdir -p avec l'option -p qui permet de cr\u00e9er les parents du dossier voulu. On ajoute une ligne dans /etc/vsftpd/vsftpd.conf pour lier le ftp dans le dossier cr\u00e9er pr\u00e9c\u00e9dement : anon_root = /home/ftp On regarde les labels de s\u00e9urit\u00e9 sur le dossier ls -lZ /home/ftp/ drwxr-xr-x. 2 root root unconfined_u:object_r:user_home_t:s0 4096 27 janv. 09 :34 pub Info A partir de redhat 9, on \u00e0 maintenant acc\u00e8s au FTP . On cherche \u00e0 lister les diff\u00e9rents modules de SE Linux avec la commande avec l'installation de tools: dnf -y install setools-console On va lister tout les r\u00e8gles d'autorisations : sesearch --allow -s ftpd_t | grep \" ftpd\" Et on obteint une information concernant la r\u00e8gle ci-dessus : 1 2 allow ftpd_t user_home_t:dir { create link rename reparent rmdir setattr unlink watch watch_reads } ; allow ftpd_t user_home_t:file { create ioctl link lock map open read rename setattr unlink watch watch_reads write } ; On peux filtrer aussi avec : sesearch --allow -s ftpd_t -t user_home_t On obteint : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 allow daemon user_home_t:file { append getattr } ; allow domain file_type:blk_file map ; [ domain_can_mmap_files ] :True allow domain file_type:chr_file map ; [ domain_can_mmap_files ] :True allow domain file_type:file map ; [ domain_can_mmap_files ] :True allow domain file_type:lnk_file map ; [ domain_can_mmap_files ] :True allow ftpd_t file_type:filesystem getattr ; allow ftpd_t non_security_file_type:dir { add_name create getattr ioctl link lock open read remove_name rename reparent rmdir search setattr unlink watch watch_reads write } ; [ ftpd_full_access ] :True allow ftpd_t non_security_file_type:dir { add_name getattr ioctl lock open read remove_name search write } ; [ ftpd_full_access ] :True allow ftpd_t non_security_file_type:dir { add_name getattr ioctl lock open read remove_name search write } ; [ ftpd_full_access ] :True allow ftpd_t non_security_file_type:file { append create getattr ioctl link lock open read rename setattr unlink watch watch_reads write } ; [ ftpd_full_access ] :True allow ftpd_t non_security_file_type:lnk_file { append create getattr ioctl link lock read rename setattr unlink watch watch_reads write } ; [ ftpd_full_access ] :True allow ftpd_t user_home_t:dir { create link rename reparent rmdir setattr unlink watch watch_reads } ; allow ftpd_t user_home_t:file { create ioctl link lock map open read rename setattr unlink watch watch_reads write } ; allow userdom_filetrans_type user_home_t:dir { add_name getattr ioctl lock open read remove_name search write } ; Exploration de SElinux avec les ports \u00b6 Installation de apache avec le package httpd . Une fois l'installation termin\u00e9e, on modifie le port de Apache dans le fichier de configuration ( /etc/httpd/conf/httpd.conf ) : Listen 8888 Warning Pour activer la modification, il faut red\u00e9marrer le service ou le d\u00e9marrer si cela n'a pas \u00e9t\u00e9 fait \u00e0 l'installation Pour red\u00e9marrer : systemctl restart httpd Pour d\u00e9marrer le service : systemctl start httpd Avec le restart, on obteint une erreur de configuration : 1 2 Job for httpd.service failed because the control process exited with error code. See \"systemctl status httpd.service\" and \"journalctl -xeu httpd.service\" for details. Si on observe les logs avec journalctl -u httpd | tail , on remarque que le port 8888 provoque un probl\u00e8me : 1 2 3 4 5 6 7 8 janv. 27 11 :15:33 LG-stream9-1.local systemd [ 1 ] : Starting The Apache HTTP Server... janv. 27 11 :15:35 LG-stream9-1.local httpd [ 1865 ] : ( 13 ) Permission denied: AH00072: make_sock: could not bind to address [ :: ] :8888 janv. 27 11 :15:35 LG-stream9-1.local httpd [ 1865 ] : ( 13 ) Permission denied: AH00072: make_sock: could not bind to address 0 .0.0.0:8888 janv. 27 11 :15:35 LG-stream9-1.local httpd [ 1865 ] : no listening sockets available, shutting down janv. 27 11 :15:35 LG-stream9-1.local httpd [ 1865 ] : AH00015: Unable to open logs janv. 27 11 :15:35 LG-stream9-1.local systemd [ 1 ] : httpd.service: Main process exited, code = exited, status = 1 /FAILURE janv. 27 11 :15:35 LG-stream9-1.local systemd [ 1 ] : httpd.service: Failed with result 'exit-code' . janv. 27 11 :15:35 LG-stream9-1.local systemd [ 1 ] : Failed to start The Apache HTTP Server. On cherche aussi dans /var/log/audit/audit.log avec la commane grep avc /var/log/audit/audit.log 1 2 type = AVC msg = audit ( 1674814535 .950:140 ) : avc: denied { name_bind } for pid = 1865 comm = \"httpd\" src = 8888 scontext = system_u:system_r:httpd_t:s0 tcontext = system_u:object_r:unreserved_port_t:s0 tclass = tcp_socket permissive = 0 type = AVC msg = audit ( 1674814535 .953:141 ) : avc: denied { name_bind } for pid = 1865 comm = \"httpd\" src = 8888 scontext = system_u:system_r:httpd_t:s0 tcontext = system_u:object_r:unreserved_port_t:s0 tclass = tcp_socket permissive = 0 On utilise audit2 pour comprendre le probl\u00e8me avec la commande ( grep avc /var/log/audit/audit.log | tail -n -1 | audit2why ): 1 2 3 4 5 6 Was caused by: The boolean nis_enabled was set incorrectly. Description: Allow nis to enabled Allow access by executing: # setsebool -P nis_enabled 1 Puis on cherche de savoir comment r\u00e9soudre ce probl\u00e8me avec audit2 avec la commande ( grep avc /var/log/audit/audit.log | tail -n -1 | audit2allow ): 1 2 3 4 #============= httpd_t ============== #!!!! This avc can be allowed using the boolean 'nis_enabled' allow httpd_t unreserved_port_t:tcp_socket name_bind ; Danger Attention cela provoque une faille de s\u00e9curit\u00e9. Nous allons donc passer par semanage . Pour lister tout les ports avec semanage ( semanage port -l | grep http ) : 1 2 3 4 5 http_cache_port_t tcp 8080 , 8118 , 8123 , 10001 -10010 http_cache_port_t udp 3130 http_port_t tcp 80 , 81 , 443 , 488 , 8008 , 8009 , 8443 , 9000 pegasus_http_port_t tcp 5988 pegasus_https_port_t tcp 5989 Ici on peut d\u00e9couvrir tout les ports, on modifie alors le label http pour autoriser le port 8888 : semanage port -a -t http_port_t -p tcp 8888 Si on observe les ports, on le retrouve dans la liste : 1 2 3 4 5 http_cache_port_t tcp 8080 , 8118 , 8123 , 10001 -10010 http_cache_port_t udp 3130 http_port_t tcp 8888 , 80 , 81 , 443 , 488 , 8008 , 8009 , 8443 , 9000 pegasus_http_port_t tcp 5988 pegasus_https_port_t tcp 5989 On red\u00e9marre alors le service httpd et on obteint aucune erreurs. Les bool\u00e9ens dans SElinux \u00b6 Pr\u00e9requis pour r\u00e9aliser cette activit\u00e9 Il est n\u00e9c\u00e9ssaire d'avoir un serveur web (par exemple httpd autrement dit apache). Ici nous utilisons le serveur web pr\u00e9c\u00e9dement install\u00e9 et sur le port 8888. Normalement, le port par d\u00e9faut est 80. Cr\u00e9ation d'un fichier /var/www/cgi-bin/env.cgi contenant : 1 2 3 4 5 #!/bin/bash echo -e \"Content-Type: text/plain\\n\\n\" set On rend ensuite le fichier executable pour tout le monde : chmod 755 /var/www/cgi-bin/env.cgi Puis on test avec un curl : curl http://127.0.0.1:8888/cgi-bin/env.cgi Attention au firewall Attention le firewall peut bloquer la communication sur le port 8888. Il faut autoriser le trafic sur le port : firewall-cmd --add-port = 8888 /tcp Petite modification du fichier /var/www/cgi-bin/env.cgi pour executer des requetes dans l'URL: 1 2 3 4 5 6 7 #!/bin/bash echo -e \"Content-Type: text/plain\\n\\n\" echo \"La commande est : $QUERY_STRING \" CMD = $( echo $QUERY_STRING | sed 's,%20, ,g' ) $CMD Si on test le script dans le navigateur avec la commande curl http://172.19.252.60:8888/cgi-bin/env.cgi?ls : Exemple avec la commande ls Danger Attention, les commandes sont execut\u00e9es avec l'identit\u00e9 du user wwwdata . Le utlisateur poss\u00e8de donc tout les droits de cr\u00e9ations et autres li\u00e9s \u00e0 wwwdata . Pour la s\u00e9curit\u00e9, on va d\u00e9sactiver toutes les executions des .cgi : getsebool -a | grep http On d\u00e9sactive alors l'execution des CGI : setsebool -P httpd_enable_cgi off Tip Attention au mode de selinux car si il est en permissive cela laissera actif l'execution des CGI.","title":"Se linux"},{"location":"Linux/Master/S%C3%A9curit%C3%A9/SElinux/#se-linux","text":"","title":"Se linux"},{"location":"Linux/Master/S%C3%A9curit%C3%A9/SElinux/#introduction","text":"SE Linux se base sur la s\u00e9curit\u00e9 de type MAC (Mandatory Access Control). La commande sestatus permet d'obtenir des informations concernant la protection de SE Linux Exemple de protection SE Linux SE Linux poss\u00e8de 2 modes : Enforcing : cette option bloque et log Permissive : cette option laisse tout faire et log Pour forcer le mode permissive on utilise la commande : Solution 1 Solution 2 setenforce 0 setenforce Permissive Pour forcer le mode enforcing on utilise la commande : Solution 1 Solution 2 setenforce 1 setenforce Enforcing Chaque fihcier et prossesus ont un label de s\u00e9curit\u00e9 (security context) avec une forme : user:role:type(files)/domaine(processus):mls Cette forme peut-etre lue avec les commandes : ls -Z /etc/hosts et ps -Zfax Info Z pour lister les labels f affiche sous forme d'arbre a pour lister les porcessus des autres utilisateurs x affiche les processus qui n'ont pas de terminal de controle Lister les r\u00e8gles d'une strat\u00e9gie : chcon -R -t Info -R pour recurcive -t pour le type","title":"Introduction"},{"location":"Linux/Master/S%C3%A9curit%C3%A9/SElinux/#manipulations","text":"","title":"Manipulations"},{"location":"Linux/Master/S%C3%A9curit%C3%A9/SElinux/#mise-a-zero-de-auditlog","text":"Arret du service auditd : systemctl stop auditd Si le service ne veux pas \u00eatre arr\u00e9t\u00e9 par le biais de systemctl , utilisez : service auditd stop Supprimez le fichier \\var\\log\\audit\\audit.log rm \\v ar \\l og \\a udit \\a udit.log On regarde ensuite les labels de s\u00e9curit\u00e9 du fichier : ls -lZ \\v ar \\l og \\a udit \\a udit.log","title":"Mise \u00e0 z\u00e9ro de audit.log"},{"location":"Linux/Master/S%C3%A9curit%C3%A9/SElinux/#mise-a-zero-de-selinux","text":"","title":"Mise \u00e0 z\u00e9ro de SElinux"},{"location":"Linux/Master/S%C3%A9curit%C3%A9/SElinux/#reconstitution-des-labels-de-securite","text":"Danger La reconsititution des labels de s\u00e9curit\u00e9s concerne tout les fichiers. Si des labels de s\u00e9curit\u00e9 ont \u00e9t\u00e9 modifi\u00e9s manuellement , ceux-ci seront r\u00e9initialis\u00e9s par la reconsititution sauf si ceux-ci ont \u00e9t\u00e9 rentr\u00e9s dans les configurations persistantes . Pour reconstruire les labels de s\u00e9curit\u00e9 : restorecon -R / Pour reconstruire les labels de s\u00e9curit\u00e9 au prochain d\u00e9marrage : touch /.autorelabel Au red\u00e9marrage on peut observe le relabel : Message au red\u00e9marrage de l'autorelabel Les templates sont stocker dans /etc/selinux/targeted . Contenu du dossier targeted Exemple d'un fichier (ici /etc/selinux/targeted/contexts/systemd_contexts ) : runtime = system_u:object_r:systemd_runtime_unit_file_t:s0","title":"Reconstitution des labels de s\u00e9curit\u00e9"},{"location":"Linux/Master/S%C3%A9curit%C3%A9/SElinux/#travail-sur-un-serveur-ftp","text":"Abstract Installation du serveur : vsftpd On observe ensuite les labels de s\u00e9curit\u00e9 sur les dossiers /var/ftp et /var/ftp/pub . On remmarque que sur les labels de s\u00e9curit\u00e9, on retrouve un label public_content_t . On demarre le service avec systemctl start vsftpd . Note Le firewall bloque peut-\u00eatre les connexion au ftp via le navigateur (ftp:// ipmachine ). On active le service firewall FTP : firewall-cmd --add-service = ftp On se connecte avec un client ftp et une session comme root. On obteint un succ\u00e8s de connexion. On s'int\u00e9rresse maintenant au fichier de configuration /etc/vsftpd/vsftpd.conf . On retrouve la ligne : anonymous_enable = NO La ligne ci-dessus doit \u00eatre comment\u00e9e afin de pouvoir autoriser les connexions anonymes. Warning Il faut restart le service afin de prendre en compte le changement de configuration. On va cr\u00e9er les dossiers pour d\u00e9placer l'attache du ftp dans /home/ftp/pub Info On peut utiliser mkdir -p avec l'option -p qui permet de cr\u00e9er les parents du dossier voulu. On ajoute une ligne dans /etc/vsftpd/vsftpd.conf pour lier le ftp dans le dossier cr\u00e9er pr\u00e9c\u00e9dement : anon_root = /home/ftp On regarde les labels de s\u00e9urit\u00e9 sur le dossier ls -lZ /home/ftp/ drwxr-xr-x. 2 root root unconfined_u:object_r:user_home_t:s0 4096 27 janv. 09 :34 pub Info A partir de redhat 9, on \u00e0 maintenant acc\u00e8s au FTP . On cherche \u00e0 lister les diff\u00e9rents modules de SE Linux avec la commande avec l'installation de tools: dnf -y install setools-console On va lister tout les r\u00e8gles d'autorisations : sesearch --allow -s ftpd_t | grep \" ftpd\" Et on obteint une information concernant la r\u00e8gle ci-dessus : 1 2 allow ftpd_t user_home_t:dir { create link rename reparent rmdir setattr unlink watch watch_reads } ; allow ftpd_t user_home_t:file { create ioctl link lock map open read rename setattr unlink watch watch_reads write } ; On peux filtrer aussi avec : sesearch --allow -s ftpd_t -t user_home_t On obteint : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 allow daemon user_home_t:file { append getattr } ; allow domain file_type:blk_file map ; [ domain_can_mmap_files ] :True allow domain file_type:chr_file map ; [ domain_can_mmap_files ] :True allow domain file_type:file map ; [ domain_can_mmap_files ] :True allow domain file_type:lnk_file map ; [ domain_can_mmap_files ] :True allow ftpd_t file_type:filesystem getattr ; allow ftpd_t non_security_file_type:dir { add_name create getattr ioctl link lock open read remove_name rename reparent rmdir search setattr unlink watch watch_reads write } ; [ ftpd_full_access ] :True allow ftpd_t non_security_file_type:dir { add_name getattr ioctl lock open read remove_name search write } ; [ ftpd_full_access ] :True allow ftpd_t non_security_file_type:dir { add_name getattr ioctl lock open read remove_name search write } ; [ ftpd_full_access ] :True allow ftpd_t non_security_file_type:file { append create getattr ioctl link lock open read rename setattr unlink watch watch_reads write } ; [ ftpd_full_access ] :True allow ftpd_t non_security_file_type:lnk_file { append create getattr ioctl link lock read rename setattr unlink watch watch_reads write } ; [ ftpd_full_access ] :True allow ftpd_t user_home_t:dir { create link rename reparent rmdir setattr unlink watch watch_reads } ; allow ftpd_t user_home_t:file { create ioctl link lock map open read rename setattr unlink watch watch_reads write } ; allow userdom_filetrans_type user_home_t:dir { add_name getattr ioctl lock open read remove_name search write } ;","title":"Travail sur un serveur FTP"},{"location":"Linux/Master/S%C3%A9curit%C3%A9/SElinux/#exploration-de-selinux-avec-les-ports","text":"Installation de apache avec le package httpd . Une fois l'installation termin\u00e9e, on modifie le port de Apache dans le fichier de configuration ( /etc/httpd/conf/httpd.conf ) : Listen 8888 Warning Pour activer la modification, il faut red\u00e9marrer le service ou le d\u00e9marrer si cela n'a pas \u00e9t\u00e9 fait \u00e0 l'installation Pour red\u00e9marrer : systemctl restart httpd Pour d\u00e9marrer le service : systemctl start httpd Avec le restart, on obteint une erreur de configuration : 1 2 Job for httpd.service failed because the control process exited with error code. See \"systemctl status httpd.service\" and \"journalctl -xeu httpd.service\" for details. Si on observe les logs avec journalctl -u httpd | tail , on remarque que le port 8888 provoque un probl\u00e8me : 1 2 3 4 5 6 7 8 janv. 27 11 :15:33 LG-stream9-1.local systemd [ 1 ] : Starting The Apache HTTP Server... janv. 27 11 :15:35 LG-stream9-1.local httpd [ 1865 ] : ( 13 ) Permission denied: AH00072: make_sock: could not bind to address [ :: ] :8888 janv. 27 11 :15:35 LG-stream9-1.local httpd [ 1865 ] : ( 13 ) Permission denied: AH00072: make_sock: could not bind to address 0 .0.0.0:8888 janv. 27 11 :15:35 LG-stream9-1.local httpd [ 1865 ] : no listening sockets available, shutting down janv. 27 11 :15:35 LG-stream9-1.local httpd [ 1865 ] : AH00015: Unable to open logs janv. 27 11 :15:35 LG-stream9-1.local systemd [ 1 ] : httpd.service: Main process exited, code = exited, status = 1 /FAILURE janv. 27 11 :15:35 LG-stream9-1.local systemd [ 1 ] : httpd.service: Failed with result 'exit-code' . janv. 27 11 :15:35 LG-stream9-1.local systemd [ 1 ] : Failed to start The Apache HTTP Server. On cherche aussi dans /var/log/audit/audit.log avec la commane grep avc /var/log/audit/audit.log 1 2 type = AVC msg = audit ( 1674814535 .950:140 ) : avc: denied { name_bind } for pid = 1865 comm = \"httpd\" src = 8888 scontext = system_u:system_r:httpd_t:s0 tcontext = system_u:object_r:unreserved_port_t:s0 tclass = tcp_socket permissive = 0 type = AVC msg = audit ( 1674814535 .953:141 ) : avc: denied { name_bind } for pid = 1865 comm = \"httpd\" src = 8888 scontext = system_u:system_r:httpd_t:s0 tcontext = system_u:object_r:unreserved_port_t:s0 tclass = tcp_socket permissive = 0 On utilise audit2 pour comprendre le probl\u00e8me avec la commande ( grep avc /var/log/audit/audit.log | tail -n -1 | audit2why ): 1 2 3 4 5 6 Was caused by: The boolean nis_enabled was set incorrectly. Description: Allow nis to enabled Allow access by executing: # setsebool -P nis_enabled 1 Puis on cherche de savoir comment r\u00e9soudre ce probl\u00e8me avec audit2 avec la commande ( grep avc /var/log/audit/audit.log | tail -n -1 | audit2allow ): 1 2 3 4 #============= httpd_t ============== #!!!! This avc can be allowed using the boolean 'nis_enabled' allow httpd_t unreserved_port_t:tcp_socket name_bind ; Danger Attention cela provoque une faille de s\u00e9curit\u00e9. Nous allons donc passer par semanage . Pour lister tout les ports avec semanage ( semanage port -l | grep http ) : 1 2 3 4 5 http_cache_port_t tcp 8080 , 8118 , 8123 , 10001 -10010 http_cache_port_t udp 3130 http_port_t tcp 80 , 81 , 443 , 488 , 8008 , 8009 , 8443 , 9000 pegasus_http_port_t tcp 5988 pegasus_https_port_t tcp 5989 Ici on peut d\u00e9couvrir tout les ports, on modifie alors le label http pour autoriser le port 8888 : semanage port -a -t http_port_t -p tcp 8888 Si on observe les ports, on le retrouve dans la liste : 1 2 3 4 5 http_cache_port_t tcp 8080 , 8118 , 8123 , 10001 -10010 http_cache_port_t udp 3130 http_port_t tcp 8888 , 80 , 81 , 443 , 488 , 8008 , 8009 , 8443 , 9000 pegasus_http_port_t tcp 5988 pegasus_https_port_t tcp 5989 On red\u00e9marre alors le service httpd et on obteint aucune erreurs.","title":"Exploration de SElinux avec les ports"},{"location":"Linux/Master/S%C3%A9curit%C3%A9/SElinux/#les-booleens-dans-selinux","text":"Pr\u00e9requis pour r\u00e9aliser cette activit\u00e9 Il est n\u00e9c\u00e9ssaire d'avoir un serveur web (par exemple httpd autrement dit apache). Ici nous utilisons le serveur web pr\u00e9c\u00e9dement install\u00e9 et sur le port 8888. Normalement, le port par d\u00e9faut est 80. Cr\u00e9ation d'un fichier /var/www/cgi-bin/env.cgi contenant : 1 2 3 4 5 #!/bin/bash echo -e \"Content-Type: text/plain\\n\\n\" set On rend ensuite le fichier executable pour tout le monde : chmod 755 /var/www/cgi-bin/env.cgi Puis on test avec un curl : curl http://127.0.0.1:8888/cgi-bin/env.cgi Attention au firewall Attention le firewall peut bloquer la communication sur le port 8888. Il faut autoriser le trafic sur le port : firewall-cmd --add-port = 8888 /tcp Petite modification du fichier /var/www/cgi-bin/env.cgi pour executer des requetes dans l'URL: 1 2 3 4 5 6 7 #!/bin/bash echo -e \"Content-Type: text/plain\\n\\n\" echo \"La commande est : $QUERY_STRING \" CMD = $( echo $QUERY_STRING | sed 's,%20, ,g' ) $CMD Si on test le script dans le navigateur avec la commande curl http://172.19.252.60:8888/cgi-bin/env.cgi?ls : Exemple avec la commande ls Danger Attention, les commandes sont execut\u00e9es avec l'identit\u00e9 du user wwwdata . Le utlisateur poss\u00e8de donc tout les droits de cr\u00e9ations et autres li\u00e9s \u00e0 wwwdata . Pour la s\u00e9curit\u00e9, on va d\u00e9sactiver toutes les executions des .cgi : getsebool -a | grep http On d\u00e9sactive alors l'execution des CGI : setsebool -P httpd_enable_cgi off Tip Attention au mode de selinux car si il est en permissive cela laissera actif l'execution des CGI.","title":"Les bool\u00e9ens dans SElinux"},{"location":"Linux/Master/S%C3%A9curit%C3%A9/permissions/","text":"Les permissions \u00b6 Liste des permissions \u00b6 Commande pour obtenir des informations concernant les droits : ls -l On obteint plusieurs groupes : x : pour se d\u00e9placer dedans (pour les fichier, on execute le fichier tel qu'un script) w : modification de contenu avec l'ajout, la modification ou la suppression d'octect (en fichiers ou en repertoires) r : lecture et copie des fichiers ( r\u00e9pertoire : lister les fichiers) s : Il conf\u00e8re l'identit\u00e9 du propri\u00e9taire de la commande (avec passwd par exemple) t : on trouve la permission sur tout les dossiers temporaires/partages. Seul le propri\u00e8taire du fichier peut le supprimer. (sticky-bit) Commandes de changements de permissions \u00b6 chown : pour modifier mes permissions du fichier chgrp : L'administrateur et l'utilisateur peuvent modifier les permissions chmod : Permet de changer les permissions d'acc\u00e8s d'un fichier ou d'un r\u00e9pertoire (il faut etre propri\u00e8taire du fichier) Pour chercher les fichiers qui poss\u00e8de le droit s : find -perm /u = s Et on obtient une liste de fichier plus ou moins longue si docker est install\u00e9 : Liste des fichiers poss\u00e8dant le droit permettant une \u00e9l\u00e9vation de privil\u00e8ges Info On peux ajouter une option -o pour faire un or et donc lier plusieurs arguments Exemple : find / -perm /u=s -o -perm /g=s Les capabilities \u00b6 Premi\u00e8res notions sur les capabilities \u00b6 Installation des pages de man (si elles ne sont pas pr\u00e9sentes) : dnf -y install man-pages Overture du man de capabilities : man capabilities Les capabilities ont 2 cat\u00e9gories : les processus privili\u00e9gi\u00e9s les processes non privili\u00e9gi\u00e9s Les processus privili\u00e9gi\u00e9s sont appell\u00e9 par un superutilisateur ou root. Ils contournent les verfications du noyaux. Les processus non privili\u00e9gi\u00e9s sont soumis \u00e0 une verification bas\u00e9e sur le processus. Les options : CAP_DAC_OVERRIDE permet \u00e0 root de contourner les v\u00e9rification de lecture et d'\u00e9critures CAP_NET_BIND_SERVICE permet de lier un socket aux ports pr\u00e9vili\u00e9gi\u00e9s (inf\u00e9rieur \u00e0 1024) CAP_CHOWN permet d'apporter des modifications sur les fichiers Tests de la commande NC \u00b6 Avec la commande NC , cela permet de d\u00e9clarer un serveur d'\u00e9coute et ainsi de pouvoir communiquer entre 2 ordinateurs distants Tip Pour pouvoir utiliser les commandes NC, il faut l'installer : dnf -y install nc L'utilisation de nc se r\u00e9alise avec 2 terminaux afin de pouvoir cr\u00e9er comme un canal de communication entre les deux terminaux. On lance avec un user sans droits sudo la commande : nc -l 90 On obtient alors une erreur: Ncat: bind to :::90: Permission denied. QUITTING. Rappel sur les commandes de groupes et users Ajout d'un groupe nomm\u00e9 ncusers : groupadd ncusers Ajout d'un utilisateur avec le groupe ncusers useradd -g ncusers ncuser On copie le dossier nc dans le tmp : cp /bin/nc /tmp/capnc Mise en place des droits : install -o ncuser -g ncusers -m 700 /bin/nc /tmp/capnc R\u00e8glage des droits avec la commande setcap : setcap cap_net_bind_service = ep /tmp/capnc V\u00e9rification des droits sur le dossier : getcap /tmp/capnc Puis on v\u00e9rifie si les droits focntionne avec la connexion sur le ncuser puis l'indication de la commande : su - ncuser -c \"/tmp/capnc -l 90\"","title":"Les permissions"},{"location":"Linux/Master/S%C3%A9curit%C3%A9/permissions/#les-permissions","text":"","title":"Les permissions"},{"location":"Linux/Master/S%C3%A9curit%C3%A9/permissions/#liste-des-permissions","text":"Commande pour obtenir des informations concernant les droits : ls -l On obteint plusieurs groupes : x : pour se d\u00e9placer dedans (pour les fichier, on execute le fichier tel qu'un script) w : modification de contenu avec l'ajout, la modification ou la suppression d'octect (en fichiers ou en repertoires) r : lecture et copie des fichiers ( r\u00e9pertoire : lister les fichiers) s : Il conf\u00e8re l'identit\u00e9 du propri\u00e9taire de la commande (avec passwd par exemple) t : on trouve la permission sur tout les dossiers temporaires/partages. Seul le propri\u00e8taire du fichier peut le supprimer. (sticky-bit)","title":"Liste des permissions"},{"location":"Linux/Master/S%C3%A9curit%C3%A9/permissions/#commandes-de-changements-de-permissions","text":"chown : pour modifier mes permissions du fichier chgrp : L'administrateur et l'utilisateur peuvent modifier les permissions chmod : Permet de changer les permissions d'acc\u00e8s d'un fichier ou d'un r\u00e9pertoire (il faut etre propri\u00e8taire du fichier) Pour chercher les fichiers qui poss\u00e8de le droit s : find -perm /u = s Et on obtient une liste de fichier plus ou moins longue si docker est install\u00e9 : Liste des fichiers poss\u00e8dant le droit permettant une \u00e9l\u00e9vation de privil\u00e8ges Info On peux ajouter une option -o pour faire un or et donc lier plusieurs arguments Exemple : find / -perm /u=s -o -perm /g=s","title":"Commandes de changements de permissions"},{"location":"Linux/Master/S%C3%A9curit%C3%A9/permissions/#les-capabilities","text":"","title":"Les capabilities"},{"location":"Linux/Master/S%C3%A9curit%C3%A9/permissions/#premieres-notions-sur-les-capabilities","text":"Installation des pages de man (si elles ne sont pas pr\u00e9sentes) : dnf -y install man-pages Overture du man de capabilities : man capabilities Les capabilities ont 2 cat\u00e9gories : les processus privili\u00e9gi\u00e9s les processes non privili\u00e9gi\u00e9s Les processus privili\u00e9gi\u00e9s sont appell\u00e9 par un superutilisateur ou root. Ils contournent les verfications du noyaux. Les processus non privili\u00e9gi\u00e9s sont soumis \u00e0 une verification bas\u00e9e sur le processus. Les options : CAP_DAC_OVERRIDE permet \u00e0 root de contourner les v\u00e9rification de lecture et d'\u00e9critures CAP_NET_BIND_SERVICE permet de lier un socket aux ports pr\u00e9vili\u00e9gi\u00e9s (inf\u00e9rieur \u00e0 1024) CAP_CHOWN permet d'apporter des modifications sur les fichiers","title":"Premi\u00e8res notions sur les capabilities"},{"location":"Linux/Master/S%C3%A9curit%C3%A9/permissions/#tests-de-la-commande-nc","text":"Avec la commande NC , cela permet de d\u00e9clarer un serveur d'\u00e9coute et ainsi de pouvoir communiquer entre 2 ordinateurs distants Tip Pour pouvoir utiliser les commandes NC, il faut l'installer : dnf -y install nc L'utilisation de nc se r\u00e9alise avec 2 terminaux afin de pouvoir cr\u00e9er comme un canal de communication entre les deux terminaux. On lance avec un user sans droits sudo la commande : nc -l 90 On obtient alors une erreur: Ncat: bind to :::90: Permission denied. QUITTING. Rappel sur les commandes de groupes et users Ajout d'un groupe nomm\u00e9 ncusers : groupadd ncusers Ajout d'un utilisateur avec le groupe ncusers useradd -g ncusers ncuser On copie le dossier nc dans le tmp : cp /bin/nc /tmp/capnc Mise en place des droits : install -o ncuser -g ncusers -m 700 /bin/nc /tmp/capnc R\u00e8glage des droits avec la commande setcap : setcap cap_net_bind_service = ep /tmp/capnc V\u00e9rification des droits sur le dossier : getcap /tmp/capnc Puis on v\u00e9rifie si les droits focntionne avec la connexion sur le ncuser puis l'indication de la commande : su - ncuser -c \"/tmp/capnc -l 90\"","title":"Tests de la commande NC"},{"location":"Linux/Master/S%C3%A9curit%C3%A9/sudo/","text":"Sudo et Sudoreplay \u00b6 Introduction \u00b6 Sudo est une abr\u00e9viation de \"substitute user do\", \"super user do\" ou \"switch user do \" , en fran\u00e7ais : \u00ab se substituer \u00e0 l'utilisateur pour faire \u00bb, \u00ab faire en tant que super-utilisateur \u00bb ou \u00ab changer d'utilisateur pour faire \u00bb). Elle est utilis\u00e9e dans tquasi tout les syst\u00e8mes de types UNIX. Important Le fichier de configuration de sudo est /etc/sudoers . Ce fichier est logiquement en lecture seule . Pour configurer sudo, on utlise les dossiers g\u00e9n\u00e9r\u00e9s par le package. Ici, un dossier est pr\u00e9sent pour laisser un fichier avec une configuration personnalis\u00e9e dans /etc/sudoers.d/ . Dans ce dossier, vous pouvez cr\u00e9er un fichier avec n'importe quelle extension avec les configurations souhait\u00e9es. Mise en oeuvre de sudo \u00b6 Directives de configurations Ici chez sudo, nous avons une directive de configuration avec !log_output . Tout est redirig\u00e9 dans le dossier /var/log/sudo-io . Mise en place des logs \u00b6 Cr\u00e9ation du dossier pour le stockage des logs d'output : mkdir -p /var/log/sudo-io Application des redirections de logs dans le dossier nouvellement cr\u00e9e. Ici on place un nouveau fichier dans /etc/sudoers.d/ nomm\u00e9 config : Defaults log_output Defaults!/usr/bin/sudoreplay !log_output Defaults!/sbin/reboot !log_output R\u00e9alisaton de r\u00e8gles pour sudo \u00b6 Commandes swap \u00b6 On souhaite que le groupe users puisse r\u00e9aliser les commandes : swapon avec n'importe quel argument swapoff avec l'argument unique \\dev\\sda3 On r\u00e9alise un nouveau fichier nomm\u00e9 swap_off_users dans le dossier de configuration de sudo : %users ALL = ( ALL ) /sbin/swapon, /sbin/swapoff /dev/sda3 Tip Pour tester les commandes, il est conseill\u00e9 de prendre un utilisateur sans aucun groupes afin de pouvoir tester simplement. Rappel : pour ajouter un user la commande est useradd et la commande pour ajouter dans un groupe usermod -aG Ici on ajoute l'utlisateur utlisateur dans le groupe users : usermod -aG users utilisateur Pour tester les commandes, on utlise les commandes suivantes : 1 2 sudo swapon /dev/sda3 sudo swapoff /dev/sda3 Commande ID \u00b6 Sudoreplay \u00b6 Avec l'activation des logs r\u00e9alis\u00e9 plus haut, tout les logs ont \u00e9t\u00e9 enregistr\u00e9s. Les logs se trouvent dans /var/log/sudo-io On peux afficher les logs avec la commande : ls -trl /var/log/sudo-io/00/00/* On peux aussi afficher les replays avec le TSID avec la commande : sudoreplay -l Pour jouer les sessions, on utlise sudoreplay avec sudoreplay TSID .","title":"Sudo et Sudoreplay"},{"location":"Linux/Master/S%C3%A9curit%C3%A9/sudo/#sudo-et-sudoreplay","text":"","title":"Sudo et Sudoreplay"},{"location":"Linux/Master/S%C3%A9curit%C3%A9/sudo/#introduction","text":"Sudo est une abr\u00e9viation de \"substitute user do\", \"super user do\" ou \"switch user do \" , en fran\u00e7ais : \u00ab se substituer \u00e0 l'utilisateur pour faire \u00bb, \u00ab faire en tant que super-utilisateur \u00bb ou \u00ab changer d'utilisateur pour faire \u00bb). Elle est utilis\u00e9e dans tquasi tout les syst\u00e8mes de types UNIX. Important Le fichier de configuration de sudo est /etc/sudoers . Ce fichier est logiquement en lecture seule . Pour configurer sudo, on utlise les dossiers g\u00e9n\u00e9r\u00e9s par le package. Ici, un dossier est pr\u00e9sent pour laisser un fichier avec une configuration personnalis\u00e9e dans /etc/sudoers.d/ . Dans ce dossier, vous pouvez cr\u00e9er un fichier avec n'importe quelle extension avec les configurations souhait\u00e9es.","title":"Introduction"},{"location":"Linux/Master/S%C3%A9curit%C3%A9/sudo/#mise-en-oeuvre-de-sudo","text":"Directives de configurations Ici chez sudo, nous avons une directive de configuration avec !log_output . Tout est redirig\u00e9 dans le dossier /var/log/sudo-io .","title":"Mise en oeuvre de sudo"},{"location":"Linux/Master/S%C3%A9curit%C3%A9/sudo/#mise-en-place-des-logs","text":"Cr\u00e9ation du dossier pour le stockage des logs d'output : mkdir -p /var/log/sudo-io Application des redirections de logs dans le dossier nouvellement cr\u00e9e. Ici on place un nouveau fichier dans /etc/sudoers.d/ nomm\u00e9 config : Defaults log_output Defaults!/usr/bin/sudoreplay !log_output Defaults!/sbin/reboot !log_output","title":"Mise en place des logs"},{"location":"Linux/Master/S%C3%A9curit%C3%A9/sudo/#realisaton-de-regles-pour-sudo","text":"","title":"R\u00e9alisaton de r\u00e8gles pour sudo"},{"location":"Linux/Master/S%C3%A9curit%C3%A9/sudo/#commandes-swap","text":"On souhaite que le groupe users puisse r\u00e9aliser les commandes : swapon avec n'importe quel argument swapoff avec l'argument unique \\dev\\sda3 On r\u00e9alise un nouveau fichier nomm\u00e9 swap_off_users dans le dossier de configuration de sudo : %users ALL = ( ALL ) /sbin/swapon, /sbin/swapoff /dev/sda3 Tip Pour tester les commandes, il est conseill\u00e9 de prendre un utilisateur sans aucun groupes afin de pouvoir tester simplement. Rappel : pour ajouter un user la commande est useradd et la commande pour ajouter dans un groupe usermod -aG Ici on ajoute l'utlisateur utlisateur dans le groupe users : usermod -aG users utilisateur Pour tester les commandes, on utlise les commandes suivantes : 1 2 sudo swapon /dev/sda3 sudo swapoff /dev/sda3","title":"Commandes swap"},{"location":"Linux/Master/S%C3%A9curit%C3%A9/sudo/#commande-id","text":"","title":"Commande ID"},{"location":"Linux/Master/S%C3%A9curit%C3%A9/sudo/#sudoreplay","text":"Avec l'activation des logs r\u00e9alis\u00e9 plus haut, tout les logs ont \u00e9t\u00e9 enregistr\u00e9s. Les logs se trouvent dans /var/log/sudo-io On peux afficher les logs avec la commande : ls -trl /var/log/sudo-io/00/00/* On peux aussi afficher les replays avec le TSID avec la commande : sudoreplay -l Pour jouer les sessions, on utlise sudoreplay avec sudoreplay TSID .","title":"Sudoreplay"},{"location":"Production_mkdocs/Acceuil_mkdocs/","text":"Mise en place du site \u00b6","title":"Mise en place du site"},{"location":"Production_mkdocs/Acceuil_mkdocs/#mise-en-place-du-site","text":"","title":"Mise en place du site"},{"location":"Production_mkdocs/Cr%C3%A9ation_des_github_actions/Prepa/","text":"Pr\u00e9paration de fichier de configuration de Github \u00b6 Ecriture d'un premier fichier vierge \u00b6","title":"Pr\u00e9paration de fichier de configuration de Github"},{"location":"Production_mkdocs/Cr%C3%A9ation_des_github_actions/Prepa/#preparation-de-fichier-de-configuration-de-github","text":"","title":"Pr\u00e9paration de fichier de configuration de Github"},{"location":"Production_mkdocs/Cr%C3%A9ation_des_github_actions/Prepa/#ecriture-dun-premier-fichier-vierge","text":"","title":"Ecriture d'un premier fichier vierge"},{"location":"Production_mkdocs/Cr%C3%A9ation_des_images/Cr%C3%A9ation_image/","text":"hide : - footer","title":"Cr\u00e9ation image"},{"location":"Production_mkdocs/Mise_en_place_de_traefik/Traefik_for_mkdocs/","text":"hide : - footer","title":"Traefik for mkdocs"},{"location":"Vitrualisation_et_cloud/Commandes/Commandes%20dans%20kubernetes/","text":"Commandes dans Kubernetes \u00b6 Changement de l'espace de travail kubectl config set-context --current --namespace kube-system Cr\u00e9ation d'un espace de travail kubectl create namespace leo Se situer dans l'environement kubectl config get-contexts Cr\u00e9ation d'un d\u00e9ployment kubectl create deployment --image nginx:latest --port 80 nginx Lister les deployments kubectl get deployments Lister les pods de mani\u00e8re simple kubectl get pods Lister les pods de mani\u00e8re plus compl\u00e8te kubectl get pods -o wide Lister tout les pods kubectl get pods -A Cr\u00e9ation d'un service kubectl create service loadbalancer --tcp 80 :80 ngnix Recuprer le service kubectl get service Edition du r\u00e9plicat kubectl scale --replicas = 3 deployment nginx D\u00e9ployement d'un template kubectl apply -f ./Deployment_whomi.yml Voir les logs d'un pod kubectl logs -f whoami Voir les logs d'un pod avec le label kubectl logs -f -l app = whoami Passer en mode exectution dans le pod kubectl exec -it nginx-deployment -- sh","title":"Commandes dans Kubernetes"},{"location":"Vitrualisation_et_cloud/Commandes/Commandes%20dans%20kubernetes/#commandes-dans-kubernetes","text":"Changement de l'espace de travail kubectl config set-context --current --namespace kube-system Cr\u00e9ation d'un espace de travail kubectl create namespace leo Se situer dans l'environement kubectl config get-contexts Cr\u00e9ation d'un d\u00e9ployment kubectl create deployment --image nginx:latest --port 80 nginx Lister les deployments kubectl get deployments Lister les pods de mani\u00e8re simple kubectl get pods Lister les pods de mani\u00e8re plus compl\u00e8te kubectl get pods -o wide Lister tout les pods kubectl get pods -A Cr\u00e9ation d'un service kubectl create service loadbalancer --tcp 80 :80 ngnix Recuprer le service kubectl get service Edition du r\u00e9plicat kubectl scale --replicas = 3 deployment nginx D\u00e9ployement d'un template kubectl apply -f ./Deployment_whomi.yml Voir les logs d'un pod kubectl logs -f whoami Voir les logs d'un pod avec le label kubectl logs -f -l app = whoami Passer en mode exectution dans le pod kubectl exec -it nginx-deployment -- sh","title":"Commandes dans Kubernetes"},{"location":"Vitrualisation_et_cloud/Commandes/Syntaxe%20fichier%20deployment%20et%20services/","text":"Syntaxe du deployment \u00b6 apiVersion : apps/v1 kind : Deployment metadata : name : nginx-deployment labels : app : nginx spec : replicas : 3 selector : matchLabels : app : nginx template : metadata : labels : app : nginx spec : containers : - name : nginx image : nginx:1.14.2 ports : - containerPort : 80 Syntaxe du service \u00b6 apiVersion : v1 kind : Service metadata : name : my-service spec : selector : app.kubernetes.io/name : MyApp ports : - protocol : TCP port : 80 targetPort : 9376 Exemple de fichier complet \u00b6 apiVersion : apps/v1 kind : Deployment metadata : name : whoami-deployment labels : app : whoami spec : replicas : 3 selector : matchLabels : app : whoami template : metadata : labels : app : whoami spec : containers : - name : whoami image : traefik/whoami:latest ports : - containerPort : 80 protocol : TCP --- apiVersion : v1 kind : Service metadata : name : whoami-service spec : selector : app : whoami ports : - protocol : TCP port : 80 targetPort : 80 type : LoadBalancer Exemple avec modification de ports \u00b6 apiVersion : apps/v1 kind : Deployment metadata : name : whoami-deployment labels : app : whoami spec : replicas : 3 selector : matchLabels : app : whoami template : metadata : labels : app : whoami spec : containers : - name : whoami image : traefik/whoami:latest env : - name : WHOAMI_PORT_NUMBER value : \"1234\" ports : - containerPort : 1234 protocol : TCP --- apiVersion : v1 kind : Service metadata : name : whoami-service spec : selector : app : whoami ports : - protocol : TCP port : 80 targetPort : 1234 type : LoadBalancer Ajout d'un namespace \u00b6 apiVersion : v1 kind : Namespace metadata : name : leo","title":"Syntaxe fichier deployment et services"},{"location":"Vitrualisation_et_cloud/Commandes/Syntaxe%20fichier%20deployment%20et%20services/#syntaxe-du-deployment","text":"apiVersion : apps/v1 kind : Deployment metadata : name : nginx-deployment labels : app : nginx spec : replicas : 3 selector : matchLabels : app : nginx template : metadata : labels : app : nginx spec : containers : - name : nginx image : nginx:1.14.2 ports : - containerPort : 80","title":"Syntaxe du deployment"},{"location":"Vitrualisation_et_cloud/Commandes/Syntaxe%20fichier%20deployment%20et%20services/#syntaxe-du-service","text":"apiVersion : v1 kind : Service metadata : name : my-service spec : selector : app.kubernetes.io/name : MyApp ports : - protocol : TCP port : 80 targetPort : 9376","title":"Syntaxe du service"},{"location":"Vitrualisation_et_cloud/Commandes/Syntaxe%20fichier%20deployment%20et%20services/#exemple-de-fichier-complet","text":"apiVersion : apps/v1 kind : Deployment metadata : name : whoami-deployment labels : app : whoami spec : replicas : 3 selector : matchLabels : app : whoami template : metadata : labels : app : whoami spec : containers : - name : whoami image : traefik/whoami:latest ports : - containerPort : 80 protocol : TCP --- apiVersion : v1 kind : Service metadata : name : whoami-service spec : selector : app : whoami ports : - protocol : TCP port : 80 targetPort : 80 type : LoadBalancer","title":"Exemple de fichier complet"},{"location":"Vitrualisation_et_cloud/Commandes/Syntaxe%20fichier%20deployment%20et%20services/#exemple-avec-modification-de-ports","text":"apiVersion : apps/v1 kind : Deployment metadata : name : whoami-deployment labels : app : whoami spec : replicas : 3 selector : matchLabels : app : whoami template : metadata : labels : app : whoami spec : containers : - name : whoami image : traefik/whoami:latest env : - name : WHOAMI_PORT_NUMBER value : \"1234\" ports : - containerPort : 1234 protocol : TCP --- apiVersion : v1 kind : Service metadata : name : whoami-service spec : selector : app : whoami ports : - protocol : TCP port : 80 targetPort : 1234 type : LoadBalancer","title":"Exemple avec modification de ports"},{"location":"Vitrualisation_et_cloud/Commandes/Syntaxe%20fichier%20deployment%20et%20services/#ajout-dun-namespace","text":"apiVersion : v1 kind : Namespace metadata : name : leo","title":"Ajout d'un namespace"},{"location":"Vitrualisation_et_cloud/Commandes/Syntaxes%20des%20stockages/","text":"Syntaxe des stockage \u00b6 D\u00e9finition du persitent volume \u00b6 apiVersion : v1 kind : PersistentVolumeClaim metadata : name : block-pvc namespace : sql spec : accessModes : - ReadWriteOnce volumeMode : Block resources : requests : storage : 10Gi","title":"Syntaxe des stockage"},{"location":"Vitrualisation_et_cloud/Commandes/Syntaxes%20des%20stockages/#syntaxe-des-stockage","text":"","title":"Syntaxe des stockage"},{"location":"Vitrualisation_et_cloud/Commandes/Syntaxes%20des%20stockages/#definition-du-persitent-volume","text":"apiVersion : v1 kind : PersistentVolumeClaim metadata : name : block-pvc namespace : sql spec : accessModes : - ReadWriteOnce volumeMode : Block resources : requests : storage : 10Gi","title":"D\u00e9finition du persitent volume"},{"location":"Vitrualisation_et_cloud/Rappels/Rappel%20sur%20la%20virtualisation/","text":"La vitrualisation \u00b6 Rappel sur les VM et les conteneurs \u00b6 Diff\u00e9rence entre la VM et le conteneur \u00b6 Rappel sur la virtualisation et les conteneurs Les VM h\u00e9bergent un syst\u00e8me virtuel complet comprenant le hardware (physique) et l'OS (Op\u00e9rating Syst\u00e8me). Cot\u00e9 conteneurs, celui-ci est utilis\u00e9 pour : la performance les ressources Facilite la MCO ( + vite , + leger et un versionning avanc\u00e9) Le prix Gain d'agilit\u00e9 Mise \u00e0 l'\u00e9chelle plus facile Les conteneurs d\u00e9pendent d'une seule et unique application. Principe du conteneur L'architecture des conteneur d\u00e9taill\u00e9 \u00b6 Le conteneur poss\u00e8de tout son environement tout autour de l'application Principe du conteneur - Architecture","title":"La vitrualisation"},{"location":"Vitrualisation_et_cloud/Rappels/Rappel%20sur%20la%20virtualisation/#la-vitrualisation","text":"","title":"La vitrualisation"},{"location":"Vitrualisation_et_cloud/Rappels/Rappel%20sur%20la%20virtualisation/#rappel-sur-les-vm-et-les-conteneurs","text":"","title":"Rappel sur les VM et les conteneurs"},{"location":"Vitrualisation_et_cloud/Rappels/Rappel%20sur%20la%20virtualisation/#difference-entre-la-vm-et-le-conteneur","text":"Rappel sur la virtualisation et les conteneurs Les VM h\u00e9bergent un syst\u00e8me virtuel complet comprenant le hardware (physique) et l'OS (Op\u00e9rating Syst\u00e8me). Cot\u00e9 conteneurs, celui-ci est utilis\u00e9 pour : la performance les ressources Facilite la MCO ( + vite , + leger et un versionning avanc\u00e9) Le prix Gain d'agilit\u00e9 Mise \u00e0 l'\u00e9chelle plus facile Les conteneurs d\u00e9pendent d'une seule et unique application. Principe du conteneur","title":"Diff\u00e9rence entre la VM et le conteneur"},{"location":"Vitrualisation_et_cloud/Rappels/Rappel%20sur%20la%20virtualisation/#larchitecture-des-conteneur-detaille","text":"Le conteneur poss\u00e8de tout son environement tout autour de l'application Principe du conteneur - Architecture","title":"L'architecture des conteneur d\u00e9taill\u00e9"},{"location":"Vitrualisation_et_cloud/Terraform/Terraform/","text":"Terraform \u00b6 Cr\u00e9ation d'un fichier main.tf : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 # Configure the Azure provider terraform { required_providers { azurerm = { source = \"hashicorp/azurerm\" version = \"~> 3.0.2\" } } required_version = \">= 1.1.0\" } # Le 'Provider' azurem va nous permettre d'int\u00e9ragir avec Azure provider \"azurerm\" { features {} } resource \"random_pet\" \"rg_name\" { prefix = \"CS2I\" } resource \"azurerm_resource_group\" \"rg\" { location = \"West Europe\" name = random_pet.rg_name.id } resource \"azurerm_kubernetes_cluster\" \"aks\" { name = \"CS2ILG\" location = azurerm_resource_group.rg.location resource_group_name = azurerm_resource_group.rg.name dns_prefix = \"CS2ILG\" default_node_pool { name = \"default\" node_count = 2 vm_size = \"Standard_D2_v2\" } identity { type = \"SystemAssigned\" } tags = { Environment = \"Demo\" } } output \"client_certificate\" { value = azurerm_kubernetes_cluster.aks.kube_config.0.client_certificate sensitive = true } output \"kube_config\" { value = azurerm_kubernetes_cluster.aks.kube_config_raw sensitive = true } Initialisation du terraform : terraform init Planninfication des changements : terraform plan -out main.tfplan Application des modifications : terraform apply main.tfplan","title":"Terraform"},{"location":"Vitrualisation_et_cloud/Terraform/Terraform/#terraform","text":"Cr\u00e9ation d'un fichier main.tf : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 # Configure the Azure provider terraform { required_providers { azurerm = { source = \"hashicorp/azurerm\" version = \"~> 3.0.2\" } } required_version = \">= 1.1.0\" } # Le 'Provider' azurem va nous permettre d'int\u00e9ragir avec Azure provider \"azurerm\" { features {} } resource \"random_pet\" \"rg_name\" { prefix = \"CS2I\" } resource \"azurerm_resource_group\" \"rg\" { location = \"West Europe\" name = random_pet.rg_name.id } resource \"azurerm_kubernetes_cluster\" \"aks\" { name = \"CS2ILG\" location = azurerm_resource_group.rg.location resource_group_name = azurerm_resource_group.rg.name dns_prefix = \"CS2ILG\" default_node_pool { name = \"default\" node_count = 2 vm_size = \"Standard_D2_v2\" } identity { type = \"SystemAssigned\" } tags = { Environment = \"Demo\" } } output \"client_certificate\" { value = azurerm_kubernetes_cluster.aks.kube_config.0.client_certificate sensitive = true } output \"kube_config\" { value = azurerm_kubernetes_cluster.aks.kube_config_raw sensitive = true } Initialisation du terraform : terraform init Planninfication des changements : terraform plan -out main.tfplan Application des modifications : terraform apply main.tfplan","title":"Terraform"},{"location":"Vitrualisation_et_cloud/kube/Informations%20sur%20kubernetes/","text":"Kubernetes \u00b6 D\u00e9finition \u00b6 Kubernetes est une solution Open Source permettant l'orchestration de ressources conteneuris\u00e9es. Cette solution est une solution d\u00e9velopp\u00e9e par Google et elle \u00e0 \u00e9t\u00e9 offert \u00e0 la Linux Fondation (2014). Par la suite la CNCF (Cloud Native Computing Fondation) \u00e0 \u00e9t\u00e9 cr\u00e9e en 2015. D\u00e9finition de kubernetes par la CNCF Kubernetes est ue plateforme open source extensible et portable pour la gestion de charge de trvail et de service conteneuris\u00e9s. Autres plateformes \u00b6 On retrouve plusieurs plateformes encore active aujourd'hui contrairement \u00e0 Docker Swarm, Mesos ... Les solutions actuelles : Titus, solution utilis\u00e9e par Netflix Nomad, soltion en voggue propuls\u00e9e par Hashicorp Apache Mesos , solution propos\u00e9e par Apache Fonctionnement de Kubernetes \u00b6 Architecture de kubernetes \u00b6 Termes utilis\u00e9s dans Kubernetes \u00b6 Terme Signification Master (ou control-plane) Permet de g\u00e9rer le syst\u00e8mes Workers Permet d'executer l'applicatif ETCD Magasin de valeurs cl\u00e9s coh\u00e9rent et hautement disponible Scheduleur Assure les diff\u00e9rentes contraintes (arret, d\u00e9marrage des conteneurs) Controller Manager Gestion des droits API-SERVER Centre n\u00e9vralgique de kubernetes Kube proxy Assure le r\u00e9seau, la communication avec l'api-server Kubelet Seul composant non contenuris\u00e9. Service systemctl qui va communiquer avec le moteur de contenurisation container Ressource ex\u00e9cutant une application pod Groupement d'un ou plusieurs conteneurs deployment Orchestre les pods et replicaSets deamonset S'assure d'avoir un pod sur chaque noeud statefullset [legacy] S'assure de n'avoir qu'un seul pod service Explose votre application sur le r\u00e9seau du cluster ingress Permet d'exposer un service en externe (#reverseProxy) persistent volumes claims Demande d'allocation de stockage configMaps stockage cl\u00e9-valeur non confidentiel secrets stockage cl\u00e9-valeur confidentiel Objets de kubernetes \u00b6","title":"Kubernetes"},{"location":"Vitrualisation_et_cloud/kube/Informations%20sur%20kubernetes/#kubernetes","text":"","title":"Kubernetes"},{"location":"Vitrualisation_et_cloud/kube/Informations%20sur%20kubernetes/#definition","text":"Kubernetes est une solution Open Source permettant l'orchestration de ressources conteneuris\u00e9es. Cette solution est une solution d\u00e9velopp\u00e9e par Google et elle \u00e0 \u00e9t\u00e9 offert \u00e0 la Linux Fondation (2014). Par la suite la CNCF (Cloud Native Computing Fondation) \u00e0 \u00e9t\u00e9 cr\u00e9e en 2015. D\u00e9finition de kubernetes par la CNCF Kubernetes est ue plateforme open source extensible et portable pour la gestion de charge de trvail et de service conteneuris\u00e9s.","title":"D\u00e9finition"},{"location":"Vitrualisation_et_cloud/kube/Informations%20sur%20kubernetes/#autres-plateformes","text":"On retrouve plusieurs plateformes encore active aujourd'hui contrairement \u00e0 Docker Swarm, Mesos ... Les solutions actuelles : Titus, solution utilis\u00e9e par Netflix Nomad, soltion en voggue propuls\u00e9e par Hashicorp Apache Mesos , solution propos\u00e9e par Apache","title":"Autres plateformes"},{"location":"Vitrualisation_et_cloud/kube/Informations%20sur%20kubernetes/#fonctionnement-de-kubernetes","text":"","title":"Fonctionnement de Kubernetes"},{"location":"Vitrualisation_et_cloud/kube/Informations%20sur%20kubernetes/#architecture-de-kubernetes","text":"","title":"Architecture de kubernetes"},{"location":"Vitrualisation_et_cloud/kube/Informations%20sur%20kubernetes/#termes-utilises-dans-kubernetes","text":"Terme Signification Master (ou control-plane) Permet de g\u00e9rer le syst\u00e8mes Workers Permet d'executer l'applicatif ETCD Magasin de valeurs cl\u00e9s coh\u00e9rent et hautement disponible Scheduleur Assure les diff\u00e9rentes contraintes (arret, d\u00e9marrage des conteneurs) Controller Manager Gestion des droits API-SERVER Centre n\u00e9vralgique de kubernetes Kube proxy Assure le r\u00e9seau, la communication avec l'api-server Kubelet Seul composant non contenuris\u00e9. Service systemctl qui va communiquer avec le moteur de contenurisation container Ressource ex\u00e9cutant une application pod Groupement d'un ou plusieurs conteneurs deployment Orchestre les pods et replicaSets deamonset S'assure d'avoir un pod sur chaque noeud statefullset [legacy] S'assure de n'avoir qu'un seul pod service Explose votre application sur le r\u00e9seau du cluster ingress Permet d'exposer un service en externe (#reverseProxy) persistent volumes claims Demande d'allocation de stockage configMaps stockage cl\u00e9-valeur non confidentiel secrets stockage cl\u00e9-valeur confidentiel","title":"Termes utilis\u00e9s dans Kubernetes"},{"location":"Vitrualisation_et_cloud/kube/Informations%20sur%20kubernetes/#objets-de-kubernetes","text":"","title":"Objets de kubernetes"},{"location":"Vitrualisation_et_cloud/kube/les%20secrets/","text":"Les secrets dans kubernetes \u00b6 Comment est fait un secret \u00b6 Un secret est stock\u00e9 dans la base ETCD de kubernetes. Ce secret est pr\u00e9sent en base 64. Cr\u00e9ation d'un secret \u00b6 La commande suivante permet de g\u00e9n\u00e9rer un fichier avec les secrets : kubectl create secret generic wordpress --from-literal = username = wordpress --from-literal = password = password --from-literal = database = user -o yaml --dry-run = client Cela nous donne : apiVersion : v1 data : database : dXNlcg== password : cGFzc3dvcmQ= username : d29yZHByZXNz kind : Secret metadata : creationTimestamp : null name : wordpress On peux retrouver les mot de passe avec la commande suivant : echo \"dXNlcg==\" | base64 -d","title":"Les secrets dans kubernetes"},{"location":"Vitrualisation_et_cloud/kube/les%20secrets/#les-secrets-dans-kubernetes","text":"","title":"Les secrets dans kubernetes"},{"location":"Vitrualisation_et_cloud/kube/les%20secrets/#comment-est-fait-un-secret","text":"Un secret est stock\u00e9 dans la base ETCD de kubernetes. Ce secret est pr\u00e9sent en base 64.","title":"Comment est fait un secret"},{"location":"Vitrualisation_et_cloud/kube/les%20secrets/#creation-dun-secret","text":"La commande suivante permet de g\u00e9n\u00e9rer un fichier avec les secrets : kubectl create secret generic wordpress --from-literal = username = wordpress --from-literal = password = password --from-literal = database = user -o yaml --dry-run = client Cela nous donne : apiVersion : v1 data : database : dXNlcg== password : cGFzc3dvcmQ= username : d29yZHByZXNz kind : Secret metadata : creationTimestamp : null name : wordpress On peux retrouver les mot de passe avec la commande suivant : echo \"dXNlcg==\" | base64 -d","title":"Cr\u00e9ation d'un secret"},{"location":"Vitrualisation_et_cloud/kube/pointasvaoir/","text":"Point \u00e0 savoir \u00b6 d\u00e9finir etat d\u00e9sir\u00e9 deploiement d'un etat d\u00e9sir\u00e9 partout mise a l'echelle 110 pods max par noeuds (kubectl top pod) pour d\u00e9bugger (log / describe / debug / exec) penser les applications avec les architectures les plus r\u00e9centes (developpement et execution) d\u00e9placement des charges de travail avec (k drain) arch mini 1 / archi mini recommand\u00e9e 3 / archi focntionnnelle 5 roles controle plain et worker ETCD (base cl\u00e9 valeur) Terraform (piloter avec de la configuration as the code) 1 pod peux contenir plusieurs conteneurs (bonne pratique 1 = 1) bdd dans un conteneur \u00e0 eviter Ingress controler pour de la gestion de trafik (redirection de trafik) CSI = Conteneur storage interface CNI = Conteneur network interface stockage = mode block / mode fichier / mode objet service = r\u00e8gle de parefeu r\u00e9seau = clusterIP / loadbancer demonset = permettre d'avoir des pods sur des noeuds diff\u00e9rents Replicaset = uniquement dans un deploiement manifests sont enregistr\u00e9s dans la base ETCD CRD permet de rajouter des plugins (ingressroute / ingressrouteTCP) RBAC = Role BAse Access Controle Secret / Configmap = base 64 qui diff\u00e8re","title":"Point \u00e0 savoir"},{"location":"Vitrualisation_et_cloud/kube/pointasvaoir/#point-a-savoir","text":"d\u00e9finir etat d\u00e9sir\u00e9 deploiement d'un etat d\u00e9sir\u00e9 partout mise a l'echelle 110 pods max par noeuds (kubectl top pod) pour d\u00e9bugger (log / describe / debug / exec) penser les applications avec les architectures les plus r\u00e9centes (developpement et execution) d\u00e9placement des charges de travail avec (k drain) arch mini 1 / archi mini recommand\u00e9e 3 / archi focntionnnelle 5 roles controle plain et worker ETCD (base cl\u00e9 valeur) Terraform (piloter avec de la configuration as the code) 1 pod peux contenir plusieurs conteneurs (bonne pratique 1 = 1) bdd dans un conteneur \u00e0 eviter Ingress controler pour de la gestion de trafik (redirection de trafik) CSI = Conteneur storage interface CNI = Conteneur network interface stockage = mode block / mode fichier / mode objet service = r\u00e8gle de parefeu r\u00e9seau = clusterIP / loadbancer demonset = permettre d'avoir des pods sur des noeuds diff\u00e9rents Replicaset = uniquement dans un deploiement manifests sont enregistr\u00e9s dans la base ETCD CRD permet de rajouter des plugins (ingressroute / ingressrouteTCP) RBAC = Role BAse Access Controle Secret / Configmap = base 64 qui diff\u00e8re","title":"Point \u00e0 savoir"},{"location":"Windows/Active_directory/GPO/","text":"Nous avons un script \u00e0 d\u00e9ployer sur toutes les machines du domaine. Ce script doit : S'executer au d\u00e9marrage de la session Les utilisateurs dans les OU choisi doivent avoir se script Info OU = Unit\u00e9 d'organisation Cr\u00e9ation d'un OU \u00b6 Pour cr\u00e9er un OU, le serveur (ici un Windows serveur 2019) doit \u00eatre un serveur AD. Le serveur AD doit \u00eatre promu en contr\u00f4leur de domaine. La cr\u00e9ation d'OU, intervient dans les outils du gestionnaire de serveur puis dans dans gestion des strat\u00e9gies de groupe . Outils de l'AD On obtient ensuite une fen\u00eatre avec la for\u00eat. Gestion des strat\u00e9gies de groupes On utlise ensuite le clic droit -> Nouvelle unit\u00e9 d'organsiation Cr\u00e9ation de l'OU Donnez ensuite un nom \u00e0 votre OU. On retrouve cette OU dans la foret sous les domaines Unit\u00e9 organisation 1 Cr\u00e9ation de la GPO \u00b6 Une fois l'OU cr\u00e9e, vous pouvez vous positionner sur celle-ci et faire Clic droit -> Cr\u00e9\u00e9r un objet GPO Mettez un nom \u00e0 cette GPO. Cr\u00e9ation de la GPO Faites clic droit sur la GPO puis modifier l\u00e0. Ici nous allons dans les strat\u00e9gies de scripts d'ouverture de sessions. Localisation des scripts d'ouverture de sessions On ajoute le script (ici un script powershell) dans l'onglet Powershell. Quand on met un script, il faut garder le dossier par d\u00e9faut et mettre le script dans ce dossier. \\\\AD-LG.local\\SysVol\\AD-LG.local\\Policies\\{53DB8C41-12CE-42EE-9DD9-509CA44D262A}\\User\\Scripts\\Logon Ici le chemin avec le num\u00e9ro de la GPO. On v\u00e9rifie ensuite le nom du script. Onglet powershell Sur la machine cliente, on peux voir avec un GPRESULT /R l'\u00e9tat de la GPO. On v\u00e9rifie que la GPO espion est bien pr\u00e9sent. Verificiation du scripts d'ouverture de sessions","title":"GPO"},{"location":"Windows/Active_directory/GPO/#creation-dun-ou","text":"Pour cr\u00e9er un OU, le serveur (ici un Windows serveur 2019) doit \u00eatre un serveur AD. Le serveur AD doit \u00eatre promu en contr\u00f4leur de domaine. La cr\u00e9ation d'OU, intervient dans les outils du gestionnaire de serveur puis dans dans gestion des strat\u00e9gies de groupe . Outils de l'AD On obtient ensuite une fen\u00eatre avec la for\u00eat. Gestion des strat\u00e9gies de groupes On utlise ensuite le clic droit -> Nouvelle unit\u00e9 d'organsiation Cr\u00e9ation de l'OU Donnez ensuite un nom \u00e0 votre OU. On retrouve cette OU dans la foret sous les domaines Unit\u00e9 organisation 1","title":"Cr\u00e9ation d'un OU"},{"location":"Windows/Active_directory/GPO/#creation-de-la-gpo","text":"Une fois l'OU cr\u00e9e, vous pouvez vous positionner sur celle-ci et faire Clic droit -> Cr\u00e9\u00e9r un objet GPO Mettez un nom \u00e0 cette GPO. Cr\u00e9ation de la GPO Faites clic droit sur la GPO puis modifier l\u00e0. Ici nous allons dans les strat\u00e9gies de scripts d'ouverture de sessions. Localisation des scripts d'ouverture de sessions On ajoute le script (ici un script powershell) dans l'onglet Powershell. Quand on met un script, il faut garder le dossier par d\u00e9faut et mettre le script dans ce dossier. \\\\AD-LG.local\\SysVol\\AD-LG.local\\Policies\\{53DB8C41-12CE-42EE-9DD9-509CA44D262A}\\User\\Scripts\\Logon Ici le chemin avec le num\u00e9ro de la GPO. On v\u00e9rifie ensuite le nom du script. Onglet powershell Sur la machine cliente, on peux voir avec un GPRESULT /R l'\u00e9tat de la GPO. On v\u00e9rifie que la GPO espion est bien pr\u00e9sent. Verificiation du scripts d'ouverture de sessions","title":"Cr\u00e9ation de la GPO"},{"location":"Windows/Powershell/Cr%C3%A9ation%20d%27un%20dossier%2Bscript/","text":"Verification \u00b6 Dans cette partie, on va v\u00e9rifier si un dossier est cr\u00e9e \u00e0\u00f9 non. Pour test si un dossier existe, on va utiliser Get-Item : $retour = Get-Item -Path \"c:/log\" -ErrorAction SilentlyContinue Ici, on stocke la valeur rendu par la commande dans $retour . On va ensuite aller chercher le dossier c:/log . On va s'assurer que la commande s'excute en silence m\u00eame si il y a des erreurs avec -ErrorAction SilentlyContinue Note Ici nous utilisons un dossier qui n'existe pas. Le but de cette activit\u00e9 est de cr\u00e9er un script qui quand il ne trouve pas le dossier c:/log , il cr\u00e9e un dossier. Dans ce dossier, nous souhaitons qu'il y ai un fichier nomm\u00e9 'ESPION.txt'. On va donc cr\u00e9er un dossier \u00e0 la racine si celui-ci n'existe pas : if (!( Get-Item -Path \"c:\\log\" -ErrorAction SilentlyContinue )) { New-Item \"c:\\log\" -ItemType Directory } On v\u00e9rifie ensuite si le fichier espion.txt existe dans le dossier c:\\log : if (!( Get-Item -Path \"c:\\log\\espion.txt\" -ErrorAction SilentlyContinue )) { New-Item -Path \"c:\\log\\espion.txt\" -ItemType File } On r\u00e9alise ensuite le script complet avec l'impl\u00e9mentation du user et de la date/heure : if (!( Get-Item -Path \"c:\\log\" -ErrorAction SilentlyContinue )) { New-Item \"c:\\log\" -ItemType Directory } if (!( Get-Item -Path \"c:\\log\\espion.txt\" -ErrorAction SilentlyContinue )) { New-Item -Path \"c:\\log\\espion.txt\" -ItemType File } $export = \"{0,-20}:{1:yyyy}:{2}:{3}:{4}:{5}:{6}\" -f $env:USERNAME , ( Get-Date ),( Get-Date ). Month ,( Get-Date ). Day ,( Get-Date ). Hour ,( Get-Date ). Minute , ( Get-Date ). DayOfWeek Write-Output $export ADD-content -path \"c:\\log\\espion.txt\" -value $export Note Le ADD-content -path \"c:\\log\\espion.txt\" -value $export permet d'\u00e9crit dans le fichier espion.txt","title":"Cr\u00e9ation d'un dossier+script"},{"location":"Windows/Powershell/Cr%C3%A9ation%20d%27un%20dossier%2Bscript/#verification","text":"Dans cette partie, on va v\u00e9rifier si un dossier est cr\u00e9e \u00e0\u00f9 non. Pour test si un dossier existe, on va utiliser Get-Item : $retour = Get-Item -Path \"c:/log\" -ErrorAction SilentlyContinue Ici, on stocke la valeur rendu par la commande dans $retour . On va ensuite aller chercher le dossier c:/log . On va s'assurer que la commande s'excute en silence m\u00eame si il y a des erreurs avec -ErrorAction SilentlyContinue Note Ici nous utilisons un dossier qui n'existe pas. Le but de cette activit\u00e9 est de cr\u00e9er un script qui quand il ne trouve pas le dossier c:/log , il cr\u00e9e un dossier. Dans ce dossier, nous souhaitons qu'il y ai un fichier nomm\u00e9 'ESPION.txt'. On va donc cr\u00e9er un dossier \u00e0 la racine si celui-ci n'existe pas : if (!( Get-Item -Path \"c:\\log\" -ErrorAction SilentlyContinue )) { New-Item \"c:\\log\" -ItemType Directory } On v\u00e9rifie ensuite si le fichier espion.txt existe dans le dossier c:\\log : if (!( Get-Item -Path \"c:\\log\\espion.txt\" -ErrorAction SilentlyContinue )) { New-Item -Path \"c:\\log\\espion.txt\" -ItemType File } On r\u00e9alise ensuite le script complet avec l'impl\u00e9mentation du user et de la date/heure : if (!( Get-Item -Path \"c:\\log\" -ErrorAction SilentlyContinue )) { New-Item \"c:\\log\" -ItemType Directory } if (!( Get-Item -Path \"c:\\log\\espion.txt\" -ErrorAction SilentlyContinue )) { New-Item -Path \"c:\\log\\espion.txt\" -ItemType File } $export = \"{0,-20}:{1:yyyy}:{2}:{3}:{4}:{5}:{6}\" -f $env:USERNAME , ( Get-Date ),( Get-Date ). Month ,( Get-Date ). Day ,( Get-Date ). Hour ,( Get-Date ). Minute , ( Get-Date ). DayOfWeek Write-Output $export ADD-content -path \"c:\\log\\espion.txt\" -value $export Note Le ADD-content -path \"c:\\log\\espion.txt\" -value $export permet d'\u00e9crit dans le fichier espion.txt","title":"Verification"},{"location":"Windows/Powershell/Cr%C3%A9ation%20fichier%20avec%20user%20%2B%20date/","text":"Comment obtenir la date en Powershell \u00b6 On utilise la commande : 1 Get-Date R\u00e9sultat de la commande Get-date Obtenir certaines informations d'apr\u00e8s une commande \u00b6 Note Les op\u00e9rateurs sont r\u00e9f\u00e9renc\u00e9s sur le site : https://ss64.com/ps/ On souhaite r\u00e9cup\u00e9rer les diff\u00e9rents membre de la date affich\u00e9e par powershell : 1 Get-Date | Get-Member R\u00e9sultat de la damande des membres Dans le cas de la commande Get-member et de Powershell en g\u00e9n\u00e9ral, nous avons un language orient\u00e9 objet. On r\u00e9cup\u00e8re les quelques informations : 1 Get-Date | Select-Object -Property Year , Month , Day Cette commande nous donne un tableau de valeur : Tableau de date On stocke la valeur dans une variable temporaire : 1 2 3 $DATE = Get-Date $DATE . Day On r\u00e9cup\u00e8re uniquement la valeur de la date. Info On peux aussi r\u00e9cup\u00e8rer la valeur d'un autre fa\u00e7on : ( Get-Date ). Day Cherche une chaine de caract\u00e8res : Get-Date -UFormat \"%Y:%m:%d:%R:%A\" Chaine de caract\u00e8re obtenue On prend le nom d'utilisateur : 1 $env:USERNAME On va ensuite aller chercher les diff\u00e9rentes informations avec leur position : 1 \"{0,-20}:{1:yyyy}:{2:MM}\" -f $env:USERNAME , ( Get-Date ). Year , ( Get-Date ). Month Info On utilise les {} pour donner la position + le formatage L'option -f permet de r\u00e9aliser le formatage Les diff\u00e9rentes informations sont s\u00e9par\u00e9es par une virgule , Pour afficher et cr\u00e9er un fichier avec les informations voulue : 1 2 3 4 5 6 7 8 9 10 11 12 $export = \"{0,-20}:{1:yyyy}:{2}:{3}:{4}\" -f $env:USERNAME , ( Get-Date ),( Get-Date ). Month ,( Get-Date ). Day ,( Get-Date ). DayOfWeek Write-Output $export # Export dans un txt # On verifi si le fichier existe $file = \".\\export.txt\" if (!( Test-Path -Path $file )){ #Si il existe pas on le cr\u00e9er New-Item -Path $file } # On ajoute notre ligne dans le fichier ADD-content -path $file -value $export","title":"Cr\u00e9ation fichier avec user + date"},{"location":"Windows/Powershell/Cr%C3%A9ation%20fichier%20avec%20user%20%2B%20date/#comment-obtenir-la-date-en-powershell","text":"On utilise la commande : 1 Get-Date R\u00e9sultat de la commande Get-date","title":"Comment obtenir la date en Powershell"},{"location":"Windows/Powershell/Cr%C3%A9ation%20fichier%20avec%20user%20%2B%20date/#obtenir-certaines-informations-dapres-une-commande","text":"Note Les op\u00e9rateurs sont r\u00e9f\u00e9renc\u00e9s sur le site : https://ss64.com/ps/ On souhaite r\u00e9cup\u00e9rer les diff\u00e9rents membre de la date affich\u00e9e par powershell : 1 Get-Date | Get-Member R\u00e9sultat de la damande des membres Dans le cas de la commande Get-member et de Powershell en g\u00e9n\u00e9ral, nous avons un language orient\u00e9 objet. On r\u00e9cup\u00e8re les quelques informations : 1 Get-Date | Select-Object -Property Year , Month , Day Cette commande nous donne un tableau de valeur : Tableau de date On stocke la valeur dans une variable temporaire : 1 2 3 $DATE = Get-Date $DATE . Day On r\u00e9cup\u00e8re uniquement la valeur de la date. Info On peux aussi r\u00e9cup\u00e8rer la valeur d'un autre fa\u00e7on : ( Get-Date ). Day Cherche une chaine de caract\u00e8res : Get-Date -UFormat \"%Y:%m:%d:%R:%A\" Chaine de caract\u00e8re obtenue On prend le nom d'utilisateur : 1 $env:USERNAME On va ensuite aller chercher les diff\u00e9rentes informations avec leur position : 1 \"{0,-20}:{1:yyyy}:{2:MM}\" -f $env:USERNAME , ( Get-Date ). Year , ( Get-Date ). Month Info On utilise les {} pour donner la position + le formatage L'option -f permet de r\u00e9aliser le formatage Les diff\u00e9rentes informations sont s\u00e9par\u00e9es par une virgule , Pour afficher et cr\u00e9er un fichier avec les informations voulue : 1 2 3 4 5 6 7 8 9 10 11 12 $export = \"{0,-20}:{1:yyyy}:{2}:{3}:{4}\" -f $env:USERNAME , ( Get-Date ),( Get-Date ). Month ,( Get-Date ). Day ,( Get-Date ). DayOfWeek Write-Output $export # Export dans un txt # On verifi si le fichier existe $file = \".\\export.txt\" if (!( Test-Path -Path $file )){ #Si il existe pas on le cr\u00e9er New-Item -Path $file } # On ajoute notre ligne dans le fichier ADD-content -path $file -value $export","title":"Obtenir certaines informations d'apr\u00e8s une commande"}]}